"""
æ„å›¾å¤„ç†å™¨ - ä¸¤é˜¶æ®µLLMæ„å›¾è¯†åˆ«å’Œå‚æ•°æå–

ç¬¬ä¸€é˜¶æ®µï¼šæ„å›¾è¯†åˆ« - åŸºäºè¯­ä¹‰ç†è§£ï¼Œä¸ä¾èµ–å…³é”®è¯åŒ¹é…
ç¬¬äºŒé˜¶æ®µï¼šå‚æ•°æå– - é’ˆå¯¹å…·ä½“æ„å›¾æå–ç»“æ„åŒ–å‚æ•°
"""

import json
import os
from typing import Dict, Any, Optional, Tuple
from Module.Common.scripts.common import debug_utils
from ..service_decorators import file_processing_safe


class IntentProcessor:
    """
    æ„å›¾å¤„ç†å™¨ - å®ç°ä¸¤é˜¶æ®µLLMå¤„ç†æµç¨‹
    """

    def __init__(self, llm_service, config_path: str = None):
        """
        åˆå§‹åŒ–æ„å›¾å¤„ç†å™¨

        Args:
            llm_service: LLMServiceå®ä¾‹
            config_path: æ„å›¾é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.llm_service = llm_service

        # åŠ è½½æ„å›¾é…ç½®
        if config_path is None:
            config_path = os.path.join(os.path.dirname(__file__), "intent_config.json")

        self.config = self._load_config(config_path)
        self.intents = self.config.get("intents", {})
        self.settings = self.config.get("settings", {})

    @file_processing_safe(
        "æ„å›¾é…ç½®åŠ è½½å¤±è´¥", return_value={"intents": {}, "settings": {}}
    )
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½æ„å›¾é…ç½®æ–‡ä»¶"""
        with open(config_path, "r", encoding="utf-8") as f:
            config = json.load(f)
        debug_utils.log_and_print(
            f"âœ… æ„å›¾é…ç½®åŠ è½½æˆåŠŸ: {len(config.get('intents', {}))} ä¸ªæ„å›¾",
            log_level="DEBUG",
        )
        return config

    # ==================== ç¬¬ä¸€é˜¶æ®µï¼šæ„å›¾è¯†åˆ« ====================

    def _build_stage1_prompt(self, user_input: str) -> str:
        """æ„å»ºç¬¬ä¸€é˜¶æ®µæ„å›¾è¯†åˆ«æç¤ºè¯"""
        intent_names = list(self.intents.keys())

        prompt_parts = [
            "# ä»»åŠ¡ï¼š",
            "æ·±å…¥ç†è§£ç”¨æˆ·è¾“å…¥çš„è¯­ä¹‰ï¼Œä¸ºä»¥ä¸‹æ¯ä¸€ä¸ªå®šä¹‰çš„æ„å›¾ç±»å‹ï¼Œåˆ†åˆ«è¯„ä¼°å…¶ä¸ç”¨æˆ·è¾“å…¥åŒ¹é…çš„ç½®ä¿¡åº¦è¯„åˆ†ï¼ˆ0-100ï¼‰ã€‚",
            "è¯·å…³æ³¨ç”¨æˆ·æƒ³è¦è¾¾æˆçš„æ ¹æœ¬ç›®æ ‡ï¼Œè€Œä¸æ˜¯è¡¨é¢çš„å…³é”®è¯åŒ¹é…ã€‚",
            "",
            "# æ”¯æŒçš„æ„å›¾ç±»å‹åŠå…¶æ ¸å¿ƒç›®æ ‡ï¼š",
        ]

        # æ·»åŠ æ„å›¾å®šä¹‰
        for intent_name, config in self.intents.items():
            prompt_parts.append(f"## æ„å›¾ï¼š{intent_name}")
            prompt_parts.append(f"   æ ¸å¿ƒç›®æ ‡ï¼š{config['core_goal']}")
            prompt_parts.append("")

        prompt_parts.extend(
            [
                "# åˆ†æä¸è¾“å‡ºè¦æ±‚ï¼š",
                "1. å¯¹äºä»¥ä¸‹æ¯ä¸€ä¸ªæ„å›¾ç±»å‹ï¼Œç»™å‡ºå…¶åŒ¹é…ç”¨æˆ·è¾“å…¥çš„ç½®ä¿¡åº¦è¯„åˆ†ï¼ˆ0-100ï¼‰ï¼š",
            ]
            + [f"   - {name}" for name in intent_names]
            + [
                "2. å¯¹äºå¯èƒ½çš„å…¶ä»–æ„å›¾ï¼Œè¿”å›å¯èƒ½çš„æ„å›¾åç§°",
                f"# ç”¨æˆ·è¾“å…¥ï¼š\n{user_input}",
                "",
            ]
        )

        return "\n".join(prompt_parts)

    def _get_stage1_response_schema(self) -> Dict[str, Any]:
        """è·å–ç¬¬ä¸€é˜¶æ®µå“åº”ç»“æ„å®šä¹‰"""
        intent_names = list(self.intents.keys())
        intent_scores_properties = {
            name: {
                "type": "integer",
                "minimum": 0,
                "maximum": 100,
                "description": f"å¯¹'{name}'æ„å›¾çš„ç½®ä¿¡åº¦è¯„åˆ†",
            }
            for name in intent_names
        }

        return {
            "type": "object",
            "properties": {
                "intent_scores": {
                    "type": "object",
                    "properties": intent_scores_properties,
                    "required": intent_names,
                    "description": "æ¯ä¸ªæ”¯æŒæ„å›¾çš„ç½®ä¿¡åº¦è¯„åˆ†ï¼ˆ0-100ï¼‰",
                },
                "other_intent_name": {
                    "type": "string",
                    "description": "å¯¹äºå¯èƒ½çš„å…¶ä»–æ„å›¾ï¼Œè¿”å›å¯èƒ½çš„æ„å›¾åç§°",
                },
            },
            "required": ["intent_scores"],
        }

    def recognize_intent_stage1(self, user_input: str) -> Dict[str, Any]:
        """æ‰§è¡Œç¬¬ä¸€é˜¶æ®µæ„å›¾è¯†åˆ«"""
        prompt = self._build_stage1_prompt(user_input)
        print("test-", prompt, "\n")

        debug_utils.log_and_print(
            f"ğŸ” å¼€å§‹ç¬¬ä¸€é˜¶æ®µæ„å›¾è¯†åˆ«: '{user_input[:50]}'", log_level="DEBUG"
        )

        try:
            # è°ƒç”¨LLMServiceçš„è·¯ç”±æ–¹æ³•
            result = self.llm_service.router_structured_call(
                prompt=prompt,
                response_schema=self._get_stage1_response_schema(),
                system_instruction="ä½ æ˜¯æ™ºèƒ½åŠ©æ‰‹æ„å›¾è¯†åˆ«ä¸“å®¶ã€‚ä¸¥æ ¼æŒ‰ç…§æä¾›çš„JSONæ¨¡å¼è¾“å‡ºï¼Œä¸è¦è¾“å‡ºé¢å¤–æ–‡æœ¬ã€‚",
                temperature=self.settings.get("stage1_model_config", {}).get(
                    "temperature", 0.1
                ),
            )
            debug_utils.log_and_print(
                f"âœ… ç¬¬ä¸€é˜¶æ®µå®Œæˆï¼Œè¯„åˆ†: {result.get('intent_scores', {})}",
                log_level="DEBUG",
            )
            return result

        except Exception as e:
            debug_utils.log_and_print(
                f"âŒ ç¬¬ä¸€é˜¶æ®µæ„å›¾è¯†åˆ«å¤±è´¥: {e}", log_level="ERROR"
            )
            # è¿”å›é”™è¯¯ç»“æœ
            return {
                "error": str(e),
                "intent_scores": {name: 0 for name in self.intents.keys()},
                "primary_extracted_content": user_input,
                "reasoning_for_scores": f"å¤„ç†å¤±è´¥: {e}",
            }

    def determine_primary_intent(
        self, stage1_result: Dict[str, Any], confidence_threshold: int = None
    ) -> Tuple[Optional[str], int]:
        """æ ¹æ®ç¬¬ä¸€é˜¶æ®µç»“æœç¡®å®šä¸»è¦æ„å›¾"""
        if confidence_threshold is None:
            confidence_threshold = self.settings.get("default_confidence_threshold", 60)

        if "error" in stage1_result or "intent_scores" not in stage1_result:
            return "å…¶ä»–", 0

        intent_scores = stage1_result["intent_scores"]

        # ä¼˜å…ˆé€‰æ‹©é"å…¶ä»–"çš„æœ€é«˜åˆ†æ„å›¾
        primary_intent = None
        max_confidence = -1

        for intent, confidence in intent_scores.items():
            if intent == "å…¶ä»–":
                continue
            if confidence > max_confidence:
                max_confidence = confidence
                primary_intent = intent

        # å¦‚æœæœ€é«˜åˆ†çš„é"å…¶ä»–"æ„å›¾è¶…è¿‡é˜ˆå€¼
        if primary_intent and max_confidence >= confidence_threshold:
            return primary_intent, max_confidence

        # å¦åˆ™ï¼Œæ£€æŸ¥"å…¶ä»–"æ„å›¾çš„å¾—åˆ†
        other_confidence = intent_scores.get("å…¶ä»–", 0)
        if other_confidence >= confidence_threshold:
            return "å…¶ä»–", other_confidence

        # å¦‚æœæ‰€æœ‰æ„å›¾éƒ½ä½äºé˜ˆå€¼ï¼Œè¿”å›å¾—åˆ†æœ€é«˜çš„
        if primary_intent and max_confidence > other_confidence:
            return primary_intent, max_confidence

        return "å…¶ä»–", other_confidence

    # ==================== ç¬¬äºŒé˜¶æ®µï¼šå‚æ•°æå– ====================

    def _build_stage2_prompt(
        self, user_input: str, determined_intent: str
    ) -> Optional[str]:
        """æ„å»ºç¬¬äºŒé˜¶æ®µå‚æ•°æå–æç¤ºè¯"""
        if determined_intent not in self.intents:
            return None

        intent_config = self.intents[determined_intent]
        schema_desc = json.dumps(
            intent_config["stage2_parameters"], indent=2, ensure_ascii=False
        )

        prompt_parts = [
            "# ä»»åŠ¡ï¼š",
            f"æ ¹æ®å·²è¯†åˆ«çš„ç”¨æˆ·æ„å›¾ {determined_intent}ï¼Œä»ä»¥ä¸‹ç”¨æˆ·è¾“å…¥ä¸­æå–ç›¸å…³çš„å‚æ•°ä¿¡æ¯ã€‚",
            "å¦‚æœæŸäº›schemaä¸­å®šä¹‰çš„å‚æ•°åœ¨ç”¨æˆ·è¾“å…¥ä¸­æœªæåŠï¼Œåˆ™çœç•¥è¯¥å‚æ•°æˆ–å°†å…¶å€¼è®¾ä¸ºnullï¼Œè€ƒè™‘ä¸€å®šçš„ç”¨æˆ·æè¿°ä¸ç²¾ç¡®çš„æƒ…å†µï¼Œå…è®¸ä¸€å®šç¨‹åº¦çš„æ¨¡ç³ŠåŒ¹é…ã€‚",
            "",
            f"# ç”¨æˆ·è¾“å…¥ï¼š\n{user_input}",
        ]

        return "\n".join(prompt_parts)

    def extract_parameters_stage2(
        self, user_input: str, determined_intent: str
    ) -> Dict[str, Any]:
        """æ‰§è¡Œç¬¬äºŒé˜¶æ®µå‚æ•°æå–"""
        if determined_intent == "å…¶ä»–" or determined_intent is None:
            # å¯¹äº"å…¶ä»–"æ„å›¾ï¼Œè¿”å›åŸå§‹è¾“å…¥
            return {
                "parameters": {
                    "original_input": user_input,
                    "possible_category": "æœªåˆ†ç±»",
                }
            }

        if determined_intent not in self.intents:
            return {"error": f"æœªçŸ¥æ„å›¾ç±»å‹: {determined_intent}"}

        prompt = self._build_stage2_prompt(user_input, determined_intent)
        print("test-prompt_stage2", prompt, "\n")
        if not prompt:
            return {"error": f"æ— æ³•ä¸ºæ„å›¾ {determined_intent} æ„å»ºå‚æ•°æå–æç¤ºè¯"}

        debug_utils.log_and_print(
            f"ğŸ”§ å¼€å§‹ç¬¬äºŒé˜¶æ®µå‚æ•°æå–: {determined_intent}", log_level="DEBUG"
        )

        try:
            # è°ƒç”¨LLMServiceçš„è·¯ç”±æ–¹æ³•
            result = self.llm_service.router_structured_call(
                prompt=prompt,
                response_schema=self.intents[determined_intent]["stage2_parameters"],
                system_instruction="ä½ æ˜¯å‚æ•°æå–ä¸“å®¶ã€‚ä¸¥æ ¼æŒ‰ç…§æä¾›çš„JSONæ¨¡å¼è¾“å‡ºï¼Œä¸è¦è¾“å‡ºé¢å¤–æ–‡æœ¬ã€‚",
                temperature=self.settings.get("stage2_model_config", {}).get(
                    "temperature", 0.2
                ),
            )

            debug_utils.log_and_print(
                f"âœ… ç¬¬äºŒé˜¶æ®µå®Œæˆï¼Œå‚æ•°: {list(result.keys())}", log_level="DEBUG"
            )
            return {"parameters": result}

        except Exception as e:
            debug_utils.log_and_print(
                f"âŒ ç¬¬äºŒé˜¶æ®µå‚æ•°æå–å¤±è´¥: {e}", log_level="ERROR"
            )
            # è¿”å›é”™è¯¯ç»“æœ
            return {"error": str(e), "parameters": {"original_input": user_input}}

    # ==================== å®Œæ•´å¤„ç†æµç¨‹ ====================

    def process_input(
        self, user_input: str, confidence_threshold: int = None
    ) -> Dict[str, Any]:
        """å®Œæ•´çš„ä¸¤é˜¶æ®µæ„å›¾å¤„ç†æµç¨‹"""
        debug_utils.log_and_print(
            f"ğŸš€ å¼€å§‹ä¸¤é˜¶æ®µæ„å›¾å¤„ç†: '{user_input[:50]}...'", log_level="INFO"
        )

        # ç¬¬ä¸€é˜¶æ®µï¼šæ„å›¾è¯†åˆ«
        stage1_result = self.recognize_intent_stage1(user_input)
        if "error" in stage1_result:
            return {
                "success": False,
                "error": stage1_result["error"],
                "user_input": user_input,
            }

        # ç¡®å®šä¸»è¦æ„å›¾
        primary_intent, intent_confidence = self.determine_primary_intent(
            stage1_result, confidence_threshold
        )

        final_result = {
            "success": True,
            "user_input": user_input,
            "stage1_intent_scores": stage1_result.get("intent_scores"),
            "other_intent_name": stage1_result.get("other_intent_name"),
            "determined_intent": primary_intent,
            "intent_confidence": intent_confidence,
            "parameters": {},
        }

        # ç¬¬äºŒé˜¶æ®µï¼šå‚æ•°æå–
        stage2_result = self.extract_parameters_stage2(user_input, primary_intent)
        if "error" in stage2_result:
            final_result["parameter_extraction_error"] = stage2_result["error"]
            final_result["parameters"] = stage2_result.get(
                "parameters", {"original_input": user_input}
            )
        else:
            final_result["parameters"] = stage2_result.get("parameters", {})

        debug_utils.log_and_print(
            f"ğŸ¯ æ„å›¾å¤„ç†å®Œæˆ: {primary_intent} (ç½®ä¿¡åº¦: {intent_confidence})",
            log_level="INFO",
        )
        debug_utils.log_and_print(
            f"ğŸ¯ æ„å›¾å¤„ç†æ˜ç»†: \n{final_result}", log_level="INFO"
        )

        return final_result

    def get_supported_intents(self) -> Dict[str, str]:
        """è·å–æ”¯æŒçš„æ„å›¾åˆ—è¡¨"""
        return {name: config["description"] for name, config in self.intents.items()}

    def get_status(self) -> Dict[str, Any]:
        """è·å–å¤„ç†å™¨çŠ¶æ€"""
        return {
            "processor_name": "IntentProcessor",
            "model_name": self.llm_service.model_name if self.llm_service else None,
            "groq_available": (
                hasattr(self.llm_service, "groq_client")
                and self.llm_service.groq_client is not None
                if self.llm_service
                else False
            ),
            "supported_intents": list(self.intents.keys()),
            "intent_count": len(self.intents),
            "confidence_threshold": self.settings.get(
                "default_confidence_threshold", 60
            ),
            "config_loaded": bool(self.intents),
        }
