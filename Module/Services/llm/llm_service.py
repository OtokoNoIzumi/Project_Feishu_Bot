"""
LLMæœåŠ¡ - åŸºäºGoogle Geminiçš„å¤§è¯­è¨€æ¨¡å‹æœåŠ¡

æä¾›ä¸¤é˜¶æ®µæ„å›¾è¯†åˆ«å’Œå‚æ•°æå–åŠŸèƒ½
"""

import os
import json
from typing import Dict, Any
from google import genai
from google.genai import types
from groq import Groq
from Module.Common.scripts.common import debug_utils
from .intent_processor import IntentProcessor


class LLMService:
    """
    LLMæœåŠ¡ - å°è£…Gemini APIè°ƒç”¨å’Œæ„å›¾å¤„ç†
    """

    def __init__(self, app_controller=None):
        """
        åˆå§‹åŒ–LLMæœåŠ¡

        Args:
            app_controller: åº”ç”¨æ§åˆ¶å™¨ï¼Œç”¨äºè·å–é…ç½®
        """
        self.app_controller = app_controller
        self.client = None
        self.model_name = None
        self.api_key = None
        self.groq_client = None
        self.groq_model_name = None
        self.groq_api_key = None
        self.intent_processor = None

        # åˆå§‹åŒ–é…ç½®
        self._init_config()

        # åˆ›å»ºGeminiå®¢æˆ·ç«¯
        self._init_client()

        # åˆ›å»ºGroqå®¢æˆ·ç«¯
        self._init_groq_client()

        # åˆå§‹åŒ–æ„å›¾å¤„ç†å™¨
        self._init_intent_processor()

    def _init_config(self):
        """åˆå§‹åŒ–é…ç½®ï¼ˆç®€æ´ç‰ˆï¼‰"""
        default_model = "gemini-2.5-flash-preview-05-20"
        default_groq_model = "openai/gpt-oss-120b"
        try:
            config_service = None
            if self.app_controller:
                config_service = self.app_controller.get_service("config")

            if config_service:
                # Geminié…ç½®
                self.model_name = config_service.get("GEMINI_MODEL_NAME", default_model)
                self.api_key = config_service.get_env("GEMINI_API_KEY")

                # Groqé…ç½®
                self.groq_model_name = config_service.get(
                    "GROQ_MODEL_NAME", default_groq_model
                )
                self.groq_api_key = config_service.get_env("GROQ_API_KEY")

                log_level = "DEBUG"
                msg = "ğŸ“‹ LLMé…ç½®åŠ è½½æˆåŠŸ"
            else:
                # Geminié…ç½®
                self.model_name = default_model
                self.api_key = os.getenv("GEMINI_API_KEY")

                # Groqé…ç½®
                self.groq_model_name = default_groq_model
                self.groq_api_key = os.getenv("GROQ_API_KEY")

                msg = (
                    "âš ï¸ é…ç½®æœåŠ¡ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®"
                    if self.app_controller
                    else "âš ï¸ æ— åº”ç”¨æ§åˆ¶å™¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®"
                )
                log_level = "WARNING"

            debug_utils.log_and_print(
                f"{msg}: Geminiæ¨¡å‹={self.model_name}, Gemini APIå¯†é’¥={'å·²è®¾ç½®' if self.api_key else 'æœªè®¾ç½®'}, "
                f"Groqæ¨¡å‹={self.groq_model_name}, Groq APIå¯†é’¥={'å·²è®¾ç½®' if self.groq_api_key else 'æœªè®¾ç½®'}",
                log_level=log_level,
            )
        except Exception as e:
            debug_utils.log_and_print(f"âŒ LLMé…ç½®åˆå§‹åŒ–å¤±è´¥: {e}", log_level="ERROR")
            self.model_name = default_model
            self.api_key = os.getenv("GEMINI_API_KEY")
            self.groq_model_name = default_groq_model
            self.groq_api_key = os.getenv("GROQ_API_KEY")

    def _init_client(self):
        """åˆå§‹åŒ–Geminiå®¢æˆ·ç«¯"""
        try:
            if not self.api_key:
                raise ValueError("æœªæä¾›Gemini APIå¯†é’¥ï¼Œè¯·è®¾ç½® GEMINI_API_KEY ç¯å¢ƒå˜é‡")

            self.client = genai.Client(api_key=self.api_key)
            debug_utils.log_and_print(
                f"âœ… Geminiå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {self.model_name}", log_level="INFO"
            )

        except Exception as e:
            debug_utils.log_and_print(
                f"âŒ Geminiå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}", log_level="ERROR"
            )
            self.client = None

    def _init_groq_client(self):
        """åˆå§‹åŒ–Groqå®¢æˆ·ç«¯"""
        try:
            if not self.groq_api_key:
                debug_utils.log_and_print(
                    "âš ï¸ æœªæä¾›Groq APIå¯†é’¥ï¼Œè·³è¿‡Groqå®¢æˆ·ç«¯åˆå§‹åŒ–", log_level="WARNING"
                )
                self.groq_client = None
                return

            self.groq_client = Groq(api_key=self.groq_api_key)
            debug_utils.log_and_print(
                f"âœ… Groqå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {self.groq_model_name}",
                log_level="INFO",
            )

        except Exception as e:
            debug_utils.log_and_print(
                f"âŒ Groqå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}", log_level="ERROR"
            )
            self.groq_client = None

    def _init_intent_processor(self):
        """åˆå§‹åŒ–æ„å›¾å¤„ç†å™¨"""
        try:
            if self.client and self.model_name:
                self.intent_processor = IntentProcessor(llm_service=self)
                debug_utils.log_and_print("âœ… æ„å›¾å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ", log_level="DEBUG")
            else:
                debug_utils.log_and_print(
                    "âš ï¸ æ— æ³•åˆå§‹åŒ–æ„å›¾å¤„ç†å™¨ï¼šLLMå®¢æˆ·ç«¯ä¸å¯ç”¨", log_level="WARNING"
                )
                self.intent_processor = None
        except Exception as e:
            debug_utils.log_and_print(
                f"âŒ æ„å›¾å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}", log_level="ERROR"
            )
            self.intent_processor = None

    def is_available(self) -> bool:
        """æ£€æŸ¥LLMæœåŠ¡æ˜¯å¦å¯ç”¨"""
        return self.client is not None and self.intent_processor is not None

    def process_input_advanced(
        self, user_input: str, confidence_threshold: int = None
    ) -> Dict[str, Any]:
        """
        é«˜çº§æ„å›¾å¤„ç†æ¥å£ï¼ˆå®Œæ•´çš„ä¸¤é˜¶æ®µç»“æœï¼‰

        Args:
            user_input: ç”¨æˆ·è¾“å…¥å†…å®¹
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼

        Returns:
            Dict[str, Any]: å®Œæ•´çš„å¤„ç†ç»“æœ
        """
        if not self.is_available():
            return {"success": False, "error": "LLMæœåŠ¡ä¸å¯ç”¨"}

        return self.intent_processor.process_input(user_input, confidence_threshold)

    def get_supported_intents(self) -> Dict[str, str]:
        """è·å–æ”¯æŒçš„æ„å›¾åˆ—è¡¨"""
        if self.intent_processor:
            return self.intent_processor.get_supported_intents()
        return {}

    def simple_chat(self, prompt: str, max_tokens: int = 1500) -> str:
        """
        ç®€å•çš„èŠå¤©æ¥å£ï¼Œç”¨äºé€šç”¨æ–‡æœ¬ç”Ÿæˆ

        Args:
            prompt: è¾“å…¥çš„æç¤ºè¯
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°

        Returns:
            str: ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹
        """
        if not self.client:
            return "LLMå®¢æˆ·ç«¯ä¸å¯ç”¨"

        try:
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=[{"role": "user", "parts": [{"text": prompt}]}],
                config={
                    "thinking_config": types.ThinkingConfig(
                        thinking_budget=-1,
                    ),
                    "temperature": 0.7,
                    "max_output_tokens": max_tokens,
                },
            )
            return response.text
        except Exception as e:
            debug_utils.log_and_print(
                f"âŒ simple_chat è°ƒç”¨å¤±è´¥: {e}", log_level="ERROR"
            )
            return f"æ–‡æœ¬ç”Ÿæˆå¤±è´¥: {e}"

    def structured_call(
        self,
        prompt: str,
        response_schema: Dict[str, Any],
        system_instruction: str = None,
        temperature: float = 0.95,
        thinking_budget: int = 0,
    ) -> Dict[str, Any]:
        """
        ç»“æ„åŒ–è°ƒç”¨æ¥å£ï¼Œæ”¯æŒJSON schemaå’Œç³»ç»Ÿæç¤ºè¯

        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            response_schema: JSONå“åº”schema
            system_instruction: ç³»ç»Ÿæç¤ºè¯
            temperature: æ¸©åº¦å‚æ•°
            thinking_budget: æ€è€ƒé¢„ç®—

        Returns:
            Dict[str, Any]: ç»“æ„åŒ–å“åº”ç»“æœ
        """
        if not self.client:
            return {"error": "LLMå®¢æˆ·ç«¯ä¸å¯ç”¨"}

        try:
            # æ„å»ºè¯·æ±‚å†…å®¹
            contents = [{"role": "user", "parts": [{"text": prompt}]}]

            # æ„å»ºé…ç½®
            config = {
                "response_mime_type": "application/json",
                "response_schema": response_schema,
                "thinking_config": types.ThinkingConfig(
                    thinking_budget=thinking_budget,
                ),
                "temperature": temperature,
            }

            # å¦‚æœæœ‰ç³»ç»Ÿæç¤ºè¯ï¼Œæ·»åŠ åˆ°é…ç½®ä¸­
            if system_instruction:
                config["system_instruction"] = system_instruction

            response = self.client.models.generate_content(
                model=self.model_name, contents=contents, config=config
            )

            # å°è¯•è§£æJSONå“åº”
            return json.loads(response.text)

        except json.JSONDecodeError as e:
            debug_utils.log_and_print(
                f"âŒ JSONè§£æå¤±è´¥: {e}, å“åº”å†…å®¹: {response.text[:200] if 'response' in locals() else 'None'}",
                log_level="ERROR",
            )
            return {"error": f"JSONè§£æå¤±è´¥: {e}"}
        except Exception as e:
            debug_utils.log_and_print(
                f"âŒ structured_call è°ƒç”¨å¤±è´¥: {e}", log_level="ERROR"
            )
            return {"error": f"ç»“æ„åŒ–è°ƒç”¨å¤±è´¥: {e}"}

    def router_structured_call(
        self,
        prompt: str,
        response_schema: Dict[str, Any],
        system_instruction: str = None,
        temperature: float = 0.95,
    ) -> Dict[str, Any]:
        """
        è·¯ç”±ä¸“ç”¨çš„ç»“æ„åŒ–è°ƒç”¨ï¼Œä¼˜å…ˆä½¿ç”¨Groqï¼Œå›é€€åˆ°Gemini

        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            response_schema: JSONå“åº”schema
            system_instruction: ç³»ç»Ÿæç¤ºè¯
            temperature: æ¸©åº¦å‚æ•°

        Returns:
            Dict[str, Any]: ç»“æ„åŒ–å“åº”ç»“æœ
        """
        # ä¼˜å…ˆå°è¯•Groq
        if self.groq_client:
            try:
                debug_utils.log_and_print(
                    "ğŸš€ ä½¿ç”¨Groqè¿›è¡Œrouter_structured_call", log_level="DEBUG"
                )
                return self._call_groq_structured(
                    prompt, response_schema, system_instruction, temperature
                )
            except Exception as e:
                debug_utils.log_and_print(
                    f"âš ï¸ Groqè°ƒç”¨å¤±è´¥ï¼Œå›é€€åˆ°Gemini: {e}", log_level="WARNING"
                )

        # å›é€€åˆ°Gemini
        debug_utils.log_and_print(
            "ğŸ”„ å›é€€åˆ°Geminiè¿›è¡Œrouter_structured_call", log_level="DEBUG"
        )
        return self.structured_call(
            prompt, response_schema, system_instruction, temperature
        )

    def _call_groq_structured(
        self,
        prompt: str,
        response_schema: Dict[str, Any],
        system_instruction: str = None,
        temperature: float = 0.95,
    ) -> Dict[str, Any]:
        """
        Groq APIè°ƒç”¨å®ç°

        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            response_schema: JSONå“åº”schema
            system_instruction: ç³»ç»Ÿæç¤ºè¯
            temperature: æ¸©åº¦å‚æ•°

        Returns:
            Dict[str, Any]: ç»“æ„åŒ–å“åº”ç»“æœ
        """
        try:
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = []
            if system_instruction:
                messages.append({"role": "system", "content": system_instruction})
            messages.append({"role": "user", "content": prompt})

            # è°ƒç”¨Groq API
            response = self.groq_client.chat.completions.create(
                model=self.groq_model_name,
                messages=messages,
                response_format={
                    "type": "json_schema",
                    "json_schema": {"name": "response", "schema": response_schema},
                },
                temperature=temperature,
            )

            # è§£æJSONå“åº”
            result = json.loads(response.choices[0].message.content)
            debug_utils.log_and_print("âœ… Groq APIè°ƒç”¨æˆåŠŸ", log_level="DEBUG")
            return result

        except json.JSONDecodeError as e:
            debug_utils.log_and_print(
                f"âŒ Groq JSONè§£æå¤±è´¥: {e}, å“åº”å†…å®¹: {response.choices[0].message.content[:200] if 'response' in locals() else 'None'}",
                log_level="ERROR",
            )
            raise Exception(f"Groq JSONè§£æå¤±è´¥: {e}")
        except Exception as e:
            debug_utils.log_and_print(f"âŒ Groq APIè°ƒç”¨å¤±è´¥: {e}", log_level="ERROR")
            raise Exception(f"Groq APIè°ƒç”¨å¤±è´¥: {e}")

    def get_status(self) -> Dict[str, Any]:
        """è·å–LLMæœåŠ¡çŠ¶æ€"""
        status = {
            "service_name": "LLMService",
            "model_name": self.model_name,
            "available": self.is_available(),
            "api_key_configured": bool(self.api_key),
            "client_initialized": self.client is not None,
            "intent_processor_initialized": self.intent_processor is not None,
            "groq_available": bool(self.groq_client),
            "groq_model": self.groq_model_name,
            "groq_api_key_configured": bool(self.groq_api_key),
            "groq_client_initialized": self.groq_client is not None,
        }

        if self.intent_processor:
            processor_status = self.intent_processor.get_status()
            status.update(
                {
                    "supported_intents": processor_status.get("supported_intents", []),
                    "intent_count": processor_status.get("intent_count", 0),
                    "confidence_threshold": processor_status.get(
                        "confidence_threshold", 60
                    ),
                }
            )

        return status
