"""
LLMæœåŠ¡ - åŸºäºGoogle Geminiçš„å¤§è¯­è¨€æ¨¡å‹æœåŠ¡

æä¾›ä¸¤é˜¶æ®µæ„å›¾è¯†åˆ«å’Œå‚æ•°æå–åŠŸèƒ½
"""

import os
from typing import Dict, Any
from google import genai
from google.genai import types
from Module.Common.scripts.common import debug_utils
from .intent_processor import IntentProcessor


class LLMService:
    """
    LLMæœåŠ¡ - å°è£…Gemini APIè°ƒç”¨å’Œæ„å›¾å¤„ç†
    """

    def __init__(self, app_controller=None):
        """
        åˆå§‹åŒ–LLMæœåŠ¡

        Args:
            app_controller: åº”ç”¨æ§åˆ¶å™¨ï¼Œç”¨äºè·å–é…ç½®
        """
        self.app_controller = app_controller
        self.client = None
        self.model_name = None
        self.api_key = None
        self.intent_processor = None

        # åˆå§‹åŒ–é…ç½®
        self._init_config()

        # åˆ›å»ºGeminiå®¢æˆ·ç«¯
        self._init_client()

        # åˆå§‹åŒ–æ„å›¾å¤„ç†å™¨
        self._init_intent_processor()

    def _init_config(self):
        """åˆå§‹åŒ–é…ç½®ï¼ˆç®€æ´ç‰ˆï¼‰"""
        default_model = 'gemini-2.5-flash-preview-05-20'
        try:
            config_service = None
            if self.app_controller:
                config_service = self.app_controller.get_service('config')

            if config_service:
                self.model_name = config_service.get('GEMINI_MODEL_NAME', default_model)
                self.api_key = config_service.get_env('GEMINI_API_KEY')
                log_level = "DEBUG"
                msg = "ğŸ“‹ LLMé…ç½®åŠ è½½æˆåŠŸ"
            else:
                self.model_name = default_model
                self.api_key = os.getenv('GEMINI_API_KEY')
                msg = "âš ï¸ é…ç½®æœåŠ¡ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®" if self.app_controller else "âš ï¸ æ— åº”ç”¨æ§åˆ¶å™¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®"
                log_level = "WARNING"

            debug_utils.log_and_print(
                f"{msg}: æ¨¡å‹={self.model_name}, APIå¯†é’¥={'å·²è®¾ç½®' if self.api_key else 'æœªè®¾ç½®'}",
                log_level=log_level
            )
        except Exception as e:
            debug_utils.log_and_print(f"âŒ LLMé…ç½®åˆå§‹åŒ–å¤±è´¥: {e}", log_level="ERROR")
            self.model_name = default_model
            self.api_key = os.getenv('GEMINI_API_KEY')

    def _init_client(self):
        """åˆå§‹åŒ–Geminiå®¢æˆ·ç«¯"""
        try:
            if not self.api_key:
                raise ValueError("æœªæä¾›Gemini APIå¯†é’¥ï¼Œè¯·è®¾ç½® GEMINI_API_KEY ç¯å¢ƒå˜é‡")

            self.client = genai.Client(api_key=self.api_key)
            debug_utils.log_and_print(f"âœ… LLMæœåŠ¡åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {self.model_name}", log_level="INFO")

        except Exception as e:
            debug_utils.log_and_print(f"âŒ LLMæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}", log_level="ERROR")
            self.client = None

    def _init_intent_processor(self):
        """åˆå§‹åŒ–æ„å›¾å¤„ç†å™¨"""
        try:
            if self.client and self.model_name:
                self.intent_processor = IntentProcessor(
                    llm_client=self.client,
                    model_name=self.model_name
                )
                debug_utils.log_and_print("âœ… æ„å›¾å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ", log_level="DEBUG")
            else:
                debug_utils.log_and_print("âš ï¸ æ— æ³•åˆå§‹åŒ–æ„å›¾å¤„ç†å™¨ï¼šLLMå®¢æˆ·ç«¯ä¸å¯ç”¨", log_level="WARNING")
                self.intent_processor = None
        except Exception as e:
            debug_utils.log_and_print(f"âŒ æ„å›¾å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}", log_level="ERROR")
            self.intent_processor = None

    def is_available(self) -> bool:
        """æ£€æŸ¥LLMæœåŠ¡æ˜¯å¦å¯ç”¨"""
        return self.client is not None and self.intent_processor is not None

    def process_input_advanced(self, user_input: str, confidence_threshold: int = None) -> Dict[str, Any]:
        """
        é«˜çº§æ„å›¾å¤„ç†æ¥å£ï¼ˆå®Œæ•´çš„ä¸¤é˜¶æ®µç»“æœï¼‰

        Args:
            user_input: ç”¨æˆ·è¾“å…¥å†…å®¹
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼

        Returns:
            Dict[str, Any]: å®Œæ•´çš„å¤„ç†ç»“æœ
        """
        if not self.is_available():
            return {
                'success': False,
                'error': 'LLMæœåŠ¡ä¸å¯ç”¨'
            }

        return self.intent_processor.process_input(user_input, confidence_threshold)

    def get_supported_intents(self) -> Dict[str, str]:
        """è·å–æ”¯æŒçš„æ„å›¾åˆ—è¡¨"""
        if self.intent_processor:
            return self.intent_processor.get_supported_intents()
        return {}

    def simple_chat(self, prompt: str, max_tokens: int = 1500) -> str:
        """
        ç®€å•çš„èŠå¤©æ¥å£ï¼Œç”¨äºé€šç”¨æ–‡æœ¬ç”Ÿæˆ

        Args:
            prompt: è¾“å…¥çš„æç¤ºè¯
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°

        Returns:
            str: ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹
        """
        if not self.client:
            return "LLMå®¢æˆ·ç«¯ä¸å¯ç”¨"

        try:
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=[{
                    'role': 'user',
                    'parts': [{'text': prompt}]
                }],
                config={
                    "thinking_config": types.ThinkingConfig(
                        thinking_budget=-1,
                    ),
                    'temperature': 0.7,
                    'max_output_tokens': max_tokens
                }
            )
            return response.text
        except Exception as e:
            debug_utils.log_and_print(f"âŒ simple_chat è°ƒç”¨å¤±è´¥: {e}", log_level="ERROR")
            return f"æ–‡æœ¬ç”Ÿæˆå¤±è´¥: {e}"

    def get_status(self) -> Dict[str, Any]:
        """è·å–LLMæœåŠ¡çŠ¶æ€"""
        status = {
            "service_name": "LLMService",
            "model_name": self.model_name,
            "available": self.is_available(),
            "api_key_configured": bool(self.api_key),
            "client_initialized": self.client is not None,
            "intent_processor_initialized": self.intent_processor is not None
        }

        if self.intent_processor:
            processor_status = self.intent_processor.get_status()
            status.update({
                "supported_intents": processor_status.get("supported_intents", []),
                "intent_count": processor_status.get("intent_count", 0),
                "confidence_threshold": processor_status.get("confidence_threshold", 60)
            })

        return status