"""
LLMÊúçÂä° - Âü∫‰∫éGoogle GeminiÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊúçÂä°

Êèê‰æõ‰∏§Èò∂ÊÆµÊÑèÂõæËØÜÂà´ÂíåÂèÇÊï∞ÊèêÂèñÂäüËÉΩ
"""

import os
import json
from typing import Dict, Any
from google import genai
from google.genai import types
from groq import Groq
from Module.Common.scripts.common import debug_utils
from .intent_processor import IntentProcessor


class LLMService:
    """
    LLMÊúçÂä° - Â∞ÅË£ÖGemini APIË∞ÉÁî®ÂíåÊÑèÂõæÂ§ÑÁêÜ
    """

    # region ÂàùÂßãÂåñ

    def __init__(self, app_controller=None):
        """
        ÂàùÂßãÂåñLLMÊúçÂä°

        Args:
            app_controller: Â∫îÁî®ÊéßÂà∂Âô®ÔºåÁî®‰∫éËé∑ÂèñÈÖçÁΩÆ
        """
        self.app_controller = app_controller
        self.client = None
        self.model_name = None
        self.api_key = None
        self.groq_client = None
        self.groq_model_name = None
        self.groq_api_key = None
        self.intent_processor = None

        # ÂàùÂßãÂåñÈÖçÁΩÆ
        self._init_config()

        # ÂàõÂª∫GeminiÂÆ¢Êà∑Á´Ø
        self._init_client()

        # ÂàõÂª∫GroqÂÆ¢Êà∑Á´Ø
        self._init_groq_client()

        # ÂàùÂßãÂåñÊÑèÂõæÂ§ÑÁêÜÂô®
        self._init_intent_processor()

    def _init_config(self):
        """ÂàùÂßãÂåñÈÖçÁΩÆÔºàÁÆÄÊ¥ÅÁâàÔºâ"""
        default_model = "gemini-2.5-flash"
        # default_model = "gemini-2.5-pro"
        default_groq_model = "openai/gpt-oss-120b"
        try:
            config_service = None
            if self.app_controller:
                config_service = self.app_controller.get_service("config")

            if config_service:
                # GeminiÈÖçÁΩÆ
                self.model_name = config_service.get("GEMINI_MODEL_NAME", default_model)
                self.api_key = config_service.get_env("GEMINI_API_KEY")

                # GroqÈÖçÁΩÆ
                self.groq_model_name = config_service.get(
                    "GROQ_MODEL_NAME", default_groq_model
                )
                self.groq_api_key = config_service.get_env("GROQ_API_KEY")

                log_level = "DEBUG"
                msg = "üìã LLMÈÖçÁΩÆÂä†ËΩΩÊàêÂäü"
            else:
                # GeminiÈÖçÁΩÆ
                self.model_name = default_model
                self.api_key = os.getenv("GEMINI_API_KEY")

                # GroqÈÖçÁΩÆ
                self.groq_model_name = default_groq_model
                self.groq_api_key = os.getenv("GROQ_API_KEY")

                msg = (
                    "‚ö†Ô∏è ÈÖçÁΩÆÊúçÂä°‰∏çÂèØÁî®Ôºå‰ΩøÁî®ÈªòËÆ§ÈÖçÁΩÆ"
                    if self.app_controller
                    else "‚ö†Ô∏è Êó†Â∫îÁî®ÊéßÂà∂Âô®Ôºå‰ΩøÁî®ÈªòËÆ§ÈÖçÁΩÆ"
                )
                log_level = "WARNING"

            debug_utils.log_and_print(
                f"{msg}: GeminiÊ®°Âûã={self.model_name}, Gemini APIÂØÜÈí•={'Â∑≤ËÆæÁΩÆ' if self.api_key else 'Êú™ËÆæÁΩÆ'}, "
                f"GroqÊ®°Âûã={self.groq_model_name}, Groq APIÂØÜÈí•={'Â∑≤ËÆæÁΩÆ' if self.groq_api_key else 'Êú™ËÆæÁΩÆ'}",
                log_level=log_level,
            )
        except Exception as e:
            debug_utils.log_and_print(f"‚ùå LLMÈÖçÁΩÆÂàùÂßãÂåñÂ§±Ë¥•: {e}", log_level="ERROR")
            self.model_name = default_model
            self.api_key = os.getenv("GEMINI_API_KEY")
            self.groq_model_name = default_groq_model
            self.groq_api_key = os.getenv("GROQ_API_KEY")

    def _init_client(self):
        """ÂàùÂßãÂåñGeminiÂÆ¢Êà∑Á´Ø"""
        try:
            if not self.api_key:
                raise ValueError("Êú™Êèê‰æõGemini APIÂØÜÈí•ÔºåËØ∑ËÆæÁΩÆ GEMINI_API_KEY ÁéØÂ¢ÉÂèòÈáè")

            self.client = genai.Client(api_key=self.api_key)
            debug_utils.log_and_print(
                f"‚úÖ GeminiÂÆ¢Êà∑Á´ØÂàùÂßãÂåñÊàêÂäüÔºåÊ®°Âûã: {self.model_name}", log_level="INFO"
            )

        except Exception as e:
            debug_utils.log_and_print(
                f"‚ùå GeminiÂÆ¢Êà∑Á´ØÂàùÂßãÂåñÂ§±Ë¥•: {e}", log_level="ERROR"
            )
            self.client = None

    def _init_groq_client(self):
        """ÂàùÂßãÂåñGroqÂÆ¢Êà∑Á´Ø"""
        try:
            if not self.groq_api_key:
                debug_utils.log_and_print(
                    "‚ö†Ô∏è Êú™Êèê‰æõGroq APIÂØÜÈí•ÔºåË∑≥ËøáGroqÂÆ¢Êà∑Á´ØÂàùÂßãÂåñ", log_level="WARNING"
                )
                self.groq_client = None
                return

            self.groq_client = Groq(api_key=self.groq_api_key)
            debug_utils.log_and_print(
                f"‚úÖ GroqÂÆ¢Êà∑Á´ØÂàùÂßãÂåñÊàêÂäüÔºåÊ®°Âûã: {self.groq_model_name}",
                log_level="INFO",
            )

        except Exception as e:
            debug_utils.log_and_print(
                f"‚ùå GroqÂÆ¢Êà∑Á´ØÂàùÂßãÂåñÂ§±Ë¥•: {e}", log_level="ERROR"
            )
            self.groq_client = None

    def _init_intent_processor(self):
        """ÂàùÂßãÂåñÊÑèÂõæÂ§ÑÁêÜÂô®"""
        try:
            if self.client and self.model_name:
                self.intent_processor = IntentProcessor(
                    llm_service=self, app_controller=self.app_controller
                )
                debug_utils.log_and_print("‚úÖ ÊÑèÂõæÂ§ÑÁêÜÂô®ÂàùÂßãÂåñÊàêÂäü", log_level="DEBUG")
            else:
                debug_utils.log_and_print(
                    "‚ö†Ô∏è Êó†Ê≥ïÂàùÂßãÂåñÊÑèÂõæÂ§ÑÁêÜÂô®ÔºöLLMÂÆ¢Êà∑Á´Ø‰∏çÂèØÁî®", log_level="WARNING"
                )
                self.intent_processor = None
        except Exception as e:
            debug_utils.log_and_print(
                f"‚ùå ÊÑèÂõæÂ§ÑÁêÜÂô®ÂàùÂßãÂåñÂ§±Ë¥•: {e}", log_level="ERROR"
            )
            self.intent_processor = None

    def is_available(self) -> bool:
        """Ê£ÄÊü•LLMÊúçÂä°ÊòØÂê¶ÂèØÁî®"""
        return self.client is not None and self.intent_processor is not None

    # endregion

    # region Ê®°ÂùóË∞ÉÁî®

    # È´òÁ∫ßÊÑèÂõæÂ§ÑÁêÜ
    def process_input_advanced(
        self, user_input: str, confidence_threshold: int = None
    ) -> Dict[str, Any]:
        """
        È´òÁ∫ßÊÑèÂõæÂ§ÑÁêÜÊé•Âè£ÔºàÂÆåÊï¥ÁöÑ‰∏§Èò∂ÊÆµÁªìÊûúÔºâ

        Args:
            user_input: Áî®Êà∑ËæìÂÖ•ÂÜÖÂÆπ
            confidence_threshold: ÁΩÆ‰ø°Â∫¶ÈòàÂÄº

        Returns:
            Dict[str, Any]: ÂÆåÊï¥ÁöÑÂ§ÑÁêÜÁªìÊûú
        """
        if not self.is_available():
            return {"success": False, "error": "LLMÊúçÂä°‰∏çÂèØÁî®"}

        return self.intent_processor.process_input(user_input, confidence_threshold)

    def get_supported_intents(self) -> Dict[str, str]:
        """Ëé∑ÂèñÊîØÊåÅÁöÑÊÑèÂõæÂàóË°®"""
        if self.intent_processor:
            return self.intent_processor.get_supported_intents()
        return {}

    # STTÊÑèÂõæÂ§ÑÁêÜ

    def process_stt_input(self, user_input: str, user_id: str) -> Dict[str, Any]:
        """Â§ÑÁêÜSTTËæìÂÖ•"""
        return self.intent_processor.process_stt_input(user_input, user_id)

    # endregion

    # region llmË∞ÉÁî®ÊñπÊ≥ï

    def simple_chat(self, prompt: str, max_tokens: int = 1500) -> str:
        """
        ÁÆÄÂçïÁöÑËÅäÂ§©Êé•Âè£ÔºåÁî®‰∫éÈÄöÁî®ÊñáÊú¨ÁîüÊàê

        Args:
            prompt: ËæìÂÖ•ÁöÑÊèêÁ§∫ËØç
            max_tokens: ÊúÄÂ§ßÁîüÊàêtokenÊï∞

        Returns:
            str: ÁîüÊàêÁöÑÊñáÊú¨ÂÜÖÂÆπ
        """
        if not self.client:
            return "LLMÂÆ¢Êà∑Á´Ø‰∏çÂèØÁî®"

        try:
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=[{"role": "user", "parts": [{"text": prompt}]}],
                config={
                    "thinking_config": types.ThinkingConfig(
                        thinking_budget=0,  # -1Ë°®Á§∫Âä®ÊÄÅÊÄùËÄÉÔºåÁÆÄÂçïËÅäÂ§©ÊàñËÆ∏Ê≤°ÂøÖË¶ÅÊÄùËÄÉ
                    ),
                    "temperature": 0.7,
                    "max_output_tokens": max_tokens,
                },
            )
            return response.text
        except Exception as e:
            debug_utils.log_and_print(
                f"‚ùå simple_chat Ë∞ÉÁî®Â§±Ë¥•: {e}", log_level="ERROR"
            )
            return f"ÊñáÊú¨ÁîüÊàêÂ§±Ë¥•: {e}"

    def get_stream_completion(
        self, prompt: str, system_instruction: str = None, max_tokens: int = 1500
    ):
        """
        Ëé∑ÂèñÊµÅÂºèÂÆåÊàê
        """
        if not self.client:
            return "LLMÂÆ¢Êà∑Á´Ø‰∏çÂèØÁî®"

        generate_config = types.GenerateContentConfig(
            safety_settings=get_safety_settings()
        )
        generate_config.thinking_config = types.ThinkingConfig(
            thinking_budget=800,
            include_thoughts=True,
        )
        generate_config.temperature = 0.95
        generate_config.max_output_tokens = max_tokens
        if system_instruction:
            generate_config.system_instruction = system_instruction

        stream_completion = self.client.models.generate_content_stream(
            model=self.model_name,
            contents=[{"role": "user", "parts": [{"text": prompt}]}],
            config=generate_config,
        )

        return stream_completion

    def structured_call(
        self,
        prompt: str,
        response_schema: Dict[str, Any],
        system_instruction: str = None,
        temperature: float = 0.95,
        thinking_budget: int = 0,
    ) -> Dict[str, Any]:
        """
        ÁªìÊûÑÂåñË∞ÉÁî®Êé•Âè£ÔºåÊîØÊåÅJSON schemaÂíåÁ≥ªÁªüÊèêÁ§∫ËØç

        Args:
            prompt: Áî®Êà∑ÊèêÁ§∫ËØç
            response_schema: JSONÂìçÂ∫îschema
            system_instruction: Á≥ªÁªüÊèêÁ§∫ËØç
            temperature: Ê∏©Â∫¶ÂèÇÊï∞
            thinking_budget: ÊÄùËÄÉÈ¢ÑÁÆó

        Returns:
            Dict[str, Any]: ÁªìÊûÑÂåñÂìçÂ∫îÁªìÊûú
        """
        if not self.client:
            return {"error": "LLMÂÆ¢Êà∑Á´Ø‰∏çÂèØÁî®"}

        try:
            # ÊûÑÂª∫ËØ∑Ê±ÇÂÜÖÂÆπ
            contents = [{"role": "user", "parts": [{"text": prompt}]}]

            # ÊûÑÂª∫ÈÖçÁΩÆ
            config = {
                "response_mime_type": "application/json",
                "response_schema": response_schema,
                "thinking_config": types.ThinkingConfig(
                    thinking_budget=thinking_budget,
                ),
                "temperature": temperature,
            }

            # Â¶ÇÊûúÊúâÁ≥ªÁªüÊèêÁ§∫ËØçÔºåÊ∑ªÂä†Âà∞ÈÖçÁΩÆ‰∏≠
            if system_instruction:
                config["system_instruction"] = system_instruction

            response = self.client.models.generate_content(
                model=self.model_name, contents=contents, config=config
            )

            # Â∞ùËØïËß£ÊûêJSONÂìçÂ∫î
            return json.loads(response.text)

        except json.JSONDecodeError as e:
            debug_utils.log_and_print(
                f"‚ùå JSONËß£ÊûêÂ§±Ë¥•: {e}, ÂìçÂ∫îÂÜÖÂÆπ: {response.text[:200] if 'response' in locals() else 'None'}",
                log_level="ERROR",
            )
            return {"error": f"JSONËß£ÊûêÂ§±Ë¥•: {e}"}
        except Exception as e:
            debug_utils.log_and_print(
                f"‚ùå structured_call Ë∞ÉÁî®Â§±Ë¥•: {e}", log_level="ERROR"
            )
            return {"error": f"ÁªìÊûÑÂåñË∞ÉÁî®Â§±Ë¥•: {e}"}

    def _call_groq_structured(
        self,
        prompt: str,
        response_schema: Dict[str, Any],
        system_instruction: str = None,
        temperature: float = 0.95,
    ) -> Dict[str, Any]:
        """
        Groq APIË∞ÉÁî®ÂÆûÁé∞

        Args:
            prompt: Áî®Êà∑ÊèêÁ§∫ËØç
            response_schema: JSONÂìçÂ∫îschema
            system_instruction: Á≥ªÁªüÊèêÁ§∫ËØç
            temperature: Ê∏©Â∫¶ÂèÇÊï∞

        Returns:
            Dict[str, Any]: ÁªìÊûÑÂåñÂìçÂ∫îÁªìÊûú
        """
        try:
            # ÊûÑÂª∫Ê∂àÊÅØÂàóË°®
            messages = []
            if system_instruction:
                messages.append({"role": "system", "content": system_instruction})
            messages.append({"role": "user", "content": prompt})

            # Ë∞ÉÁî®Groq API
            response = self.groq_client.chat.completions.create(
                model=self.groq_model_name,
                messages=messages,
                response_format={
                    "type": "json_schema",
                    "json_schema": {"name": "response", "schema": response_schema},
                },
                temperature=temperature,
            )

            # Ëß£ÊûêJSONÂìçÂ∫î
            result = json.loads(response.choices[0].message.content)
            return result

        except json.JSONDecodeError as e:
            debug_utils.log_and_print(
                f"‚ùå Groq JSONËß£ÊûêÂ§±Ë¥•: {e}, ÂìçÂ∫îÂÜÖÂÆπ: {response.choices[0].message.content[:200] if 'response' in locals() else 'None'}",
                log_level="ERROR",
            )
            raise Exception(f"Groq JSONËß£ÊûêÂ§±Ë¥•: {e}")
        except Exception as e:
            debug_utils.log_and_print(f"‚ùå Groq APIË∞ÉÁî®Â§±Ë¥•: {e}", log_level="ERROR")
            raise Exception(f"Groq APIË∞ÉÁî®Â§±Ë¥•: {e}")

    def router_structured_call(
        self,
        prompt: str,
        response_schema: Dict[str, Any],
        system_instruction: str = None,
        temperature: float = 0.95,
    ) -> Dict[str, Any]:
        """
        Ë∑ØÁî±‰∏ìÁî®ÁöÑÁªìÊûÑÂåñË∞ÉÁî®Ôºå‰ºòÂÖà‰ΩøÁî®GroqÔºåÂõûÈÄÄÂà∞Gemini

        Args:
            prompt: Áî®Êà∑ÊèêÁ§∫ËØç
            response_schema: JSONÂìçÂ∫îschema
            system_instruction: Á≥ªÁªüÊèêÁ§∫ËØç
            temperature: Ê∏©Â∫¶ÂèÇÊï∞

        Returns:
            Dict[str, Any]: ÁªìÊûÑÂåñÂìçÂ∫îÁªìÊûú
        """
        # ‰ºòÂÖàÂ∞ùËØïGroq
        if self.groq_client:
            try:
                return self._call_groq_structured(
                    prompt, response_schema, system_instruction, temperature
                )
            except Exception as e:
                debug_utils.log_and_print(
                    f"‚ö†Ô∏è GroqË∞ÉÁî®Â§±Ë¥•ÔºåÂõûÈÄÄÂà∞Gemini: {e}", log_level="WARNING"
                )

        # ÂõûÈÄÄÂà∞Gemini
        debug_utils.log_and_print(
            "üîÑ ÂõûÈÄÄÂà∞GeminiËøõË°årouter_structured_call", log_level="DEBUG"
        )
        return self.structured_call(
            prompt, response_schema, system_instruction, temperature
        )

    # endregion

    # region ËæÖÂä©ÂäüËÉΩ

    def get_status(self) -> Dict[str, Any]:
        """Ëé∑ÂèñLLMÊúçÂä°Áä∂ÊÄÅ"""
        status = {
            "service_name": "LLMService",
            "model_name": self.model_name,
            "available": self.is_available(),
            "api_key_configured": bool(self.api_key),
            "client_initialized": self.client is not None,
            "intent_processor_initialized": self.intent_processor is not None,
            "groq_available": bool(self.groq_client),
            "groq_model": self.groq_model_name,
            "groq_api_key_configured": bool(self.groq_api_key),
            "groq_client_initialized": self.groq_client is not None,
        }

        if self.intent_processor:
            processor_status = self.intent_processor.get_status()
            status.update(
                {
                    "supported_intents": processor_status.get("supported_intents", []),
                    "intent_count": processor_status.get("intent_count", 0),
                    "confidence_threshold": processor_status.get(
                        "confidence_threshold", 60
                    ),
                }
            )

        return status

    # endregion


def get_safety_settings():
    """Ëé∑ÂèñÂÆâÂÖ®ËÆæÁΩÆ"""
    return [
        types.SafetySetting(category="HARM_CATEGORY_HATE_SPEECH", threshold="OFF"),
        types.SafetySetting(
            category="HARM_CATEGORY_DANGEROUS_CONTENT", threshold="OFF"
        ),
        types.SafetySetting(category="HARM_CATEGORY_HARASSMENT", threshold="OFF"),
        types.SafetySetting(
            category="HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold="OFF"
        ),
        types.SafetySetting(category="HARM_CATEGORY_CIVIC_INTEGRITY", threshold="OFF"),
    ]
