"""æ¯æ—¥ä¿¡æ¯æ±‡æ€»ä¸šåŠ¡

å¤„ç†æ¯æ—¥ä¿¡æ¯æ±‡æ€»çš„å®Œæ•´ä¸šåŠ¡é€»è¾‘ï¼ŒåŒ…æ‹¬ï¼š
1. Bç«™ä¿¡æ¯åˆ†ææ•°æ®æ„å»º
2. è¿è¥æ•°æ®è·å–ä¸å¤„ç†
3. æ—¥æŠ¥å¡ç‰‡ç”Ÿæˆ
4. ç”¨æˆ·æƒé™éªŒè¯
"""

import os
from typing import Dict, Any, List
from datetime import datetime, timedelta
import random
import pandas as pd
import numpy as np

from Module.Common.scripts.common import debug_utils
from Module.Services.constants import (
    ServiceNames,
    ResponseTypes,
    SchedulerConstKeys,
    AdapterNames,
    ColorTypes,
)
from Module.Business.processors.base_processor import (
    BaseProcessor,
    ProcessResult,
    require_service,
    safe_execute,
)
from Module.Services.bili_adskip_service import convert_to_bili_app_link
from Module.Business.shared_process import format_time_label
from Module.Business.routine_record import RoutineRecord, wax_stamp_prompt
from Module.Adapters.feishu.cards.json_builder import JsonBuilder


class DailySummaryBusiness(BaseProcessor):
    """
    æ¯æ—¥ä¿¡æ¯æ±‡æ€»ä¸šåŠ¡

    è´Ÿè´£å¤„ç†æ¯æ—¥ä¿¡æ¯æ±‡æ€»çš„å®Œæ•´ä¸šåŠ¡æµç¨‹
    """

    # region åç«¯ä¸šåŠ¡å…¥å£
    # ä¸šåŠ¡å †æ ˆ
    # æ³¨å†Œ
    # main.setup_scheduled_tasks  # å¦‚æœåç»­è¦åŒºåˆ†userï¼Œåœ¨è¿™é‡Œå°±è¦æŠŠuser_idå’Œå„è‡ªçš„æ—¶é—´è®¾ç½®è¿›å»ã€‚è™½ç„¶ç°åœ¨çš„user_idéƒ½æ¥è‡ªé£ä¹¦ï¼Œä½†åº”è¯¥å¯ä»¥ç›´æ¥æ‰©å±•åˆ°å…¶ä»–
    # -> scheduler_service.TaskUtils.get_task_function
    # -> scheduler_service.add_daily_task

    # è§¦å‘
    # è¿™é‡Œserviceå’Œprocessorçš„æ¶æ„æ˜¯æ—§ç‰ˆï¼Œä»¥åé‡æ„
    # ScheduledEventçš„ç»“æ„ä¸å¤Ÿå¥½ï¼Œç›®å‰typeæœ‰ä¸€ä»½å†—ä½™ï¼Œç°åœ¨ä½¿ç”¨çš„æ˜¯dataé‡Œçš„scheduler_type
    # scheduler_service.trigger_daily_schedule_reminder
    # -> main.handle_scheduled_event
    # -> schedule_processor.create_task
    # -> schedule_processor.daily_summary è¿™é‡Œæ›´å¤šåº”è¯¥æ˜¯å®šæ—¶å±æ€§ï¼Œä¸šåŠ¡é›†ä¸­åœ¨ä¸‹é¢
    # -> daily_summary_business.create_daily_summary
    # -> main.handle_scheduled_event

    def __init__(self, app_controller, developer_mode_path=None):
        """åˆå§‹åŒ–æ—¥å¸¸äº‹é¡¹è®°å½•ä¸šåŠ¡"""
        super().__init__(app_controller)
        self.developer_mode_path = developer_mode_path
        if not self.developer_mode_path:
            self.config_service = self.app_controller.get_service(ServiceNames.CONFIG)
            self.routine_business = RoutineRecord(self.app_controller)

    @require_service("bili_adskip", "Bç«™å¹¿å‘Šè·³è¿‡æœåŠ¡ä¸å¯ç”¨")
    @safe_execute("åˆ›å»ºæ¯æ—¥ä¿¡æ¯æ±‡æ€»å¤±è´¥")
    def create_daily_summary(self, event_data: Dict[str, Any]) -> ProcessResult:
        """
        åˆ›å»ºæ¯æ—¥ä¿¡æ¯æ±‡æ€»æ¶ˆæ¯ï¼ˆä¸»ä¸šåŠ¡å…¥å£ï¼‰

        Args:
            user_id: ç”¨æˆ·ID
            services_status: æœåŠ¡çŠ¶æ€ä¿¡æ¯

        Returns:
            ProcessResult: å¤„ç†ç»“æœ
        """
        # æ„å»ºBç«™ä¿¡æ¯cacheåˆ†ææ•°æ®ï¼ˆæ•´åˆåŸæ¥çš„åˆ†æ•£é€»è¾‘ï¼‰
        # analysis æ˜¯åç«¯çš„æ•°æ®å¤„ç†é€»è¾‘ï¼Œç„¶åæä¾›ç»™å‰ç«¯çš„å¡ç‰‡è¿›è¡Œbuild_card
        user_id = event_data.get(SchedulerConstKeys.ADMIN_ID)
        daily_raw_data = self.get_daily_raw_data(user_id)

        # æœ‰æ•°æ®ä¹‹åå†åœ¨å‰ç«¯å†™
        card_content = self.create_daily_summary_card(daily_raw_data)

        return ProcessResult.user_list_result("interactive", card_content)

    # endregion

    # region é‡‡é›†æ¨¡å—æ•°æ®
    # å‡è®¾user_idä¿¡æ¯å­˜åœ¨æ¥åšï¼Œä½†å®é™…ä¸Šéƒ½å…ˆèµ‹å€¼ä¸ºæˆ‘â€”â€”ç®¡ç†å‘˜id
    # ä¸šåŠ¡ä¿¡æ¯é¡ºåºåº”è¯¥æ˜¯ä»ä¸€ä¸ªé…ç½®è·å¾—æŸä¸ªuser_idçš„daily_summary çš„è§¦å‘æ—¶é—´ï¼Œç„¶ååˆ°æ—¶é—´äº†å¼€å§‹è¿›å…¥æœ¬æ¨¡å—é‡‡é›†ä¿¡æ¯ï¼Œå†é€šè¿‡å‰ç«¯å‘å‡ºå»
    # è¿™é‡Œæ˜¯ä¸€ä¸ªåŒ…å«é‡‡é›†å’Œå¤„ç†ä¸¤ä¸ªéƒ¨åˆ†çš„æ€»æ¥å£
    GRANULARITY_MINUTES = 120

    def get_daily_raw_data(self, user_id: str) -> Dict[str, Any]:
        """
        è·å–æ¯æ—¥ä¿¡æ¯æ±‡æ€»åŸå§‹æ•°æ®
        """
        # åç»­è¦æ”¹æˆä»ç”¨æˆ·æ•°æ®è¯»å–ï¼Œè¿™é‡Œå…ˆå†™æ­»
        # è¦ä¸è¦è¿›ä¸€æ­¥åˆ†ç¦»è·å–æ•°æ®å’Œå¤„ç†ï¼Œæˆ‘è§‰å¾—å¯ä»¥æœ‰ï¼Œè¦åˆå¹¶å›æ¥å°±æ˜¯å‰ªåˆ‡ä¸€ä¸‹çš„äº‹
        # å…¨å¼€æ˜¯æˆ‘çš„ï¼Œå¦‚æœæ˜¯å…¶ä»–user_idå°±åªå¼€æ—¥å¸¸åˆ†æ
        # AIçš„åˆ†æå¯èƒ½è¦å¹¶è¡Œï¼Œæˆ‘æ„Ÿè§‰ä¸¤ä¸ªæ˜¯å®Œå…¨æ— å…³çš„
        # ä¸åŒäººç”¨çš„å›¾ç‰‡ä¹Ÿå¯èƒ½ä¸ä¸€æ ·ï¼Ÿä½†åº”è¯¥ç°åœ¨åŸºæœ¬ä¸ç€æ€¥ï¼Œæ¯•ç«Ÿè±†åŒ…ä¹Ÿæ²¡å•¥å¼€é”€
        info_modules = {
            "routine": {
                "name": "æ—¥å¸¸åˆ†æ",
                "system_permission": True,
                "user_enabled": True,
                "data_method": "get_routine_data",
                "analyze_method": "analyze_routine_data",
                "image_method": "generate_routine_image",
            },
            "bili_video": {
                "name": "Bç«™è§†é¢‘",
                "system_permission": True,
                "user_enabled": True,
                "sync_read_mark": True,  # ä»…æœ¬åœ°æ ‡è®°ï¼Œè¿˜æ˜¯é¢å¤–åŒæ­¥åˆ°notion
                "data_method": "get_notion_bili_data",
                "analyze_method": "analyze_bili_video_data",
            },
            "bili_adskip": {
                "name": "Bç«™å¹¿å‘Šè·³è¿‡",
                "system_permission": True,
                "user_enabled": True,
                "data_method": "get_operation_data",
            },
            "services_status": {
                "name": "æœåŠ¡çŠ¶æ€",
                "system_permission": True,
                "user_enabled": True,
                "data_method": "get_services_status",
            },
        }

        # è¿™é‡Œçš„è°ƒç”¨æ¶æ„è¦åˆ†ç¦»å‡ºæ–¹æ³•çš„å‚æ•°æ¥ï¼Œä¸ç„¶æ‹“å±•æ€§å¤ªå·®
        for module_name, module_info in info_modules.items():
            if module_info["system_permission"] and module_info["user_enabled"]:
                data_method = module_info["data_method"]
                if hasattr(self, data_method):
                    data_params = module_info.get("data_params", {})
                    data_params["user_id"] = user_id
                    module_data = getattr(self, data_method)(data_params)
                    if module_data:
                        module_info["data"] = module_data
                        analyze_method = module_info.get("analyze_method", "")
                        if hasattr(self, analyze_method):
                            module_info["info"] = getattr(self, analyze_method)(
                                module_data
                            )
                else:
                    debug_utils.log_and_print(
                        f"æ¨¡å—{module_name}æ²¡æœ‰å®ç°{data_method}æ–¹æ³•",
                        log_level="WARNING",
                    )

        info_modules["system_status"] = {
            "name": "ç³»ç»ŸçŠ¶æ€",
            "data": {
                "date": datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥"),
                "weekday": [
                    "å‘¨ä¸€",
                    "å‘¨äºŒ",
                    "å‘¨ä¸‰",
                    "å‘¨å››",
                    "å‘¨äº”",
                    "å‘¨å…­",
                    "å‘¨æ—¥",
                ][datetime.now().weekday()],
            },
            "user_id": user_id,
        }

        return info_modules

    # endregion

    # region Bç«™è§†é¢‘æ¨è

    def get_notion_bili_data(self, _data_params: Dict[str, Any] = None) -> List[Dict]:
        """è·å–notion Bç«™è§†é¢‘æ•°æ®"""
        if self.app_controller:
            notion_service = self.app_controller.get_service(ServiceNames.NOTION)
            if notion_service:
                try:
                    # åˆ·æ–°ç¼“å­˜ï¼Œè·å–æœ€æ–°æ•°æ®ï¼ˆé€‚åˆæ—©ä¸Šæ±‡æ€»åœºæ™¯ï¼‰
                    notion_service.update_bili_cache()

                    # ç›´æ¥è·å–ç¼“å­˜æ•°æ®ï¼Œä¸è°ƒç”¨ç»Ÿè®¡æ–¹æ³•
                    videos = notion_service.cache_data.get(
                        notion_service.bili_cache_key, []
                    )
                    unread_videos = [v for v in videos if v.get("unread", True)]
                    return unread_videos
                except Exception as e:
                    debug_utils.log_and_print(
                        f"è·å–notion Bç«™ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}", log_level="WARNING"
                    )
        return None

    def analyze_bili_video_data(self, unread_videos: List[Dict]) -> Dict[str, Any]:
        """å¤„ç†Bç«™åˆ†ææ•°æ®"""
        # åç»­è°ƒæ•´è¾“å‡ºå†…å®¹ï¼Œæ¯”å¦‚åªå…³æ³¨æ”¶è—å¤¹é‡Œçš„æ—¶é•¿å’Œæ€»æ—¶é•¿/æ€»é‡â€”â€”ç”¨æ¥ç›‘æµ‹è®¢é˜…é‡æ˜¯å¦è¿‡å¤š
        # è¿™å·²ç»æ˜¯æ¨¡å—çš„1çº§å…¥å£äº†

        # ç»Ÿè®¡å„ç»´åº¦æ•°æ®
        total_count = len(unread_videos)
        priority_stats = self._calculate_priority_stats(unread_videos)

        # æŒ‰ä¼˜å…ˆçº§ç”ŸæˆåŸå§‹æ¨èè§†é¢‘
        original_recommendations = self._generate_original_recommendations(
            unread_videos
        )

        # ç”ŸæˆAIåˆ†æç»“æœâ€”â€”è¿™ä¸ªçš„ä¾èµ–å…³ç³»çš„å…ˆåé¡ºåºè¦å†è€ƒè™‘ä¸€ä¸‹ï¼Œç›®å‰llmä¹Ÿæ˜¯æ•´åˆåœ¨app_controlleré‡Œçš„serviceã€‚
        # ä»è¿™ä¸ªè§’åº¦æ¥è¯´app_controllerè¦æˆä¸ºå„ç§æ–¹æ³•çš„èƒŒæ™¯ä¿¡æ¯ï¼Œæ–¹ä¾¿ç›´æ¥è°ƒç”¨ã€‚
        ai_analysis = self._generate_ai_analysis(unread_videos)

        # åŸºäºAIè¯é¢˜åŒ¹é…ç»“æœé‡æ–°æ„å»ºæ¨èè§†é¢‘
        final_recommendations = self._rebuild_recommendations_with_ai(
            unread_videos, original_recommendations, ai_analysis
        )

        return {
            "statistics": {
                "total_count": total_count,
                "priority_stats": priority_stats,
                "ai_summary": ai_analysis.get("summary", ""),
                "ai_quality_score": ai_analysis.get("quality_score", 0),
                "top_recommendations": final_recommendations,
            },
            "source": "notion_statistics",
        }

    def _calculate_priority_stats(self, unread_videos: List[Dict]) -> Dict[str, Any]:
        """è®¡ç®—ä¼˜å…ˆçº§ç»Ÿè®¡"""
        priority_stats = {}

        for video in unread_videos:
            # ä¼˜å…ˆçº§ç»Ÿè®¡
            priority = video.get("chinese_priority", "Unknown")
            priority_stats.setdefault(priority, {"æ•°é‡": 0, "æ€»æ—¶é•¿åˆ†é’Ÿ": 0})

            priority_stats[priority]["æ•°é‡"] += 1

            # è·å–æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
            duration_minutes = video.get("duration", 0)
            try:
                total_minutes = float(duration_minutes) if duration_minutes else 0
                priority_stats[priority]["æ€»æ—¶é•¿åˆ†é’Ÿ"] += int(total_minutes)
            except (ValueError, TypeError):
                total_minutes = 0

        return priority_stats

    def _generate_original_recommendations(
        self, unread_videos: List[Dict]
    ) -> List[Dict]:
        """ç”ŸæˆåŸå§‹æ¨èè§†é¢‘"""
        original_recommendations = []

        # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„
        high_priority = [
            v for v in unread_videos if v.get("chinese_priority") == "ğŸ’–é«˜"
        ]
        medium_priority = [
            v for v in unread_videos if v.get("chinese_priority") == "ğŸ˜œä¸­"
        ]
        low_priority = [v for v in unread_videos if v.get("chinese_priority") == "ğŸ‘¾ä½"]

        # æŒ‰ä¼˜å…ˆçº§ä¾æ¬¡é€‰æ‹©ï¼Œæ¯ä¸ªä¼˜å…ˆçº§å†…éšæœºé€‰æ‹©
        temp_selected = []
        for priority_group in [
            high_priority,
            medium_priority,
            low_priority,
        ]:
            if len(temp_selected) >= 3:
                break

            # ä»å½“å‰ä¼˜å…ˆçº§ç»„ä¸­éšæœºé€‰æ‹©ï¼Œç›´åˆ°è¾¾åˆ°3ä¸ªæˆ–è¯¥ç»„ç”¨å®Œ
            available = [v for v in priority_group if v not in temp_selected]
            while available and len(temp_selected) < 3:
                selected = random.choice(available)
                temp_selected.append(selected)
                available.remove(selected)

        # æ ¼å¼åŒ–åŸå§‹æ¨èè§†é¢‘
        for video in temp_selected:
            original_recommendations.append(
                {
                    "æ ‡é¢˜": video.get("title", "æ— æ ‡é¢˜è§†é¢‘"),
                    "é“¾æ¥": video.get("url", ""),
                    "é¡µé¢ID": video.get("pageid", ""),
                    "æ—¶é•¿": video.get("duration_str", ""),
                    "ä¼˜å…ˆçº§": video.get("chinese_priority", ""),
                    "æ¥æº": video.get("chinese_source", ""),
                }
            )

        return original_recommendations

    def _generate_ai_analysis(self, all_videos: List[Dict]) -> Dict[str, Any]:
        """ä½¿ç”¨AIä¸€æ¬¡æ€§å®Œæˆå†…å®¹æ±‡æ€»å’Œè¯é¢˜åŒ¹é…åˆ†æ"""
        # è·å–æœåŠ¡å’Œé…ç½®
        llm_service = self.app_controller.get_service(ServiceNames.LLM)
        if not llm_service or not llm_service.is_available():
            return {
                "summary": "AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œæ— æ³•ç”Ÿæˆåˆ†æ",
                "quality_score": 0,
                "topic_matches": [],
            }

        config_service = self.app_controller.get_service(ServiceNames.CONFIG)
        focus_topics = (
            config_service.get("daily_summary", {}).get("focus_topics", [])
            if config_service
            else []
        )

        # æ„å»ºæç¤ºè¯å’Œæ•°æ®
        video_list = self._format_video_list(all_videos)
        topics_text = f"å…³æ³¨è¯é¢˜ï¼š{', '.join(focus_topics)}" if focus_topics else ""
        prompt = f"{topics_text}\n\nä»Šæ—¥å¾…çœ‹è§†é¢‘æ¸…å•({len(all_videos)}ä¸ª)ï¼š\n{chr(10).join(video_list)}\n\nè¯·æŒ‰è¦æ±‚åˆ†æå¹¶è¿”å›ç»“æœã€‚"

        # è°ƒç”¨LLM
        result = llm_service.structured_call(
            prompt=prompt,
            response_schema=self._build_response_schema(bool(focus_topics)),
            system_instruction=self._build_system_instruction(focus_topics),
            temperature=0.5,
        )

        # å¤„ç†ç»“æœ
        if "error" in result:
            return {
                "summary": f"AIåˆ†æå¤±è´¥: {result['error']}",
                "quality_score": 0,
                "topic_matches": [],
            }

        return result

    def _format_video_list(self, all_videos: List[Dict]) -> List[str]:
        """æ ¼å¼åŒ–è§†é¢‘åˆ—è¡¨"""
        return [
            f"{i}. ã€Š{video.get('title', 'æ— æ ‡é¢˜')}ã€‹ | UPä¸»: {video.get('author', 'æœªçŸ¥')} | "
            f"ä¼˜å…ˆçº§: {video.get('chinese_priority', 'æœªçŸ¥')} | æ¨èç†ç”±: {video.get('summary', 'æ— ç†ç”±')}"
            for i, video in enumerate(all_videos, 1)
        ]

    # ç±»çº§åˆ«å¸¸é‡ - é¿å…é‡å¤å®šä¹‰
    AI_ANALYSIS_BASE_INSTRUCTION = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ†æåŠ©ç†ã€‚

**æ ¸å¿ƒè¦æ±‚ï¼š**
1. ä¼˜å…ˆæ±‡æŠ¥é«˜ä»·å€¼å†…å®¹ï¼šæ–°æŠ€æœ¯çªç ´ã€è¡Œä¸šæ´å¯Ÿã€å®ç”¨æ–¹æ³•è®º
2. æ•´åˆç›¸ä¼¼ä¸»é¢˜ï¼Œé¿å…é‡å¤ä¿¡æ¯
3. å¦‚æœå†…å®¹è´¨é‡æ™®éä¸€èˆ¬ï¼Œç›´æ¥è¯´"ä»Šæ—¥æ— ç‰¹åˆ«é‡ç‚¹"
4. æ§åˆ¶åœ¨80å­—å†…ï¼Œé‡è´¨é‡ä¸é‡æ•°é‡
5. **å¿…é¡»ç»™å‡ºæ•´ä½“å†…å®¹è´¨é‡è¯„åˆ†(0-10)**

**åˆ¤æ–­æ ‡å‡†ï¼š**
- ä¼˜å…ˆçº§"é«˜"ä¸”å†…å®¹æ–°é¢– â†’ å¿…é¡»æ±‡æŠ¥
- å¤šä¸ªUPä¸»è°ˆè®ºåŒä¸€çƒ­ç‚¹ â†’ æ•´åˆæ±‡æŠ¥
- çº¯å¨±ä¹ã€é‡å¤è¯é¢˜ â†’ å¯å¿½ç•¥
- å®ç”¨å·¥å…·ã€æŠ€æœ¯æ•™ç¨‹ â†’ é‡ç‚¹å…³æ³¨

**è´¨é‡è¯„åˆ†æ ‡å‡†ï¼š**
- 9-10åˆ†ï¼šæœ‰é‡å¤§æŠ€æœ¯çªç ´æˆ–æ·±åº¦æ´å¯Ÿ
- 7-8åˆ†ï¼šæœ‰å®ç”¨ä»·å€¼æˆ–æ–°é¢–è§‚ç‚¹
- 4-6åˆ†ï¼šæ™®é€šå†…å®¹ï¼Œä»·å€¼ä¸€èˆ¬
- 0-3åˆ†ï¼šçº¯å¨±ä¹æˆ–é‡å¤å†…å®¹"""

    def _build_system_instruction(self, focus_topics: List[str]) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        task_section = (
            """
**ä»»åŠ¡ï¼š**
1. åˆ†æä»Šæ—¥è§†é¢‘æ¸…å•ï¼Œ**æ™ºèƒ½åˆ¤æ–­çœŸæ­£æœ‰ä»·å€¼çš„é‡ç‚¹**ï¼Œè€Œéç®€å•ç½—åˆ—ã€‚
2. åˆ†æå“ªäº›è§†é¢‘ä¸æä¾›çš„å…³æ³¨è¯é¢˜ç›¸å…³ï¼Œç»™å‡ºè§†é¢‘åºå·å’Œå…³è”åº¦è¯„åˆ†(0-10)

**ä»»åŠ¡1è¾“å‡ºæ ¼å¼ï¼š**
å¦‚æœ‰é‡ç‚¹ï¼šç®€æ´è¯´æ˜å‡ ä¸ªå…³é”®å†…å®¹ç‚¹
å¦‚æ— é‡ç‚¹ï¼šç›´æ¥è¯´"ä»Šæ—¥å¾…çœ‹å†…å®¹ä»¥[ä¸»è¦ç±»å‹]ä¸ºä¸»ï¼Œæ— ç‰¹åˆ«é‡ç‚¹"

**ä»»åŠ¡2è¯é¢˜åŒ¹é…è¦æ±‚ï¼š**
- åªè¿”å›ä¸å…³æ³¨è¯é¢˜é«˜åº¦ç›¸å…³çš„è§†é¢‘
- å…³è”åº¦è¯„åˆ†è¦å‡†ç¡®(0-10ï¼Œ10è¡¨ç¤ºæœ€ç›¸å…³)
- æ²¡æœ‰ç›¸å…³çš„å¯ä»¥è¿”å›ç©ºæ•°ç»„"""
            if focus_topics
            else """
**ä»»åŠ¡ï¼š**
åˆ†æä»Šæ—¥è§†é¢‘æ¸…å•ï¼Œ**æ™ºèƒ½åˆ¤æ–­çœŸæ­£æœ‰ä»·å€¼çš„é‡ç‚¹**ï¼Œè€Œéç®€å•ç½—åˆ—ã€‚

**è¾“å‡ºæ ¼å¼ï¼š**
å¦‚æœ‰é‡ç‚¹ï¼šç®€æ´è¯´æ˜å‡ ä¸ªå…³é”®å†…å®¹ç‚¹
å¦‚æ— é‡ç‚¹ï¼šç›´æ¥è¯´"ä»Šæ—¥å¾…çœ‹å†…å®¹ä»¥[ä¸»è¦ç±»å‹]ä¸ºä¸»ï¼Œæ— ç‰¹åˆ«é‡ç‚¹" """
        )

        return self.AI_ANALYSIS_BASE_INSTRUCTION + task_section

    def _build_response_schema(self, has_focus_topics: bool) -> Dict[str, Any]:
        """æ„å»ºå“åº”schemaï¼Œæ ¹æ®ä¸šåŠ¡éœ€æ±‚è¿”å›ä¸åŒç»“æ„"""
        # å…¬å…±å±æ€§å®šä¹‰
        base_properties = {
            "summary": {"type": "string", "description": "ä»Šæ—¥å†…å®¹æ±‡æ€»è¯´æ˜"},
            "quality_score": {
                "type": "integer",
                "minimum": 0,
                "maximum": 10,
                "description": "æ•´ä½“å†…å®¹è´¨é‡è¯„åˆ†(0-10)",
            },
        }

        base_required = ["summary", "quality_score"]

        if has_focus_topics:
            # æœ‰å…³æ³¨è¯é¢˜æ—¶ï¼Œéœ€è¦è¿”å›åŒ¹é…ç»“æœ
            base_properties["topic_matches"] = {
                "type": "array",
                "description": "ä¸å…³æ³¨è¯é¢˜åŒ¹é…çš„è§†é¢‘",
                "items": {
                    "type": "object",
                    "properties": {
                        "video_id": {
                            "type": "integer",
                            "description": "è§†é¢‘åºå·(ä»1å¼€å§‹)",
                        },
                        "relevance_score": {
                            "type": "integer",
                            "minimum": 0,
                            "maximum": 10,
                            "description": "è¯é¢˜å…³è”åº¦è¯„åˆ†(0-10)",
                        },
                    },
                    "required": ["video_id", "relevance_score"],
                },
            }
            base_required.append("topic_matches")

        return {
            "type": "object",
            "properties": base_properties,
            "required": base_required,
        }

    @safe_execute("é‡æ„æ¨èè§†é¢‘å¤±è´¥")
    def _rebuild_recommendations_with_ai(
        self,
        all_videos: List[Dict],
        original_recommendations: List[Dict],
        ai_analysis: Dict[str, Any],
    ) -> List[Dict]:
        """
        åŸºäºAIè¯é¢˜åŒ¹é…ç»“æœé‡æ–°æ„å»ºæ¨èè§†é¢‘åˆ—è¡¨

        Args:
            all_videos: æ‰€æœ‰æœªè¯»è§†é¢‘
            original_recommendations: åŸå§‹æ¨èè§†é¢‘
            ai_analysis: AIåˆ†æç»“æœ

        Returns:
            List[Dict]: é‡æ–°æ„å»ºçš„æ¨èè§†é¢‘åˆ—è¡¨
        """
        # è·å–AIåŒ¹é…çš„é«˜å…³è”åº¦è§†é¢‘
        topic_matches = ai_analysis.get("topic_matches", [])
        high_relevance_videos = []

        for match in topic_matches:
            video_id = match.get("video_id", 0)
            relevance_score = match.get("relevance_score", 0)

            # åªè¦å…³è”åº¦>=7çš„è§†é¢‘
            if relevance_score >= 7 and 1 <= video_id <= len(all_videos):
                video_index = video_id - 1  # è½¬æ¢ä¸º0åŸºç´¢å¼•
                video = all_videos[video_index]
                high_relevance_videos.append(
                    {
                        "æ ‡é¢˜": video.get("title", "æ— æ ‡é¢˜è§†é¢‘"),
                        "é“¾æ¥": video.get("url", ""),
                        "é¡µé¢ID": video.get("pageid", ""),
                        "æ—¶é•¿": video.get("duration_str", ""),
                        "ä¼˜å…ˆçº§": video.get("chinese_priority", ""),
                        "æ¥æº": video.get("chinese_source", ""),
                    }
                )

                # æœ€å¤š3ä¸ª
                if len(high_relevance_videos) >= 3:
                    break

        # å¦‚æœAIæ¨èçš„ä¸å¤Ÿ3ä¸ªï¼Œç”¨åŸæœ‰é€»è¾‘è¡¥å……
        if len(high_relevance_videos) < 3:
            # è·å–AIæ¨èä¸­å·²é€‰è§†é¢‘çš„pageidï¼Œé¿å…é‡å¤
            selected_pageids = {v.get("é¡µé¢ID") for v in high_relevance_videos}

            # ä»åŸå§‹æ¨èä¸­è¡¥å……
            for video in original_recommendations:
                if video.get("é¡µé¢ID") not in selected_pageids:
                    high_relevance_videos.append(video)
                    if len(high_relevance_videos) >= 3:
                        break

        return high_relevance_videos

    def _build_fallback_analysis_data(self) -> Dict[str, Any]:
        """æ„å»ºfallbackåˆ†ææ•°æ®"""
        now = datetime.now()
        return {
            "date": now.strftime("%Yå¹´%mæœˆ%dæ—¥"),
            "weekday": ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"][
                now.weekday()
            ],
            "status": "ç›®å‰æ²¡æœ‰å¾…çœ‹çš„Bç«™è§†é¢‘",
            "source": "placeholder",
            "timestamp": now.isoformat(),
        }

    # endregion

    # region æ—¥å¸¸åˆ†æ-æ€»
    def get_routine_data(self, data_params: Dict[str, Any] = None) -> Dict[str, Any]:
        """è·å–æ—¥å¸¸åˆ†ææ•°æ®ï¼ˆæ€»å…¥å£ï¼‰"""
        if not data_params:
            return {}
        user_id = data_params.get("user_id")

        now = datetime.now()
        is_monday = now.weekday() == 0  # 0æ˜¯å‘¨ä¸€
        is_monday = True
        is_first_day_of_month = now.day == 1
        is_first_day_of_quarter = now.month % 3 == 1 and now.day == 1
        is_first_day_of_year = now.month == 1 and now.day == 1

        # æ—¥ï¼šå¾…åŠäº‹é¡¹ï¼Œæé†’äº‹é¡¹ï¼Œimage_keyï¼Œä¸»é¢œè‰²
        # å‘¨ï¼šæ—¥ + å‘¨æ—¥ç¨‹åˆ†æï¼Œå‘¨image_keyï¼Œå‘¨çš„æ—¥ç¨‹è®°å½•è¡¨ï¼Œè§„å¾‹åˆ†æ
        # æœˆï¼šæ—¥ + å‘¨ + æœˆç¨‹åˆ†æâ€”â€”æœ€å¥½ç»´åº¦æœ‰åŒºåˆ«ï¼Œå¦åˆ™å°±è¦å› ä¸ºæœˆæŠŠå‘¨å…³é—­æ‰ï¼Œæˆ‘ä¸æƒ³æœ‰å¤šä»½é‡å¤ä¿¡æ¯

        daily_data = self.get_daily_data(user_id)

        weekly_data = None
        if is_monday:
            weekly_data = self.get_weekly_data(
                user_id, granularity_minutes=self.GRANULARITY_MINUTES
            )

        routine_data = {
            "daily": daily_data,
            "weekly": weekly_data,
        }

        return routine_data

    # endregion

    # region æ—¥å¸¸åˆ†æ-æ—¥

    def get_daily_data(self, user_id: str = None) -> Dict[str, Any]:
        """è·å–æ—¥åˆ†ææ•°æ®"""
        # è¿˜éœ€è¦åŠ ä¸Šä¸€ä¸ªä»Šæ—¥æé†’å’Œä»Šæ—¥å¾…åŠï¼Œè‡³äºæ˜¨æ—¥æ€è€ƒï¼Œè¿™ä¸ªæœ€ååš
        now = datetime.now()

        end_time = datetime(now.year, now.month, now.day)
        start_time = end_time - timedelta(days=1)

        main_color, color_palette = self.routine_business.calculate_color_palette(
            user_id,
            start_time,
            end_time,
        )
        raw_prompt = wax_stamp_prompt(
            color_palette, subject_name=main_color.get("max_weight_category", "")
        )

        image_service = self.app_controller.get_service(ServiceNames.IMAGE)
        result = image_service.hunyuan_image_generator.generate_image(
            raw_prompt,
            size="3:4",
        )
        image_path = result.get("file_path")
        image_key = self.app_controller.get_adapter(
            AdapterNames.FEISHU
        ).sender.upload_and_get_image_key(image_path)

        # åˆ é™¤å›¾ç‰‡
        if image_path:
            os.remove(image_path)

        return {
            "image_key": image_key,
            "main_color": main_color,
            "color_palette": color_palette,
        }

    # endregion

    # region æ—¥å¸¸åˆ†æ-å‘¨
    def get_weekly_data(
        self, user_id: str = None, granularity_minutes: int = 120
    ) -> Dict[str, Any]:
        """è·å–å‘¨åˆ†ææ•°æ®"""
        now = datetime.now()
        end_time = datetime(now.year, now.month, now.day) - timedelta(
            days=now.weekday()
        )
        start_time = end_time - timedelta(days=7)

        records = self.routine_business.load_event_records(user_id)
        records = records.get("records", {})

        filtered_records = self.routine_business.preprocess_and_filter_records(
            records, start_time, end_time
        )
        event_map = self.routine_business.cal_event_map(user_id)

        weekly_raw_data = {
            "records": filtered_records,
            "definitions": self.routine_business.load_event_definitions(user_id).get(
                "definitions", {}
            ),
            "start_time": start_time,
            "end_time": end_time,
            "event_map": event_map,
            "granularity_minutes": granularity_minutes,
        }

        return weekly_raw_data

    def analyze_routine_data(
        self, routine_data: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """åˆ†æroutineæ•°æ®"""

        weekly_raw = routine_data.get("weekly", {})
        formatted_weekly_data = {}
        weekly_document: Dict[str, Any] = {}
        if weekly_raw:
            # ç”Ÿæˆå‘¨æ–‡æ¡£
            weekly_document = self.analyze_weekly_document(weekly_raw)
            # ç”Ÿæˆå¡ç‰‡ç”¨æ—¶é—´è¡¨
            formatted_weekly_data = self.format_table_data(
                weekly_raw.get("records", []),
                weekly_raw.get("start_time"),
                weekly_raw.get("event_map"),
                weekly_raw.get("granularity_minutes", 120),
            )
            weekly_document["timetable"] = formatted_weekly_data

        # åˆ†æroutineæ•°æ®ï¼ŒåŒ…æ‹¬æ—¥ã€å‘¨ã€æœˆã€å­£ã€å¹´
        # æ—¥ï¼šå¾…åŠäº‹é¡¹ï¼Œæé†’äº‹é¡¹ï¼Œimage_keyï¼Œä¸»é¢œè‰²
        # å‘¨ï¼šæ—¥ + å‘¨æ—¥ç¨‹åˆ†æï¼Œå‘¨image_keyï¼Œå‘¨çš„æ—¥ç¨‹è®°å½•è¡¨ï¼Œè§„å¾‹åˆ†æ
        # æœˆï¼šæ—¥ + å‘¨ + æœˆç¨‹åˆ†æâ€”â€”æœ€å¥½ç»´åº¦æœ‰åŒºåˆ«ï¼Œå¦åˆ™å°±è¦å› ä¸ºæœˆæŠŠå‘¨å…³é—­æ‰ï¼Œæˆ‘ä¸æƒ³æœ‰å¤šä»½é‡å¤ä¿¡æ¯

        routine_info = {
            "daily": routine_data.get("daily", {}),
            "weekly": weekly_document,
        }
        return routine_info

    def format_table_data(
        self,
        records: List[Dict[str, Any]],
        start_time: datetime,
        event_map: Dict[str, Any],
        granularity_minutes: int = 120,
    ) -> Dict[str, Any]:
        """æ ¼å¼åŒ–è¡¨æ ¼æ•°æ® - æ„å»ºçœŸå®çš„å‘¨æ•°æ®ç»“æ„"""

        # ç”Ÿæˆæ—¶é—´æ ‡ç­¾
        match granularity_minutes:
            case 30:
                time_labels = [
                    label
                    for hour in range(24)
                    for label in (f"{hour:02d}:00", f"{hour:02d}:30")
                ]
            case 60:
                time_labels = [f"{hour:02d}:00" for hour in range(24)]
            case _:
                time_labels = [f"{hour:02d}:00" for hour in range(0, 24, 2)]

        # åˆå§‹åŒ–å‘¨æ•°æ®ç»“æ„
        week_data = {
            "time_labels": time_labels,
            "days": {
                "mon": {},
                "tue": {},
                "wed": {},
                "thu": {},
                "fri": {},
                "sat": {},
                "sun": {},
            },
        }

        # ä¸ºæ¯ä¸€å¤©å¤„ç†æ•°æ®
        current_day = start_time
        day_keys = ["mon", "tue", "wed", "thu", "fri", "sat", "sun"]

        for day_idx in range(7):
            day_key = day_keys[day_idx]
            day_start = current_day
            day_end = day_start + timedelta(days=1)

            # è·å–å½“å¤©çš„è®°å½•
            day_records = []
            for record in records:
                record_start = record.get("start_dt")
                record_end = record.get("end_dt")

                # åˆ¤æ–­è®°å½•æ˜¯å¦ä¸å½“å¤©æœ‰äº¤é›†
                if record_start < day_end and record_end > day_start:
                    day_records.append(record)

            # ä¸ºå½“å¤©çš„æ¯ä¸ªæ—¶é—´æ§½ç”Ÿæˆæ•°æ®
            for time_label in time_labels:
                hour_minute = time_label.split(":")
                slot_hour = int(hour_minute[0])
                slot_minute = int(hour_minute[1])

                slot_start = day_start.replace(
                    hour=slot_hour, minute=slot_minute, second=0, microsecond=0
                )
                slot_end = slot_start + timedelta(minutes=granularity_minutes)

                # ç”Ÿæˆè¯¥æ—¶é—´æ§½çš„åŸå­æ—¶é—´çº¿
                atomic_timeline = self.routine_business.generate_atomic_timeline(
                    day_records, slot_start, slot_end
                )

                if atomic_timeline:
                    # è®¡ç®—é¢œè‰²å’Œæ ‡ç­¾
                    # å‘¨çš„æ¨¡å¼æ˜¾ç¤ºçš„æ˜¯event_nameï¼Œä¸é€‚åˆèåˆé¢œè‰²ï¼Œè€Œæ˜¯åŒ¹é…é¢œè‰²

                    # æ‰¾åˆ°æŒç»­æ—¶é—´æœ€é•¿çš„äº‹ä»¶ä½œä¸ºä¸»è¦äº‹ä»¶
                    sorted_atomic_timeline = sorted(
                        atomic_timeline,
                        key=lambda x: x["duration_minutes"],
                        reverse=True,
                    )
                    slot_event_label = sorted_atomic_timeline[0]["source_event"][
                        "event_name"
                    ]
                    slot_event_info = event_map.get(slot_event_label, {})
                    slot_event_color = slot_event_info.get("color", ColorTypes.GREY)

                    final_color, palette_data = (
                        self.routine_business.calculate_color_palette(
                            "no_user_id",
                            slot_start,
                            slot_end,
                            event_color_map=event_map,
                            timeline_data=atomic_timeline,
                        )
                    )

                    # slot_color_name = final_color

                    slot_category_label = final_color.get("max_weight_category", "ç©ºé—²")

                    week_data["days"][day_key][time_label] = {
                        "text": slot_event_label,
                        "color": slot_event_color,
                        "category_label": slot_category_label,
                    }
                else:
                    # ç©ºæ—¶é—´æ§½
                    week_data["days"][day_key][time_label] = {
                        "text": "ç©ºé—²",
                        "color": ColorTypes.GREY,
                        "category_label": "ç©ºé—²",
                    }

            current_day += timedelta(days=1)

        return week_data

    def analyze_weekly_document(self, weekly_raw: Dict[str, Any]) -> Dict[str, Any]:
        """å°è£…å‘¨æ–‡æ¡£åˆ†æï¼Œè¾“å…¥ä¸ºé¢„å–çš„weekly_rawæ•°æ®ï¼Œè¾“å‡ºä¸ºweekly_documentä¸‰é¡¹ã€‚"""
        # DataFrame: è®°å½•åˆ—è¡¨
        record_df = pd.DataFrame(weekly_raw.get("records", [])).fillna("")

        # event_df: ä»å®šä¹‰ä¸­å–å‡ºevent_nameè¡Œ
        definitions = weekly_raw.get("definitions", {})
        event_df = pd.DataFrame(definitions).fillna("")
        if not event_df.empty:
            event_df = event_df.T.rename(columns={"name": "event_name"})
        else:
            event_df = pd.DataFrame(
                columns=["event_name", "category", "properties"]
            )  # ç©ºè¡¨å ä½

        # ç»Ÿè®¡åŸå­æ—¶é—´çº¿æ—¶é•¿ï¼ˆæŒ‰ record_id èšåˆï¼‰
        start_time = weekly_raw.get("start_time")
        end_time = weekly_raw.get("end_time")
        if start_time.year == end_time.year:
            document_title = f"å‘¨æŠ¥å‘Š{start_time.strftime('%y%m%d')}-{end_time.strftime('%m%d')}"
        else:
            document_title = f"å‘¨æŠ¥å‘Š{start_time.strftime('%y%m%d')}-{end_time.strftime('%y%m%d')}"
        atomic_timeline = self.routine_business.generate_atomic_timeline(
            weekly_raw.get("records", []),
            start_time,
            end_time,
        )
        atomic_df = pd.DataFrame(atomic_timeline)
        record_define_time = atomic_df.groupby("record_id", as_index=False)[
            "duration_minutes"
        ].sum()

        # interval_type ä» properties ä¸­æå–
        if "properties" in event_df.columns:
            event_df["interval_type"] = event_df["properties"].apply(
                self._extract_interval_type
            )
        else:
            event_df["interval_type"] = "degree"

        # åˆå¹¶è®°å½•ä¸å®šä¹‰ä¿¡æ¯
        merged_df = record_df.merge(
            event_df[["event_name", "category", "interval_type"]],
            on="event_name",
            how="left",
        ).fillna({"category": "", "degree": "", "interval_type": "degree"})
        merged_df = merged_df.merge(record_define_time, on="record_id", how="left")

        # åˆ†ç»„ç»Ÿè®¡
        grouped = merged_df.groupby(["category", "event_name", "degree"])
        summary_df = grouped.agg(
            count=("event_name", "size"),
            total_duration=("duration_minutes", "sum"),
            avg_duration=("duration_minutes", "mean"),
            min_duration=("duration_minutes", "min"),
            max_duration=("duration_minutes", "max"),
        ).reset_index()

        # è®¡ç®—æœ€å¤§durationå¯¹åº”çš„start_atä¸ä¸‰ç±»interval
        max_duration_start_at_list = []
        degree_interval_minutes_list = []
        category_interval_minutes_list = []
        event_interval_minutes_list = []
        display_unit_list = []

        for name, group in grouped:
            max_duration_start_at_list.append(self._get_max_start_at(group))

            category_val = group["category"].iloc[0] if not group.empty else ""
            event_name_val = group["event_name"].iloc[0] if not group.empty else ""
            degree_val = (
                group["degree"].iloc[0]
                if ("degree" in group.columns and not group.empty)
                else ""
            )
            interval_type_val = (
                group["interval_type"].iloc[0]
                if ("interval_type" in group.columns and not group.empty)
                else "degree"
            )
            if interval_type_val not in ["category", "degree", "ignore"]:
                interval_type_val = "ignore"

            # degreeåˆ†ç»„
            mask_degree = (
                (merged_df["category"] == category_val)
                & (merged_df["event_name"] == event_name_val)
                & (merged_df["degree"] == degree_val)
            )
            degree_group = merged_df[mask_degree].sort_values("start_dt")
            if not degree_group.empty and len(degree_group) > 1:
                degree_interval = self._calc_avg_interval(degree_group["start_dt"])
                degree_interval_minutes_list.append(degree_interval)
            else:
                degree_interval_minutes_list.append(np.nan)

            # categoryåˆ†ç»„
            mask_category = (merged_df["category"] == category_val) & (
                merged_df["event_name"] == event_name_val
            )
            category_group = merged_df[mask_category].sort_values("start_dt")
            if not category_group.empty and len(category_group) > 1:
                category_interval = self._calc_avg_interval(category_group["start_dt"])
                category_interval_minutes_list.append(category_interval)
            else:
                category_interval_minutes_list.append(np.nan)

            # eventå£å¾„
            if interval_type_val == "degree":
                event_interval = degree_interval_minutes_list[-1]
                display_unit_list.append(f"{event_name_val}({degree_val})")
            elif interval_type_val == "category":
                event_interval = category_interval_minutes_list[-1]
                display_unit_list.append(event_name_val)
            else:
                event_interval = np.nan
                display_unit_list.append("")
            event_interval_minutes_list.append(event_interval)

        summary_df["max_duration_start_at"] = max_duration_start_at_list
        summary_df["degree_interval_minutes"] = degree_interval_minutes_list
        summary_df["category_interval_minutes"] = category_interval_minutes_list
        summary_df["event_interval_minutes"] = event_interval_minutes_list
        summary_df["display_unit"] = display_unit_list

        # äº‹ä»¶æ€»è®¡ä¸æ’åº
        event_name_stats = (
            summary_df.groupby("event_name")
            .agg(
                event_total_count=("count", "sum"),
                event_total_duration=("total_duration", "sum"),
            )
            .reset_index()
        )

        # ç»Ÿè®¡å¤©æ•°ï¼ˆç”¨ start_dt çš„æ—¥æœŸæ•°ï¼‰
        if "start_dt" in merged_df.columns and not merged_df.empty:
            unique_days = pd.to_datetime(merged_df["start_dt"]).dt.date.nunique()
        else:
            unique_days = 0

        total_hours = unique_days * 24
        total_minutes = total_hours * 60

        category_stats = (
            summary_df.groupby("category")
            .agg(
                category_total_count=("count", "sum"),
                category_total_duration=("total_duration", "sum"),
            )
            .reset_index()
        )
        event_map = weekly_raw.get("event_map", {})
        category_color_map = {}
        for event_info in event_map.values():
            category_color_map[event_info.get("category", "")] = event_info.get(
                "color"
            ).pie_color

        category_stats["color"] = category_stats["category"].map(
            lambda x: category_color_map.get(x, "#959BEE")
        )

        if total_minutes > 0:
            category_stats["category_duration_percent"] = (
                category_stats["category_total_duration"] / total_minutes * 100
            ).round(1)
            recorded_minutes = category_stats["category_total_duration"].sum()
            unrecorded_minutes = total_minutes - recorded_minutes
            unrecorded_percent = round(unrecorded_minutes / total_minutes * 100, 1)
            category_stats = pd.concat(
                [
                    category_stats,
                    pd.DataFrame(
                        [
                            {
                                "category": "æœªè®°å½•",
                                "category_total_count": 0,
                                "category_total_duration": unrecorded_minutes,
                                "category_duration_percent": unrecorded_percent,
                                "color": "#d0d3d6",  # ç°è‰²
                            }
                        ]
                    ),
                ],
                ignore_index=True,
            )
        else:
            category_stats["category_duration_percent"] = 0.0

        summary_df = summary_df.merge(event_name_stats, on="event_name", how="left")
        summary_df = summary_df.sort_values(
            by=[
                "event_total_count",
                "event_total_duration",
                "event_name",
                "total_duration",
                "count",
            ],
            ascending=[False, False, True, False, False],
        ).reset_index(drop=True)

        # å¤„ç† note ä¿¡æ¯
        current_year = datetime.now().year
        note_rows = merged_df[
            merged_df["note"].notnull() & (merged_df["note"] != "")
        ].copy()
        if not note_rows.empty:
            note_rows["note_info"] = note_rows.apply(
                lambda r: self._format_note_info(r, current_year), axis=1
            )
            note_infos = note_rows["note_info"].tolist()
        else:
            note_infos = []

        return {
            "note_list": note_infos,
            "event_summary": summary_df.to_dict(orient="records"),
            "category_stats": category_stats.to_dict(orient="records"),
            "document_title": document_title,
        }

    def _extract_interval_type(self, properties):
        # propertiesä¸ºå­—å…¸ï¼Œinterval_typeä¸ºå…¶keyä¹‹ä¸€
        if isinstance(properties, dict):
            interval_type = properties.get("interval_type", None)
            if interval_type in ["category", "degree", "ignore"]:
                return interval_type
            else:
                return "ignore"
        else:
            return "ignore"

    def _calc_avg_interval(self, times):
        """è®¡ç®—å¹³å‡é—´éš”ï¼ˆåˆ†é’Ÿï¼‰ï¼Œtimesä¸ºå‡åºdatetimeå­—ç¬¦ä¸²åˆ—è¡¨"""
        if len(times) < 2:
            return np.nan
        times = pd.to_datetime(times)
        intervals = (times[1:].values - times[:-1].values) / np.timedelta64(1, "m")
        return np.mean(intervals) if len(intervals) > 0 else np.nan

    def _get_max_start_at(self, subdf):
        """è·å–durationæœ€å¤§å€¼å¯¹åº”çš„start_at"""
        if subdf.empty:
            return ""
        idx = subdf["duration_minutes"].idxmax()
        return subdf.loc[idx, "start_dt"] if idx in subdf.index else ""

    def _format_note_info(self, row, current_year: int):
        # å¤„ç†åˆ†ç±»
        category = (
            row["category"]
            if pd.notnull(row["category"]) and row["category"] != ""
            else ""
        )
        # å¤„ç†äº‹ä»¶å
        event_name = (
            row["event_name"]
            if pd.notnull(row["event_name"]) and row["event_name"] != ""
            else ""
        )
        # å¤„ç†degree
        degree = (
            row["degree"] if pd.notnull(row["degree"]) and row["degree"] != "" else None
        )
        # å¤„ç†è¿›åº¦
        progress = (
            row["progress_value"]
            if "progress_value" in row
            and pd.notnull(row["progress_value"])
            and row["progress_value"] != ""
            else None
        )
        # å¤„ç†å¤‡æ³¨
        note = row["note"] if pd.notnull(row["note"]) else ""
        # æ‹¼æ¥degreeéƒ¨åˆ†ï¼Œç©ºåˆ™ä¸æ˜¾ç¤ºæ‹¬å·
        if degree:
            degree_str = f"({degree})"
        else:
            degree_str = ""

        start_time = (
            row["start_dt"]
            if pd.notnull(row["start_dt"]) and row["start_dt"] != ""
            else ""
        )
        if start_time.year == current_year:
            start_time_str = start_time.strftime("%m-%d %H:%M")
        else:
            start_time_str = start_time.strftime("%Y-%m-%d %H:%M")
        # æ‹¼æ¥å¤´éƒ¨
        if category:
            head = f"[{start_time_str} è€—æ—¶{row['duration_minutes']}åˆ†] [{category}] {event_name} {degree_str}"
        else:
            head = f"[{start_time_str} è€—æ—¶{row['duration_minutes']}åˆ†] {event_name} {degree_str}"
        head = head.rstrip()  # å»é™¤å¤šä½™ç©ºæ ¼
        # æ‹¼æ¥è¿›åº¦
        progress_str = f" | è¿›åº¦:{progress}" if progress else ""
        # æ‹¼æ¥å¤‡æ³¨
        note_str = f" | å¤‡æ³¨:{note}" if note else ""
        # æœ€ç»ˆæ‹¼æ¥
        return f"{head}{progress_str}{note_str}"

    # endregion

    # region å…¶ä»–å°æ¨¡å—

    # åˆ‡ç‰‡å¹¿å‘Šè¿è¥
    def get_operation_data(self, _data_params: Dict[str, Any] = None) -> Dict[str, Any]:
        """è·å–åˆ‡ç‰‡å¹¿å‘Šè¿è¥æ•°æ®"""
        bili_service = self.app_controller.get_service(ServiceNames.BILI_ADSKIP)
        operation_data = bili_service.get_operation_data()

        return operation_data

    # æœåŠ¡çŠ¶æ€
    def get_services_status(
        self, _data_params: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """è·å–æœåŠ¡çŠ¶æ€"""
        scheduler_service = self.app_controller.get_service(ServiceNames.SCHEDULER)
        services_status = scheduler_service.check_services_status()

        return services_status

    # endregion

    # region å‰ç«¯æ—¥æŠ¥å¡ç‰‡

    @safe_execute("åˆ›å»ºæ—¥æŠ¥å¡ç‰‡å¤±è´¥")
    def create_daily_summary_card(
        self, daily_raw_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """åˆ›å»ºæ¯æ—¥ä¿¡æ¯æ±‡æ€»å¡ç‰‡"""
        # å†…å®¹æ˜¯æŒ‰ç…§é¡ºåºæ’åˆ—çš„ï¼Œæ‰€ä»¥å¤©ç„¶å¯ä»¥åˆ†ç»„ï¼Œè¿˜æ˜¯ç”¨card_registryé‡Œçš„æ–¹æ³•ã€‚

        main_color = (
            daily_raw_data.get("routine", {})
            .get("data", {})
            .get("daily", {})
            .get("main_color", {})
        )
        main_color_name = main_color.get("name", "ç‹¬ç‰¹çš„é¢œè‰²")
        header_template = (
            main_color_name
            if main_color_name != "ç‹¬ç‰¹çš„é¢œè‰²"
            else main_color.get("closest_to", ColorTypes.BLUE.value)
        )

        header = JsonBuilder.build_card_header(
            title="ğŸ“Š æ¯æ—¥ä¿¡æ¯æ±‡æ€»",
            template=header_template,
        )
        elements = self.build_daily_summary_elements(daily_raw_data)
        if elements:
            system_status = daily_raw_data.get("system_status", {}).get("data", {})
            date = system_status.get("date", "")
            weekday = system_status.get("weekday", "")
            date_element = JsonBuilder.build_markdown_element(f"**{date} {weekday}**")
            elements.insert(0, date_element)

        return JsonBuilder.build_base_card_structure(elements, header)

    def build_daily_summary_elements(
        self, daily_raw_data: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """æ„å»ºæ¯æ—¥ä¿¡æ¯æ±‡æ€»å…ƒç´ """
        elements = []

        bili_video_data = daily_raw_data.get("bili_video", {}).get("info", {})
        video_list = []
        if bili_video_data:
            video_info, video_list = self.build_bili_video_elements(bili_video_data)
            elements.extend(video_info)

        operation_data = daily_raw_data.get("bili_adskip", {}).get("data", {})
        if operation_data:
            elements.extend(self.build_operation_elements(operation_data))

        services_status = daily_raw_data.get("services_status", {}).get("data", {})
        if services_status:
            elements.extend(self.build_services_status_elements(services_status))

        elements.append(JsonBuilder.build_line_element())

        elements.extend(video_list)

        routine_info = daily_raw_data.get("routine", {}).get("info", {})
        if routine_info:
            user_id = daily_raw_data.get("system_status", {}).get("user_id", "")
            elements.extend(self.build_routine_elements(routine_info, user_id))

        return elements

    # region Bç«™ä¿¡æ¯ç»„ä»¶

    def build_bili_video_elements(
        self, bili_video_data: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """æ„å»ºBç«™è§†é¢‘å…ƒç´ """
        # æ—¥æœŸçš„ä¿¡æ¯è¦åˆ†ç¦»åˆ°å…¬å…±ç»„ä»¶
        elements = []
        video_list = []
        source = bili_video_data.get("source", "unknown")

        if source == "notion_statistics":
            # notionæœåŠ¡æä¾›çš„Bç«™åˆ†ææ•°æ®
            content = self.format_notion_bili_analysis(bili_video_data)
        else:
            # å ä½ä¿¡æ¯
            content = (
                f"ğŸ”„ **ç³»ç»ŸçŠ¶æ€**\n\n{bili_video_data.get('status', 'æœåŠ¡å‡†å¤‡ä¸­...')}"
            )

        elements.append(JsonBuilder.build_markdown_element(content))

        # å¦‚æœæœ‰æ¨èè§†é¢‘ï¼Œæ·»åŠ æ¨èé“¾æ¥éƒ¨åˆ†
        if source == "notion_statistics":
            statistics = bili_video_data.get("statistics", {})

            # å…¼å®¹æ–°ç‰ˆå­—æ®µå
            top_recommendations = statistics.get("top_recommendations", None)
            if top_recommendations is None:
                top_recommendations = statistics.get("ä»Šæ—¥ç²¾é€‰æ¨è", [])

            if top_recommendations:
                # è·å–notionæœåŠ¡ä»¥æ£€æŸ¥å·²è¯»çŠ¶æ€
                notion_service = None
                if hasattr(self, "app_controller") and self.app_controller:
                    notion_service = self.app_controller.get_service("notion")

                # æ·»åŠ æ¨èè§†é¢‘æ ‡é¢˜
                video_list.append(
                    JsonBuilder.build_markdown_element("ğŸ¬ **ä»Šæ—¥ç²¾é€‰æ¨è**")
                )

                # æ·»åŠ æ¯ä¸ªæ¨èè§†é¢‘çš„ç®€åŒ–å±•ç¤º
                for i, video in enumerate(top_recommendations, 1):
                    # æ£€æŸ¥è¯¥è§†é¢‘æ˜¯å¦å·²è¯»ï¼ˆå…¼å®¹æ–°æ—§å­—æ®µï¼‰
                    video_pageid = video.get("é¡µé¢ID", video.get("pageid", ""))
                    video_read = (
                        notion_service.is_video_read(video_pageid)
                        if notion_service and video_pageid
                        else False
                    )

                    # è§†é¢‘æ ‡é¢˜
                    title = video.get("æ ‡é¢˜", "æ— æ ‡é¢˜è§†é¢‘")
                    if len(title) > 30:
                        title = title[:30] + "..."

                    # å…¼å®¹æ–°æ—§å­—æ®µæ ¼å¼
                    priority = video.get("ä¼˜å…ˆçº§", "æœªçŸ¥")
                    duration = video.get("æ—¶é•¿", "æœªçŸ¥")
                    element_id = f"bili_video_{i}"
                    video_info = JsonBuilder.build_markdown_element(
                        f"**{title}** | ä¼˜å…ˆçº§: {priority} â€¢ æ—¶é•¿: {duration}{' | å·²è¯»' if video_read else ''}",
                        element_id=element_id,
                    )
                    video_list.append(video_info)

                    # è§†é¢‘åŸºæœ¬ä¿¡æ¯å’Œé“¾æ¥æŒ‰é’®
                    video_url = video.get("é“¾æ¥", "")

                    video_button = JsonBuilder.build_button_element(
                        text="ğŸ“º Bç«™",
                        size="tiny",
                        url_data={
                            "default_url": video_url,
                            "pc_url": video_url,
                            "ios_url": video_url,
                            "android_url": convert_to_bili_app_link(video_url),
                        },
                    )

                    video_read_button = JsonBuilder.build_button_element(
                        text="âœ… å·²è¯»",
                        size="tiny",
                        action_data={
                            "card_action": "mark_bili_read_in_daily_summary",
                            "pageid": video_pageid,
                            "video_index": i,  # æ¨èè§†é¢‘åºå· (1,2,3)
                        },
                        element_id=f"mark_bili_read_{i}",
                    )
                    button_list = [video_button]
                    if (not video_read) and video_pageid:
                        button_list.append(video_read_button)

                    button_group = JsonBuilder.build_button_group_element(button_list)
                    video_list.append(button_group)

        return elements, video_list

    def format_notion_bili_analysis(self, data: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–notion Bç«™ç»Ÿè®¡æ•°æ®"""
        content = "ğŸ¯ **Bç«™ä¿¡æ¯åˆ†ææ±‡æ€»**"

        statistics = data.get("statistics", {})

        # æ€»ä½“ç»Ÿè®¡
        total_count = statistics.get("total_count", None)

        content += f"\n\nğŸ“ˆ **æ€»è®¡:** {total_count} ä¸ªæœªè¯»è§†é¢‘"

        if total_count > 0:
            # ä¼˜å…ˆçº§ç»Ÿè®¡ï¼ˆå¢åŠ æ—¶é•¿æ€»è®¡ï¼‰
            priority_stats = statistics.get("priority_stats", {})
            if priority_stats:
                content += "\nğŸ¯ **ä¼˜å…ˆçº§åˆ†å¸ƒ:**"
                for priority, info in priority_stats.items():
                    count = info.get("æ•°é‡", info.get("count", 0))
                    total_minutes = info.get("æ€»æ—¶é•¿åˆ†é’Ÿ", info.get("total_minutes", 0))
                    time_str = format_time_label(total_minutes)
                    content += f"\nâ€¢ {priority}: {count} ä¸ª ({time_str})"

            # AIæ±‡æ€»ï¼ˆåªæ˜¾ç¤ºè´¨é‡è¯„åˆ†>=5çš„ï¼‰
            ai_summary = statistics.get("ai_summary", "")
            ai_quality_score = statistics.get("ai_quality_score", 0)
            if ai_summary and ai_quality_score >= 5:
                content += f"\nğŸŒŸ **AIæ±‡æ€»:**\n{ai_summary}"

        return content

    # endregion

    # region è¿è¥æ•°æ®ç»„ä»¶
    def build_operation_elements(
        self, operation_data: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """æ„å»ºè¿è¥æ•°æ®å…ƒç´ """
        elements = []
        content = self.format_operation_data(operation_data)
        elements.append(JsonBuilder.build_markdown_element(content))
        return elements

    def format_operation_data(
        self, operation_data: Dict[str, Any], detail_mode: bool = False
    ) -> str:
        """æ ¼å¼åŒ–è¿è¥æ•°æ®ä¿¡æ¯"""
        content = "\n\nğŸ“ˆ **è¿è¥æ—¥æŠ¥**"

        # è·å–æ¯æ—¥æ•°æ®
        daily = operation_data.get("daily")
        is_monday = operation_data.get("is_monday", False)

        if daily and daily.get("success", False):
            current = daily.get("current", {})
            comparison = daily.get("comparison", {})

            # åŸºç¡€ç»Ÿè®¡ä¿¡æ¯
            date_str = current.get("stats_date", "æœªçŸ¥æ—¥æœŸ")
            content += f"\nğŸ“… **{date_str} æ•°æ®æ¦‚è§ˆ**"

            # ç”¨æˆ·æ´»è·ƒåº¦
            active_users = current.get("active_users", 0)
            new_users = current.get("new_users", 0)
            content += (
                f"\nğŸ‘¥ **ç”¨æˆ·æ´»è·ƒåº¦:** {active_users} æ´»è·ƒç”¨æˆ· (+{new_users} æ–°å¢)"
            )

            # å†…å®¹ç»Ÿè®¡
            if detail_mode:
                new_videos_user = current.get("new_videos_user", 0)
                new_videos_admin = current.get("new_videos_admin", 0)
                total_requests = current.get("total_user_requests", 0)
                content += f"\nğŸ¬ **å†…å®¹ç»Ÿè®¡:** {new_videos_user} ç”¨æˆ·è§†é¢‘ | {new_videos_admin} ç®¡ç†å‘˜è§†é¢‘"
                content += f"\nğŸ”„ **è¯·æ±‚æ€»æ•°:** {total_requests} æ¬¡"

            # ç¼“å­˜æ•ˆç‡
            cache_hits = current.get("cache_hits", 0)
            cache_rate = current.get("cache_utilization_rate", 0)
            content += f"\nâš¡ **ç¼“å­˜æ•ˆç‡:** {cache_hits} æ¬¡å‘½ä¸­ ({cache_rate:.1%})"

            # æ‹’ç»ç»Ÿè®¡
            total_rejections = current.get("total_rejections", 0)
            rejected_users = current.get("rejected_users", 0)
            if rejected_users > 0:
                rejected_rate = total_rejections / rejected_users
                content += f"\nğŸš« **æ‹’ç»è¯·æ±‚:** {total_rejections} æ¬¡ ({rejected_users} ç”¨æˆ·ï¼Œäººå‡ {rejected_rate:.1f} æ¬¡)"
            else:
                content += (
                    f"\nğŸš« **æ‹’ç»è¯·æ±‚:** {total_rejections} æ¬¡ ({rejected_users} ç”¨æˆ·)"
                )

            if detail_mode:
                # æ˜¾ç¤ºå…³é”®å˜åŒ–è¶‹åŠ¿
                if comparison:
                    trends = []

                    # æ£€æŸ¥ç”¨æˆ·æ´»è·ƒåº¦å˜åŒ–
                    if "active_users" in comparison:
                        change = comparison["active_users"].get("change", 0)
                        trend = comparison["active_users"].get("trend", "")
                        if abs(change) >= 5:  # æ˜¾è‘—å˜åŒ–
                            trend_emoji = "ğŸ“ˆ" if trend == "up" else "ğŸ“‰"
                            trends.append(f"æ´»è·ƒç”¨æˆ·{trend_emoji}{abs(change)}")

                    # æ£€æŸ¥è¯·æ±‚é‡å˜åŒ–
                    if "total_user_requests" in comparison:
                        change = comparison["total_user_requests"].get("change", 0)
                        trend = comparison["total_user_requests"].get("trend", "")
                        if abs(change) >= 20:  # æ˜¾è‘—å˜åŒ–
                            trend_emoji = "ğŸ“ˆ" if trend == "up" else "ğŸ“‰"
                            trends.append(f"è¯·æ±‚é‡{trend_emoji}{abs(change)}")

                    if trends:
                        content += f"\nğŸ“Š **ä»Šæ—¥å˜åŒ–:** {' | '.join(trends)}"

                # å¹¿å‘Šæ£€æµ‹ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰ï¼‰
                ads_detected = current.get("ads_detected", 0)
                total_ad_duration = current.get("total_ad_duration", 0)
                ad_rate = ads_detected / total_requests if total_requests > 0 else 0
                if ads_detected > 0:
                    ad_minutes = int(total_ad_duration / 60) if total_ad_duration else 0
                    content += f"\nğŸ¯ **å¹¿å‘Šæ£€æµ‹:** {ads_detected} ä¸ªå¹¿å‘Šï¼Œæ€»æ—¶é•¿ {ad_minutes} åˆ†é’Ÿï¼Œå æ¯” {ad_rate:.1%}"

        # å¦‚æœæ˜¯å‘¨ä¸€ï¼Œæ·»åŠ å‘¨æŠ¥æ•°æ®
        if is_monday:
            weekly = operation_data.get("weekly")
            if weekly and weekly.get("success", False):
                content += self.format_weekly_operation_data(weekly.get("data", {}))

        return content

    def format_weekly_operation_data(self, weekly_data: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–å‘¨è¿è¥æ•°æ®"""
        content = "\n\nğŸ“… **æœ¬å‘¨è¿è¥æ¦‚è§ˆ**"

        # å‘¨æœŸä¿¡æ¯
        week_start = weekly_data.get("week_start_date", "")
        week_end = weekly_data.get("week_end_date", "")
        if week_start and week_end:
            content += f"\nğŸ—“ï¸ **ç»Ÿè®¡å‘¨æœŸ:** {week_start} è‡³ {week_end}"

        # ç”¨æˆ·ç»Ÿè®¡
        total_users = weekly_data.get("total_users", 0)
        weekly_new_users = weekly_data.get("weekly_new_users", 0)
        weekly_churned_users = weekly_data.get("weekly_churned_users", 0)
        active_users = weekly_data.get("active_users", 0)
        content += f"\nğŸ‘¥ **ç”¨æˆ·æ¦‚å†µ:** {total_users} æ€»ç”¨æˆ· | {active_users} æ´»è·ƒ | +{weekly_new_users} æ–°å¢ | -{weekly_churned_users} æµå¤±"

        # ä»˜è´¹ç”¨æˆ·
        free_users = weekly_data.get("free_users", 0)
        paid_users = weekly_data.get("paid_users", 0)
        if paid_users > 0:
            paid_rate = (
                paid_users / (free_users + paid_users) * 100
                if (free_users + paid_users) > 0
                else 0
            )
            content += f"\nğŸ’° **ä»˜è´¹æƒ…å†µ:** {paid_users} ä»˜è´¹ç”¨æˆ· ({paid_rate:.1f}%)"

        # å†…å®¹åˆ†æ
        weekly_unique_videos = weekly_data.get("weekly_unique_videos", 0)
        weekly_requests = weekly_data.get("weekly_total_requests", 0)
        cache_rate = weekly_data.get("weekly_cache_utilization_rate", 0)
        content += f"\nğŸ“Š **å†…å®¹æ´»åŠ¨:** {weekly_unique_videos} è§†é¢‘ | {weekly_requests} è¯·æ±‚ | ç¼“å­˜å‘½ä¸­ç‡ {cache_rate:.1%}"

        # å¹¿å‘Šåˆ†æ
        weekly_ad_videos = weekly_data.get("weekly_ad_videos", 0)
        weekly_ad_time_ratio = weekly_data.get("weekly_ad_time_ratio", 0)
        if weekly_ad_videos > 0:
            content += f"\nğŸ¯ **å¹¿å‘Šåˆ†æ:** {weekly_ad_videos} ä¸ªå¹¿å‘Šè§†é¢‘ ({weekly_ad_time_ratio:.2%} æ—¶é•¿å æ¯”)"

        return content

    # endregion

    # region æœåŠ¡çŠ¶æ€ç»„ä»¶
    def build_services_status_elements(
        self, services_status: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """æ„å»ºæœåŠ¡çŠ¶æ€å…ƒç´ """
        elements = []
        content = self.format_services_status(services_status)
        elements.append(JsonBuilder.build_markdown_element(content))
        return elements

    def format_services_status(self, services_status: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æœåŠ¡çŠ¶æ€ä¿¡æ¯"""
        content = ""
        # ä¸¤ä¸ª\nå¼€å¤´ä¼šè¢«è‡ªåŠ¨å¤„ç†æ‰ï¼Œæ‰€ä»¥ä¸ç”¨é¢å¤–å†™ä»£ç 

        services = services_status.get("services", {})

        # Bç«™APIæœåŠ¡çŠ¶æ€ï¼Œåªåœ¨å¼‚å¸¸æ˜¯æ˜¾ç¤º
        bili_api = services.get("bilibili_api", {})
        if bili_api.get("enabled", False):
            status = bili_api.get("status", "unknown")
            message = bili_api.get("message", "")
            response_time = bili_api.get("response_time", "")
            url = bili_api.get("url", "")

            status_emoji = {
                "healthy": "âœ…",
                "warning": "âš ï¸",
                "error": "âŒ",
                "disabled": "â¸ï¸",
            }.get(status, "â“")

            if status != "healthy":
                content += f"\n\n{status_emoji} **{bili_api.get('service_name', 'Bç«™APIæœåŠ¡')}**"
                content += f"\nçŠ¶æ€: {message}"
                if response_time:
                    content += f" ({response_time})"
                if url and status != "error":
                    # æˆªæ–­é•¿URLæ˜¾ç¤º
                    display_url = url if len(url) <= 40 else url[:37] + "..."
                    content += f"\nåœ°å€: {display_url}"

        else:
            content += "\n\nâ¸ï¸ **Bç«™APIæœåŠ¡**: æœªå¯ç”¨"

        # GradioæœåŠ¡çŠ¶æ€
        gradio = services.get("gradio", {})
        if gradio.get("enabled", False):
            status = gradio.get("status", "unknown")
            message = gradio.get("message", "")
            response_time = gradio.get("response_time", "")
            url = gradio.get("url", "")

            status_emoji = {
                "healthy": "âœ…",
                "warning": "âš ï¸",
                "error": "âŒ",
                "disabled": "â¸ï¸",
            }.get(status, "â“")

            content += (
                f"\n\n{status_emoji} **{gradio.get('service_name', 'Gradioå›¾åƒæœåŠ¡')}**"
            )
            if status != "healthy":
                content += f"\nçŠ¶æ€: {message}"
                if response_time:
                    content += f" ({response_time})"
            if url and status != "error":
                # æˆªæ–­é•¿URLæ˜¾ç¤º
                display_url = url if len(url) <= 40 else url[:37] + "..."
                content += f"\nåœ°å€: {display_url}"

            # æ˜¾ç¤ºä»¤ç‰Œä¿¡æ¯
            token_info = gradio.get("token_info", {})
            if token_info.get("has_token", False):
                token_status = token_info.get("status", "unknown")
                if token_status == "valid":
                    expires_in_hours = token_info.get("expires_in_hours", 0)
                    expires_at = token_info.get("expires_at", "")
                    # æ ¼å¼åŒ–æ—¶é—´ä¸º mm-dd hh:mm
                    formatted_expires_at = ""
                    if expires_at:
                        try:
                            # å…¼å®¹å¸¦æ—¶åŒºçš„ISOæ ¼å¼
                            if "+" in expires_at or "Z" in expires_at:
                                # å»æ‰æ—¶åŒºä¿¡æ¯
                                expires_at_clean = expires_at.split("+")[0].replace(
                                    "Z", ""
                                )
                            else:
                                expires_at_clean = expires_at
                            dt = datetime.fromisoformat(expires_at_clean)
                            formatted_expires_at = dt.strftime("%m-%d %H:%M")
                        except Exception:
                            formatted_expires_at = expires_at  # è§£æå¤±è´¥åˆ™åŸæ ·è¾“å‡º
                    if expires_in_hours <= 24:  # 24å°æ—¶å†…è¿‡æœŸæ˜¾ç¤ºè­¦å‘Š
                        content += f"\nâš ï¸ ä»¤ç‰Œå°†åœ¨ {expires_in_hours}å°æ—¶ åè¿‡æœŸ ({formatted_expires_at})"
                    else:
                        content += f"\nğŸ”‘ ä»¤ç‰Œæœ‰æ•ˆæœŸè‡³: {formatted_expires_at}"
                elif token_status == "expired":
                    expires_at = token_info.get("expires_at", "")
                    formatted_expires_at = ""
                    if expires_at:
                        try:
                            if "+" in expires_at or "Z" in expires_at:
                                expires_at_clean = expires_at.split("+")[0].replace(
                                    "Z", ""
                                )
                            else:
                                expires_at_clean = expires_at
                            dt = datetime.fromisoformat(expires_at_clean)
                            formatted_expires_at = dt.strftime("%m-%d %H:%M")
                        except Exception:
                            formatted_expires_at = expires_at
                    content += f"\nâŒ ä»¤ç‰Œå·²äº{formatted_expires_at}è¿‡æœŸï¼Œéœ€è¦æ›´æ–°"
                elif token_status == "parse_error":
                    content += "\nâš ï¸ ä»¤ç‰Œæ—¶é—´è§£æå¼‚å¸¸"
                elif token_status == "no_expiry_info":
                    content += "\nğŸ”‘ ä»¤ç‰Œå·²é…ç½® (æ— è¿‡æœŸä¿¡æ¯)"
        else:
            content += "\n\nâ¸ï¸ **Gradioå›¾åƒæœåŠ¡**: æœªå¯ç”¨"

        return content

    # endregion

    # region æ—¥å¸¸ç»„ä»¶-æ€»

    def build_routine_elements(
        self, routine_data: Dict[str, Any], user_id: str
    ) -> List[Dict[str, Any]]:
        """æ„å»ºæ—¥å¸¸å…ƒç´ """
        elements = []
        image_key = routine_data.get("daily", {}).get("image_key", "")
        main_color = routine_data.get("daily", {}).get("main_color", {})
        weekly_data = routine_data.get("weekly", {})

        if image_key:
            image_element = JsonBuilder.build_image_element(
                image_key=image_key,
                alt=f"æ˜¨å¤©ä½ çš„{main_color.get('max_weight_category', '')}å°ç« ",
                title="æ˜¨æ—¥ä¸ªæ€§å°ç« ",
                corner_radius="5px",
                scale_type="crop_center",
                size="80px 90px",
            )
            elements.append(image_element)

        if weekly_data:
            # å…ˆå¢åŠ cardé‡Œçš„å†…å®¹ï¼Œå†æŠŠå…¶ä»–å†…å®¹åˆ›å»ºæˆæ–‡æ¡£
            pie_raw_data = weekly_data.get("category_stats", [])

            if pie_raw_data:
                pie_data = []
                color_mapping = {}  # ç”¨äºå­˜å‚¨ç±»å‹åˆ°é¢œè‰²çš„æ˜ å°„
                for item in pie_raw_data:
                    type_name = item.get("category", "") or "æ— åˆ†ç±»"
                    color = item.get("color", "#959BEE")  # é»˜è®¤é¢œè‰²

                    pie_data.append(
                        {
                            "type": type_name,
                            "value": round(
                                item.get("category_total_duration", 0) / 60, 1
                            ),
                        }
                    )
                    color_mapping[type_name] = color
                pie_element = JsonBuilder.build_chart_element(
                    chart_type="pie",
                    title="ä¸Šå‘¨æ—¶é—´ç»Ÿè®¡",
                    data=pie_data,
                    color_mapping=color_mapping,
                    formatter="{type}: {value}å°æ—¶,{_percent_}%",
                )
                elements.append(pie_element)

            # è¿™é‡Œç›´æ¥æ·»åŠ æ–‡æ¡£ï¼Œè¿˜éœ€è¦å¼‚æ­¥è°ƒç”¨llmï¼Ÿè¿™ä¸ªä¼¼ä¹ä¸åº”è¯¥æ˜¯å‰ç«¯åšçš„äº‹ï¼Œé‚£å°±å…ˆå¢åŠ æ–‡æ¡£å§ã€‚
            # è¿™é‡Œçš„ä¸šåŠ¡é€»è¾‘ç»“æœå°±æ˜¯å¾€ä¸€ä¸ªtokensçš„æ–‡ä»¶å¤¹å¢åŠ ä¸€ä¸ªpageï¼Œå­˜åœ¨æœ¬åœ°
            weekly_record = self.routine_business.load_weekly_record(user_id)
            root_folder_token = weekly_record.get("root_folder_token", "")
            business_folder_token = weekly_record.get("business_folder_token", {}).get(
                "å‘¨æŠ¥å‘Š", ""
            )
            document_manager = self.app_controller.get_adapter(
                AdapterNames.FEISHU
            ).cloud_manager

            need_update_tokens = False
            if not root_folder_token:
                root_folder_token = document_manager.get_user_root_folder_token(user_id)
                weekly_record["root_folder_token"] = root_folder_token
                need_update_tokens = True
            if not business_folder_token:
                business_folder_token = document_manager.get_user_business_folder_token(
                    user_id, "å‘¨æŠ¥å‘Š", root_folder_token
                )
                weekly_record["business_folder_token"]["å‘¨æŠ¥å‘Š"] = business_folder_token
                need_update_tokens = True

            if need_update_tokens:
                self.routine_business.save_weekly_record(user_id, weekly_record)

            title = weekly_data.get("document_title", "")
            # åŸå­åŒ–åŒæ­¥è°ƒç”¨ï¼šå…ˆåˆ›å»ºæ–‡æ¡£ï¼Œå†å†™å…¥å—ï¼ˆå‡å¸¦æŒ‡æ•°é€€é¿ï¼‰ã€‚å¦‚éœ€éé˜»å¡ï¼Œæœªæ¥åˆ‡æ¢åˆ°å¼‚æ­¥å®¢æˆ·ç«¯ç»Ÿä¸€è°ƒåº¦ã€‚
            doc_data = document_manager.create_document(
                folder_token=business_folder_token,
                document_title=title,
            )
            # SDK è¿”å›è·¯å¾„ï¼šdata.document.document_id
            document_id = (
                getattr(getattr(doc_data, "document", None), "document_id", None)
                if doc_data
                else None
            )
            if document_id:
                content = self.generate_weekly_document_content(routine_data)
                block_resp = document_manager.create_document_block_descendant(
                    document_id=document_id,
                    block_data=content,
                    document_title=title,
                )
                url = f"https://ddsz-peng13.feishu.cn/docx/{document_id}"
                folder_url = f"https://ddsz-peng13.feishu.cn/drive/folder/{business_folder_token}"
                # è¦çœ‹çœ‹æ€ä¹ˆè®¾ç½®ä¸ºé»˜è®¤æ‰“å¼€é“¾æ¥ï¼Œä½†è¿™æ˜¯å°äº‹ï¼Œè¿˜æ˜¯è¦å…ˆåŠ å†…å®¹ï¼Œä»¥åŠåç»­ç¨å¾®äººå¤šä¸€ç‚¹ä¹‹å‰å°±è¦åšå¼‚æ­¥çš„æ”¹é€ ï¼ŒåŒ…æ‹¬é…åˆLLM
                markdown_element = JsonBuilder.build_markdown_element(
                    content=f"[æŸ¥çœ‹åˆ†æï¼š{title}]({url})\n[è®¿é—®æŠ¥å‘Šæ–‡ä»¶å¤¹]({folder_url})"
                )
                elements.append(markdown_element)
            else:
                debug_utils.log_and_print("åˆ›å»ºå‘¨æŠ¥å‘Šæ–‡æ¡£å¤±è´¥", log_level="ERROR")

        return elements

    # endregion

    # region æ—¥å¸¸ç»„ä»¶-å‘¨æŠ¥å‘Š

    def generate_weekly_document_content(
        self, routine_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ç”Ÿæˆå‘¨æŠ¥å‘Šæ–‡æ¡£å†…å®¹(ä¹Ÿå¯èƒ½å…¼å®¹æˆæœˆæŠ¥)"""
        # ä»¥åµŒå¥—å—çš„æ–¹å¼ä¸€æ¬¡æ€§ç»„è£…å¥½
        # æ¯ä¸ªå…ƒç´ éƒ½åŒ…å«äº†è‡ªå·±çš„idè¿›childrenå’Œè‡ªå·±çš„å†…å®¹ï¼Œè¿›descendants
        weekly_data = routine_data.get("weekly", {})
        weekly_table_data = routine_data.get("weekly", {}).get("timetable", {})

        children = []
        descendants = []
        # å…ˆæ„å»ºè¡¨æ ¼
        document_manager = self.app_controller.get_adapter(
            AdapterNames.FEISHU
        ).cloud_manager

        # å®‰å…¨è·å–æ•°æ®
        time_labels: List[str] = weekly_table_data.get("time_labels", [])
        days_data: Dict[str, Any] = weekly_table_data.get("days", {})

        # é¡¶å±‚ childrenï¼ˆä¸¤ä¸ªå—ï¼šæ ‡é¢˜ + è¡¨æ ¼ï¼‰
        # æ–‡æ¡£å¤§æ¦‚è¦åœ¨è¿™é‡Œå¤„ç†ï¼Œé‚£ä¹ˆchildrenå’Œdescendentsè¦ä¸€èµ·åŠ å’¯ï¼Ÿç„¶åå†è¿½åŠ ä¹‹å‰çš„è¡¨æ ¼ï¼Œè¿™ä¸ªä½œä¸ºä¸€ä¸ªæ€»å®¹å™¨è¿˜æ˜¯ä¸é”™çš„
        heading_block_id = "heading_timetable"
        note_block_id = "note_timetable"
        table_block_id = "table_timetable"
        children = [heading_block_id, note_block_id, table_block_id]

        # æ ‡é¢˜å—ï¼ˆé‡‡ç”¨ heading1ï¼‰
        heading_block = document_manager.create_formated_text_block(
            block_id=heading_block_id,
            text="ä¸ªäººæ—¶é—´è¡¨",
            block_type="heading1",
        )
        descendants.append(heading_block)

        note_block = document_manager.create_text_block(
            block_id=note_block_id,
            text="\n".join(weekly_data.get("note_list", [])),
        )
        descendants.append(note_block)

        # è¡¨å¤´æ˜ å°„
        day_label_map = {
            "mon": "å‘¨ä¸€",
            "tue": "å‘¨äºŒ",
            "wed": "å‘¨ä¸‰",
            "thu": "å‘¨å››",
            "fri": "å‘¨äº”",
            "sat": "å‘¨å…­",
            "sun": "å‘¨æ—¥",
        }
        day_keys: List[str] = list(day_label_map.keys())

        # è¡¨æ ¼ children é¡ºåºï¼šæŒ‰è¡Œ (header -> æ¯ä¸ªæ—¶é—´ç‚¹)ï¼Œæ¯è¡ŒæŒ‰åˆ— (time -> mon..sun)
        table_children_ids: List[str] = []

        # è¡¨å¤´è¡Œ cell ä¸æ–‡æœ¬
        header_cell_ids = ["cell_header_time"] + [
            f"cell_header_{day}" for day in day_keys
        ]
        header_text_ids = ["text_header_time"] + [
            f"text_header_{day}" for day in day_keys
        ]
        table_children_ids.extend(header_cell_ids)

        # æ·»åŠ è¡¨å¤´ cell ä¸ text å—
        # æ—¶é—´åˆ—è¡¨å¤´
        descendants.append(
            document_manager.create_table_cell_block(
                block_id=header_cell_ids[0], children=[header_text_ids[0]]
            )
        )
        descendants.append(
            document_manager.create_text_block(
                block_id=header_text_ids[0], text="æ—¶é—´", align=2
            )
        )
        # æ˜ŸæœŸåˆ—è¡¨å¤´
        for idx, day in enumerate(day_keys, start=1):
            descendants.append(
                document_manager.create_table_cell_block(
                    block_id=header_cell_ids[idx], children=[header_text_ids[idx]]
                )
            )
            descendants.append(
                document_manager.create_text_block(
                    block_id=header_text_ids[idx], text=day_label_map[day], align=2
                )
            )

        # æ•°æ®è¡Œ cell ä¸æ–‡æœ¬
        for time_label in time_labels:
            # ä½¿ç”¨å°æ—¶ä½œä¸º id ç‰‡æ®µï¼Œå¦‚ "00"ã€"02"ã€"12" ç­‰
            row_cell_ids = [f"cell_{time_label}"] + [
                f"cell_{time_label}_{day}" for day in day_keys
            ]
            row_text_ids = [f"text_{time_label}"] + [
                f"text_{time_label}_{day}" for day in day_keys
            ]
            table_children_ids.extend(row_cell_ids)

            # æ—¶é—´åˆ—å•å…ƒæ ¼
            descendants.append(
                document_manager.create_table_cell_block(
                    block_id=row_cell_ids[0], children=[row_text_ids[0]]
                )
            )
            descendants.append(
                document_manager.create_text_block(
                    block_id=row_text_ids[0], text=time_label, align=2
                )
            )

            # æ¯å¤©åˆ—å•å…ƒæ ¼
            for col_index, day in enumerate(day_keys, start=1):
                # å–å¯¹åº”æ§½ä½æ•°æ®
                slot_info: Dict[str, Any] = days_data.get(day, {}).get(time_label, {})
                slot_text: str = slot_info.get("text", "")
                slot_color = slot_info.get("color", None)
                background_color_id = (
                    slot_color.background_color_id
                    if hasattr(slot_color, "background_color_id")
                    else -1
                )

                descendants.append(
                    document_manager.create_table_cell_block(
                        block_id=row_cell_ids[col_index],
                        children=[row_text_ids[col_index]],
                    )
                )
                descendants.append(
                    document_manager.create_text_block(
                        block_id=row_text_ids[col_index],
                        text=slot_text,
                        background_color=background_color_id,
                        align=2,
                    )
                )

        # è¡¨æ ¼å—
        row_size = 1 + len(time_labels)
        column_size = 1 + len(day_keys)
        table_block = document_manager.create_table_block(
            row_size=row_size,
            column_size=column_size,
            block_id=table_block_id,
            children=table_children_ids,
            column_width=[70] + [110] * len(day_keys),
            header_row=True,
            header_column=True,
        )
        descendants.append(table_block)

        # æ·»åŠ é‡è¦æŠ¥å‘Šå’Œæ´»åŠ¨æ˜ç»†
        from collections import defaultdict

        event_records = weekly_data.get("event_summary", [])
        category_stats = weekly_data.get("category_stats", [])

        # === é‡è¦æŠ¥å‘Š ===
        children.append("heading_important_report")
        descendants.append(
            document_manager.create_formated_text_block(
                block_id="heading_important_report", text="é‡è¦æŠ¥å‘Š", block_type="heading1"
            )
        )

        children.append("heading_important_report_interval")
        descendants.append(
            document_manager.create_formated_text_block(
                block_id="heading_important_report_interval", text="äº‹ä»¶é—´éš”", block_type="heading2"
            )
        )


        important_lines = []
        # ç­›é€‰æœ‰é—´éš”ä¸”display_unitä¸ä¸ºç©ºçš„è®°å½•
        valid_records = []
        for record in event_records:
            if (record.get("event_interval_minutes") and
                not pd.isna(record.get("event_interval_minutes")) and
                record.get("display_unit")):
                valid_records.append(record)

        # æŒ‰é—´éš”ä»å°åˆ°å¤§æ’åº
        sorted_records = sorted(valid_records,
                               key=lambda x: x.get("event_interval_minutes", float('inf')))

        # å»é‡ï¼šåŸºäºdisplay_unitå’Œevent_interval_minutes
        seen = set()
        unique_records = []
        for record in sorted_records:
            key = (record["display_unit"], record["event_interval_minutes"])
            if key not in seen:
                seen.add(key)
                unique_records.append(record)

        # ç”Ÿæˆæ˜¾ç¤ºæ–‡æœ¬
        for record in unique_records:
            display_unit = record["display_unit"]
            minutes = int(round(float(record["event_interval_minutes"])))
            interval_label = format_time_label(minutes)
            important_lines.append(f"{display_unit}é—´éš”ï¼š{interval_label} | {minutes} åˆ†é’Ÿ")

        children.append("text_important_overview")
        descendants.append(
            document_manager.create_text_block(
                block_id="text_important_overview", text="\n".join(important_lines)
            )
        )

        # === æ´»åŠ¨æ•°æ®åˆ†ç±»æ˜ç»† ===
        children.append("heading_category_details")
        descendants.append(
            document_manager.create_formated_text_block(
                block_id="heading_category_details", text="æ´»åŠ¨æ•°æ®åˆ†ç±»æ˜ç»†", block_type="heading1"
            )
        )

        # åˆ†ç±»æ’åºï¼šæœªè®°å½•æœ€åï¼Œå…¶ä»–æŒ‰æ€»æ—¶é•¿é™åº
        category_totals = {stat["category"]: stat["category_total_duration"] for stat in category_stats}
        sorted_categories = sorted(category_totals.keys(),
                                 key=lambda x: (1 if x == "æœªè®°å½•" else 0, -category_totals[x]))

        # æŒ‰åˆ†ç±»åˆ†ç»„äº‹ä»¶è®°å½•
        category_events = defaultdict(lambda: defaultdict(list))
        for record in event_records:
            category_events[record["category"]][record["event_name"]].append(record)

        def format_duration_stats(record):
            """æ ¼å¼åŒ–æ—¶é•¿ç»Ÿè®¡ä¿¡æ¯"""
            count = int(record["count"])
            force_new_line = False
            if count <= 1:
                return "", force_new_line

            avg = int(round(record["avg_duration"]))
            min_dur = int(round(record["min_duration"]))
            max_dur = int(round(record["max_duration"]))

            if avg == min_dur == max_dur or (min_dur != 0 and max_dur / min_dur < 1.2):
                return f"å¹³å‡æ—¶é•¿ï¼š{format_time_label(avg)}", force_new_line

            force_new_line = True

            final_str = f"å¹³å‡æ—¶é•¿ï¼š{format_time_label(avg)}ï½œæœ€çŸ­ï¼š{format_time_label(min_dur)}ï½œæœ€é•¿ï¼š{format_time_label(max_dur)}"

            if max_dur > 30:
                max_start = str(record["max_duration_start_at"])[:16]
                week_day = day_label_map[record["max_duration_start_at"].strftime("%a").lower()]
                final_str += f"ï¼Œ{max_start} {week_day}"

            return final_str, force_new_line

        # ç”Ÿæˆå„åˆ†ç±»å†…å®¹
        for category in sorted_categories:
            # åˆ†ç±»æ ‡é¢˜
            children.extend([f"heading_cat_{category}", f"text_cat_{category}"])
            descendants.extend([
                document_manager.create_formated_text_block(
                    block_id=f"heading_cat_{category}", text=f"ğŸ“œ {category if category else 'æ— åˆ†ç±»'}", block_type="heading2"
                ),
                document_manager.create_text_block(
                    block_id=f"text_cat_{category}", text=f"æ€»æ—¶é•¿ï¼š{format_time_label(category_totals[category])}"
                )
            ])

            # è¯¥åˆ†ç±»ä¸‹çš„äº‹ä»¶ï¼ŒæŒ‰äº‹ä»¶æ€»æ—¶é•¿æ’åº
            events = category_events[category]
            sorted_events = sorted(events.items(),
                                 key=lambda x: x[1][0].get("event_total_duration", 0),
                                 reverse=True)

            for event_name, records in sorted_events:
                # äº‹ä»¶æ ‡é¢˜
                children.extend([f"heading_ev_{category}_{event_name}", f"text_ev_{category}_{event_name}"])
                descendants.append(
                    document_manager.create_formated_text_block(
                        block_id=f"heading_ev_{category}_{event_name}", text=event_name, block_type="heading3"
                    )
                )

                # äº‹ä»¶åŸºæœ¬ä¿¡æ¯
                first_record = records[0]
                info_parts = [
                    f"æ€»æ—¶é•¿ï¼š{format_time_label(first_record['event_total_duration'])}",
                    f"äº‹ä»¶æ¬¡æ•°ï¼š{int(first_record['event_total_count'])}"
                ]

                # æ·»åŠ åˆ†ç±»é—´éš”ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                if (first_record.get("category_interval_minutes") and
                    not pd.isna(first_record.get("category_interval_minutes"))):
                    minutes = first_record["category_interval_minutes"]
                    interval_label = format_time_label(minutes)
                    info_parts.append(f"äº‹ä»¶é—´éš”ï¼š{interval_label}")

                # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæˆæ–¹å¼è®°å½•
                degree_records = [r for r in records if r.get("degree")]
                no_degree_records = [r for r in records if not r.get("degree")]

                final_str = " ï½œ ".join(info_parts)

                # å¦‚æœæ²¡æœ‰å®Œæˆæ–¹å¼è®°å½•ï¼Œåœ¨äº‹ä»¶çº§æ˜¾ç¤ºç»Ÿè®¡
                if not degree_records and no_degree_records:
                    extra_str, force_new_line = format_duration_stats(no_degree_records[0])
                    if extra_str:
                        if force_new_line or len(info_parts) > 2:
                            final_str += "\n"
                        final_str += extra_str

                descendants.append(
                    document_manager.create_text_block(
                        block_id=f"text_ev_{category}_{event_name}", text=final_str
                    )
                )

                # å¤„ç†å®Œæˆæ–¹å¼è®°å½•
                if degree_records:
                    # åˆ›å»ºå®Œæˆæ–¹å¼å¼•ç”¨å®¹å™¨çš„childrenåˆ—è¡¨
                    degree_children = []

                    for record in sorted(degree_records, key=lambda x: x.get("total_duration", 0), reverse=True):
                        degree = record.get("degree", "æœªåˆ†çº§")
                        degree_children.extend([f"heading_deg_{category}_{event_name}_{degree}", f"text_deg_{category}_{event_name}_{degree}"])

                        descendants.append(
                            document_manager.create_formated_text_block(
                                block_id=f"heading_deg_{category}_{event_name}_{degree}", text=degree, block_type="heading4"
                            )
                        )

                        # å®Œæˆæ–¹å¼ç»Ÿè®¡ä¿¡æ¯
                        parts = [
                            f"æ€»æ—¶é•¿ï¼š{format_time_label(record['total_duration'])}",
                            f"æ¬¡æ•°ï¼š{int(record['count'])}",
                        ]
                        if (record.get("degree_interval_minutes") and
                            not pd.isna(record.get("degree_interval_minutes"))):
                            interval_minutes = int(round(float(record["degree_interval_minutes"])))
                            interval_label = format_time_label(interval_minutes)
                            parts.append(f"é—´éš”æ—¶é—´ï¼š{interval_label} ({interval_minutes} åˆ†é’Ÿ)")

                        degree_str = " ï½œ ".join(parts)
                        extra_str, force_new_line = format_duration_stats(record)
                        if extra_str:
                            if force_new_line or len(parts) > 2:
                                degree_str += "\n"
                            degree_str += extra_str

                        descendants.append(
                            document_manager.create_text_block(
                                block_id=f"text_deg_{category}_{event_name}_{degree}", text=degree_str
                            )
                        )

                    # åˆ›å»ºå®Œæˆæ–¹å¼å¼•ç”¨å®¹å™¨
                    quote_block_id = f"quote_deg_{category}_{event_name}"
                    children.append(quote_block_id)
                    descendants.append(
                        document_manager.create_quote_block(
                            block_id=quote_block_id,
                            children=degree_children
                        )
                    )

        # ç»„åˆé¡¶å±‚å†…å®¹
        content = document_manager.create_descendant_block_body(
            index=0, children=children, descendants=descendants
        )
        return content

    # endregion

    # region å›è°ƒå¤„ç†

    @require_service("notion", "æ ‡è®°æœåŠ¡æš‚æ—¶ä¸å¯ç”¨")
    @safe_execute("å¤„ç†Bç«™æ ‡è®°å·²è¯»å¤±è´¥")
    def mark_bili_read_v2(self, action_value: Dict[str, Any]) -> ProcessResult:
        """å¤„ç†Bç«™è§†é¢‘æ ‡è®°å·²è¯»çš„å›è°ƒ"""
        # è·å–notionæœåŠ¡
        notion_service = self.app_controller.get_service(ServiceNames.NOTION)

        # è·å–å‚æ•°
        pageid = action_value.get("pageid", "")
        video_index = action_value.get("video_index", 1)

        # æ‰§è¡Œæ ‡è®°ä¸ºå·²è¯»æ“ä½œ
        success = notion_service.mark_video_as_read(pageid)
        if not success:
            return ProcessResult.error_result("æ ‡è®°ä¸ºå·²è¯»å¤±è´¥")

        return ProcessResult.success_result(
            ResponseTypes.SCHEDULER_CARD_UPDATE_BILI_BUTTON,
            {
                "toast": {
                    "type": "success",
                    "content": f"å·²æ ‡è®°ç¬¬{video_index}ä¸ªæ¨èä¸ºå·²è¯»",
                },
                "remove_element_id": f"mark_bili_read_{video_index}",
                "text_element_id": f"bili_video_{video_index}",
            },
        )

    # endregion

    # region å†å²æ–¹æ³•ç¼“å­˜
    def generate_weekly_card_content(
        self, weekly_table_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ç”Ÿæˆå‘¨æŠ¥å‘Šå¡ç‰‡å†…å®¹"""
        elements = []
        elements.append(JsonBuilder.build_markdown_element("ä¸Šå‘¨æ—¶é—´è¡¨"))
        columns = []
        columns.append(
            JsonBuilder.build_table_column_element(
                name="time",
                display_name="æ—¶é—´",
                data_type="text",
                width="80px",
            )
        )
        day_dict = {
            "mon": "å‘¨ä¸€",
            "tue": "å‘¨äºŒ",
            "wed": "å‘¨ä¸‰",
            "thu": "å‘¨å››",
            "fri": "å‘¨äº”",
            "sat": "å‘¨å…­",
            "sun": "å‘¨æ—¥",
        }
        for day_key, day_name in day_dict.items():
            columns.append(
                JsonBuilder.build_table_column_element(
                    name=day_key,
                    display_name=day_name,
                    data_type="options",
                    width="120px",
                )
            )
        table_element = JsonBuilder.build_table_element(
            columns=columns,
            rows=[],
            freeze_first_column=True,
        )

        time_labels = weekly_table_data.get("time_labels", [])
        days_data = weekly_table_data.get("days", {})

        DEFAULT_SLOT_DATA = {
            "text": "ç©ºé—²",
            "color": ColorTypes.GREY,
            "category_label": "ç©ºé—²",
        }

        for time_label in time_labels:
            row = {"time": time_label}

            for day_key in day_dict.keys():
                day_data = days_data.get(day_key, {})
                slot_data = day_data.get(time_label, DEFAULT_SLOT_DATA)

                row[day_key] = [
                    {
                        "text": slot_data.get("text", DEFAULT_SLOT_DATA.get("text")),
                        "color": slot_data.get(
                            "color", DEFAULT_SLOT_DATA.get("color")
                        ).option_value,
                    }
                ]

            table_element["rows"].append(row)

        elements.append(table_element)

        return elements

    # endregion
