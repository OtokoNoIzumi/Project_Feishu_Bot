"""æ¯æ—¥ä¿¡æ¯æ±‡æ€»ä¸šåŠ¡

å¤„ç†æ¯æ—¥ä¿¡æ¯æ±‡æ€»çš„å®Œæ•´ä¸šåŠ¡é€»è¾‘ï¼ŒåŒ…æ‹¬ï¼š
1. Bç«™ä¿¡æ¯åˆ†ææ•°æ®æ„å»º
2. è¿è¥æ•°æ®è·å–ä¸å¤„ç†
3. æ—¥æŠ¥å¡ç‰‡ç”Ÿæˆ
4. ç”¨æˆ·æƒé™éªŒè¯
"""

import os
import json
import copy
from typing import Dict, Any, List
from datetime import datetime, timedelta
import random
import pandas as pd
import numpy as np

from Module.Common.scripts.common import debug_utils
from Module.Services.constants import (
    ServiceNames,
    ResponseTypes,
    SchedulerConstKeys,
    AdapterNames,
    ColorTypes,
)
from Module.Business.processors.base_processor import (
    BaseProcessor,
    ProcessResult,
    require_service,
    safe_execute,
)
from Module.Services.bili_adskip_service import convert_to_bili_app_link
from Module.Business.shared_process import format_time_label
from Module.Business.routine_record import RoutineRecord, wax_stamp_prompt
from Module.Adapters.feishu.cards.json_builder import JsonBuilder


class DailySummaryBusiness(BaseProcessor):
    """
    æ¯æ—¥ä¿¡æ¯æ±‡æ€»ä¸šåŠ¡

    è´Ÿè´£å¤„ç†æ¯æ—¥ä¿¡æ¯æ±‡æ€»çš„å®Œæ•´ä¸šåŠ¡æµç¨‹
    """

    # region åç«¯ä¸šåŠ¡å…¥å£
    # ä¸šåŠ¡å †æ ˆ
    # æ³¨å†Œ
    # main.setup_scheduled_tasks  # å¦‚æœåç»­è¦åŒºåˆ†userï¼Œåœ¨è¿™é‡Œå°±è¦æŠŠuser_idå’Œå„è‡ªçš„æ—¶é—´è®¾ç½®è¿›å»ã€‚è™½ç„¶ç°åœ¨çš„user_idéƒ½æ¥è‡ªé£ä¹¦ï¼Œä½†åº”è¯¥å¯ä»¥ç›´æ¥æ‰©å±•åˆ°å…¶ä»–
    # -> scheduler_service.TaskUtils.get_task_function
    # -> scheduler_service.add_daily_task

    # è§¦å‘
    # è¿™é‡Œserviceå’Œprocessorçš„æ¶æ„æ˜¯æ—§ç‰ˆï¼Œä»¥åé‡æ„
    # ScheduledEventçš„ç»“æ„ä¸å¤Ÿå¥½ï¼Œç›®å‰typeæœ‰ä¸€ä»½å†—ä½™ï¼Œç°åœ¨ä½¿ç”¨çš„æ˜¯dataé‡Œçš„scheduler_type
    # scheduler_service.trigger_daily_schedule_reminder
    # -> main.handle_scheduled_event
    # -> schedule_processor.create_task
    # -> schedule_processor.daily_summary è¿™é‡Œæ›´å¤šåº”è¯¥æ˜¯å®šæ—¶å±æ€§ï¼Œä¸šåŠ¡é›†ä¸­åœ¨ä¸‹é¢
    # -> daily_summary_business.create_daily_summary
    # -> main.handle_scheduled_event

    def __init__(self, app_controller, developer_mode_path=None):
        """åˆå§‹åŒ–æ—¥å¸¸äº‹é¡¹è®°å½•ä¸šåŠ¡"""
        super().__init__(app_controller)
        self.developer_mode_path = developer_mode_path
        if not self.developer_mode_path:
            self.config_service = self.app_controller.get_service(ServiceNames.CONFIG)
            self.routine_business = RoutineRecord(self.app_controller)

    @require_service("bili_adskip", "Bç«™å¹¿å‘Šè·³è¿‡æœåŠ¡ä¸å¯ç”¨")
    @safe_execute("åˆ›å»ºæ¯æ—¥ä¿¡æ¯æ±‡æ€»å¤±è´¥")
    def create_daily_summary(self, event_data: Dict[str, Any]) -> ProcessResult:
        """
        åˆ›å»ºæ¯æ—¥ä¿¡æ¯æ±‡æ€»æ¶ˆæ¯ï¼ˆä¸»ä¸šåŠ¡å…¥å£ï¼‰

        Args:
            user_id: ç”¨æˆ·ID
            services_status: æœåŠ¡çŠ¶æ€ä¿¡æ¯

        Returns:
            ProcessResult: å¤„ç†ç»“æœ
        """
        # æ„å»ºBç«™ä¿¡æ¯cacheåˆ†ææ•°æ®ï¼ˆæ•´åˆåŸæ¥çš„åˆ†æ•£é€»è¾‘ï¼‰
        # analysis æ˜¯åç«¯çš„æ•°æ®å¤„ç†é€»è¾‘ï¼Œç„¶åæä¾›ç»™å‰ç«¯çš„å¡ç‰‡è¿›è¡Œbuild_card
        user_id = event_data.get(SchedulerConstKeys.ADMIN_ID)
        daily_raw_data = self.get_daily_raw_data(user_id)

        # æœ‰æ•°æ®ä¹‹åå†åœ¨å‰ç«¯å†™
        card_content = self.create_daily_summary_card(daily_raw_data)

        return ProcessResult.user_list_result("interactive", card_content)

    # endregion

    # region é‡‡é›†æ¨¡å—æ•°æ®
    # å‡è®¾user_idä¿¡æ¯å­˜åœ¨æ¥åšï¼Œä½†å®é™…ä¸Šéƒ½å…ˆèµ‹å€¼ä¸ºæˆ‘â€”â€”ç®¡ç†å‘˜id
    # ä¸šåŠ¡ä¿¡æ¯é¡ºåºåº”è¯¥æ˜¯ä»ä¸€ä¸ªé…ç½®è·å¾—æŸä¸ªuser_idçš„daily_summary çš„è§¦å‘æ—¶é—´ï¼Œç„¶ååˆ°æ—¶é—´äº†å¼€å§‹è¿›å…¥æœ¬æ¨¡å—é‡‡é›†ä¿¡æ¯ï¼Œå†é€šè¿‡å‰ç«¯å‘å‡ºå»
    # è¿™é‡Œæ˜¯ä¸€ä¸ªåŒ…å«é‡‡é›†å’Œå¤„ç†ä¸¤ä¸ªéƒ¨åˆ†çš„æ€»æ¥å£
    GRANULARITY_MINUTES = 120

    def get_daily_raw_data(self, user_id: str) -> Dict[str, Any]:
        """
        è·å–æ¯æ—¥ä¿¡æ¯æ±‡æ€»åŸå§‹æ•°æ®
        """
        # åç»­è¦æ”¹æˆä»ç”¨æˆ·æ•°æ®è¯»å–ï¼Œè¿™é‡Œå…ˆå†™æ­»
        # è¦ä¸è¦è¿›ä¸€æ­¥åˆ†ç¦»è·å–æ•°æ®å’Œå¤„ç†ï¼Œæˆ‘è§‰å¾—å¯ä»¥æœ‰ï¼Œè¦åˆå¹¶å›æ¥å°±æ˜¯å‰ªåˆ‡ä¸€ä¸‹çš„äº‹
        # å…¨å¼€æ˜¯æˆ‘çš„ï¼Œå¦‚æœæ˜¯å…¶ä»–user_idå°±åªå¼€æ—¥å¸¸åˆ†æ
        # AIçš„åˆ†æå¯èƒ½è¦å¹¶è¡Œï¼Œæˆ‘æ„Ÿè§‰ä¸¤ä¸ªæ˜¯å®Œå…¨æ— å…³çš„
        # ä¸åŒäººç”¨çš„å›¾ç‰‡ä¹Ÿå¯èƒ½ä¸ä¸€æ ·ï¼Ÿä½†åº”è¯¥ç°åœ¨åŸºæœ¬ä¸ç€æ€¥ï¼Œæ¯•ç«Ÿè±†åŒ…ä¹Ÿæ²¡å•¥å¼€é”€
        info_modules = {
            "routine": {
                "name": "æ—¥å¸¸åˆ†æ",
                "system_permission": True,
                "user_enabled": True,
                "data_method": "get_routine_data",
                "analyze_method": "analyze_routine_data",
                "image_method": "generate_routine_image",
            },
            "bili_video": {
                "name": "Bç«™è§†é¢‘",
                "system_permission": True,
                "user_enabled": True,
                "sync_read_mark": True,  # ä»…æœ¬åœ°æ ‡è®°ï¼Œè¿˜æ˜¯é¢å¤–åŒæ­¥åˆ°notion
                "data_method": "get_notion_bili_data",
                "analyze_method": "analyze_bili_video_data",
            },
            "bili_adskip": {
                "name": "Bç«™å¹¿å‘Šè·³è¿‡",
                "system_permission": True,
                "user_enabled": True,
                "data_method": "get_operation_data",
            },
            "services_status": {
                "name": "æœåŠ¡çŠ¶æ€",
                "system_permission": True,
                "user_enabled": True,
                "data_method": "get_services_status",
            },
        }

        # è¿™é‡Œçš„è°ƒç”¨æ¶æ„è¦åˆ†ç¦»å‡ºæ–¹æ³•çš„å‚æ•°æ¥ï¼Œä¸ç„¶æ‹“å±•æ€§å¤ªå·®
        for module_name, module_info in info_modules.items():
            if module_info["system_permission"] and module_info["user_enabled"]:
                data_method = module_info["data_method"]
                if hasattr(self, data_method):
                    data_params = module_info.get("data_params", {})
                    data_params["user_id"] = user_id
                    module_data = getattr(self, data_method)(data_params)
                    if module_data:
                        module_info["data"] = module_data
                        analyze_method = module_info.get("analyze_method", "")
                        if hasattr(self, analyze_method):
                            module_info["info"] = getattr(self, analyze_method)(
                                module_data
                            )
                else:
                    debug_utils.log_and_print(
                        f"æ¨¡å—{module_name}æ²¡æœ‰å®ç°{data_method}æ–¹æ³•",
                        log_level="WARNING",
                    )

        info_modules["system_status"] = {
            "name": "ç³»ç»ŸçŠ¶æ€",
            "data": {
                "date": datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥"),
                "weekday": [
                    "å‘¨ä¸€",
                    "å‘¨äºŒ",
                    "å‘¨ä¸‰",
                    "å‘¨å››",
                    "å‘¨äº”",
                    "å‘¨å…­",
                    "å‘¨æ—¥",
                ][datetime.now().weekday()],
            },
            "user_id": user_id,
        }

        return info_modules

    # endregion

    # region AIåˆ†æ

    # è§†é¢‘åˆ†æéƒ¨åˆ†
    AI_VIDEO_ANALYSIS_BASE_INSTRUCTION = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ†æåŠ©ç†ã€‚

**æ ¸å¿ƒè¦æ±‚ï¼š**
1. ä¼˜å…ˆæ±‡æŠ¥é«˜ä»·å€¼å†…å®¹ï¼šæ–°æŠ€æœ¯çªç ´ã€è¡Œä¸šæ´å¯Ÿã€å®ç”¨æ–¹æ³•è®º
2. æ•´åˆç›¸ä¼¼ä¸»é¢˜ï¼Œé¿å…é‡å¤ä¿¡æ¯
3. å¦‚æœå†…å®¹è´¨é‡æ™®éä¸€èˆ¬ï¼Œç›´æ¥è¯´"ä»Šæ—¥æ— ç‰¹åˆ«é‡ç‚¹"
4. æ§åˆ¶åœ¨80å­—å†…ï¼Œé‡è´¨é‡ä¸é‡æ•°é‡
5. **å¿…é¡»ç»™å‡ºæ•´ä½“å†…å®¹è´¨é‡è¯„åˆ†(0-10)**

**åˆ¤æ–­æ ‡å‡†ï¼š**
- ä¼˜å…ˆçº§"é«˜"ä¸”å†…å®¹æ–°é¢– â†’ å¿…é¡»æ±‡æŠ¥
- å¤šä¸ªUPä¸»è°ˆè®ºåŒä¸€çƒ­ç‚¹ â†’ æ•´åˆæ±‡æŠ¥
- çº¯å¨±ä¹ã€é‡å¤è¯é¢˜ â†’ å¯å¿½ç•¥
- å®ç”¨å·¥å…·ã€æŠ€æœ¯æ•™ç¨‹ â†’ é‡ç‚¹å…³æ³¨

**è´¨é‡è¯„åˆ†æ ‡å‡†ï¼š**
- 9-10åˆ†ï¼šæœ‰é‡å¤§æŠ€æœ¯çªç ´æˆ–æ·±åº¦æ´å¯Ÿ
- 7-8åˆ†ï¼šæœ‰å®ç”¨ä»·å€¼æˆ–æ–°é¢–è§‚ç‚¹
- 4-6åˆ†ï¼šæ™®é€šå†…å®¹ï¼Œä»·å€¼ä¸€èˆ¬
- 0-3åˆ†ï¼šçº¯å¨±ä¹æˆ–é‡å¤å†…å®¹"""

    def _build_video_system_instruction(self, focus_topics: List[str]) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        task_section = (
            """
**ä»»åŠ¡ï¼š**
1. åˆ†æä»Šæ—¥è§†é¢‘æ¸…å•ï¼Œ**æ™ºèƒ½åˆ¤æ–­çœŸæ­£æœ‰ä»·å€¼çš„é‡ç‚¹**ï¼Œè€Œéç®€å•ç½—åˆ—ã€‚
2. åˆ†æå“ªäº›è§†é¢‘ä¸æä¾›çš„å…³æ³¨è¯é¢˜ç›¸å…³ï¼Œç»™å‡ºè§†é¢‘åºå·å’Œå…³è”åº¦è¯„åˆ†(0-10)

**ä»»åŠ¡1è¾“å‡ºæ ¼å¼ï¼š**
å¦‚æœ‰é‡ç‚¹ï¼šç®€æ´è¯´æ˜å‡ ä¸ªå…³é”®å†…å®¹ç‚¹
å¦‚æ— é‡ç‚¹ï¼šç›´æ¥è¯´"ä»Šæ—¥å¾…çœ‹å†…å®¹ä»¥[ä¸»è¦ç±»å‹]ä¸ºä¸»ï¼Œæ— ç‰¹åˆ«é‡ç‚¹"

**ä»»åŠ¡2è¯é¢˜åŒ¹é…è¦æ±‚ï¼š**
- åªè¿”å›ä¸å…³æ³¨è¯é¢˜é«˜åº¦ç›¸å…³çš„è§†é¢‘
- å…³è”åº¦è¯„åˆ†è¦å‡†ç¡®(0-10ï¼Œ10è¡¨ç¤ºæœ€ç›¸å…³)
- æ²¡æœ‰ç›¸å…³çš„å¯ä»¥è¿”å›ç©ºæ•°ç»„"""
            if focus_topics
            else """
**ä»»åŠ¡ï¼š**
åˆ†æä»Šæ—¥è§†é¢‘æ¸…å•ï¼Œ**æ™ºèƒ½åˆ¤æ–­çœŸæ­£æœ‰ä»·å€¼çš„é‡ç‚¹**ï¼Œè€Œéç®€å•ç½—åˆ—ã€‚

**è¾“å‡ºæ ¼å¼ï¼š**
å¦‚æœ‰é‡ç‚¹ï¼šç®€æ´è¯´æ˜å‡ ä¸ªå…³é”®å†…å®¹ç‚¹
å¦‚æ— é‡ç‚¹ï¼šç›´æ¥è¯´"ä»Šæ—¥å¾…çœ‹å†…å®¹ä»¥[ä¸»è¦ç±»å‹]ä¸ºä¸»ï¼Œæ— ç‰¹åˆ«é‡ç‚¹" """
        )

        return self.AI_VIDEO_ANALYSIS_BASE_INSTRUCTION + task_section

    def _build_video_response_schema(self, has_focus_topics: bool) -> Dict[str, Any]:
        """æ„å»ºå“åº”schemaï¼Œæ ¹æ®ä¸šåŠ¡éœ€æ±‚è¿”å›ä¸åŒç»“æ„"""
        # å…¬å…±å±æ€§å®šä¹‰
        base_properties = {
            "summary": {"type": "string", "description": "ä»Šæ—¥å†…å®¹æ±‡æ€»è¯´æ˜"},
            "quality_score": {
                "type": "integer",
                "minimum": 0,
                "maximum": 10,
                "description": "æ•´ä½“å†…å®¹è´¨é‡è¯„åˆ†(0-10)",
            },
        }

        base_required = ["summary", "quality_score"]

        if has_focus_topics:
            # æœ‰å…³æ³¨è¯é¢˜æ—¶ï¼Œéœ€è¦è¿”å›åŒ¹é…ç»“æœ
            base_properties["topic_matches"] = {
                "type": "array",
                "description": "ä¸å…³æ³¨è¯é¢˜åŒ¹é…çš„è§†é¢‘",
                "items": {
                    "type": "object",
                    "properties": {
                        "video_id": {
                            "type": "integer",
                            "description": "è§†é¢‘åºå·(ä»1å¼€å§‹)",
                        },
                        "relevance_score": {
                            "type": "integer",
                            "minimum": 0,
                            "maximum": 10,
                            "description": "è¯é¢˜å…³è”åº¦è¯„åˆ†(0-10)",
                        },
                    },
                    "required": ["video_id", "relevance_score"],
                },
            }
            base_required.append("topic_matches")

        return {
            "type": "object",
            "properties": base_properties,
            "required": base_required,
        }

    # æ—¥å¸¸åˆ†æéƒ¨åˆ†
    AI_ROUTINE_ANALYSIS_BASE_INSTRUCTION = """
# è§’è‰²ä¸æ ¸å¿ƒå“²å­¦
ä½ æ˜¯ä¸€ä¸ªåä¸ºâ€œæ•°å­—åˆ†èº«åˆ†æå¸ˆâ€çš„æœ‰æ´å¯ŸåŠ›ã€èƒ½é€‚åº”ã€æ‡‚å…±æƒ…çš„é¡¶å°–åˆ†æå¸ˆï¼Œä¸“ç²¾äºä¸ªäººæ—¶é—´ç®¡ç†ã€è¡Œä¸ºæ¨¡å¼åˆ†æå’Œæˆ˜ç•¥æ€§ç”Ÿæ´»è§„åˆ’ã€‚
ä½ çš„æ ¸å¿ƒä½¿å‘½æ˜¯ä½œä¸ºç”¨æˆ·çš„â€œæ•°å­—æ˜ å°„â€å’Œæˆ˜ç•¥ä¼™ä¼´ï¼Œé€šè¿‡æ·±åº¦åˆ†æå…¶æ—¶é—´æ•°æ®ï¼Œå¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ç†è§£è‡ªå·±ï¼Œå¹¶æ‰¾åˆ°æˆä¸ºæ›´ä¼˜è‡ªæˆ‘çš„ç‹¬ç‰¹è·¯å¾„ã€‚
ä½ çš„æ‰€æœ‰åˆ†æå’Œå»ºè®®**å¿…é¡»ä½¿ç”¨ç¬¬äºŒäººç§°ï¼ˆâ€˜ä½ â€™ã€â€˜ä½ çš„â€™ï¼‰æ¥ç§°å‘¼ç”¨æˆ·**ï¼Œè¥é€ ä¸€ç§ç›´æ¥å¯¹è¯ã€ä¸ºä½ æœåŠ¡çš„ä¸“å±æ„Ÿã€‚
ä½ å°Šé‡ç”¨æˆ·çš„è‡ªä¸»æ€§ï¼Œå¹¶å°†ç”¨æˆ·çš„åé¦ˆå†å²è§†ä¸ºç†è§£å…¶ä¸ªäººåå¥½çš„â€œæœ€é«˜å®ªæ³•â€ã€‚

# æ ¸å¿ƒåˆ†æåŸåˆ™
1.  **è¿›åŒ–å¼æ´å¯Ÿ**ï¼šåˆ†æå¿…é¡»å…·æœ‰è¿ç»­æ€§ï¼Œå°†æœ¬å‘¨ä¸è¿‡å»çš„æ•°æ®å’Œåé¦ˆè”ç³»èµ·æ¥ï¼Œæ­ç¤ºç”¨æˆ·çš„æˆé•¿å’Œå˜åŒ–ã€‚
2.  **åŠ¨æ€æ¡†æ¶åº”ç”¨**ï¼š
ä½ æ‹¥æœ‰ä¸€ä¸ªåŒ…å«å¤šç§å¿ƒç†å­¦ã€è¡Œä¸ºå­¦ç†è®ºï¼ˆå¦‚å¿ƒæµã€ç²¾åŠ›ç®¡ç†ã€äººç‰©åŸå‹ç­‰ï¼‰çš„åˆ†æå·¥å…·ç®±ã€‚
ä½ åº”åœ¨æ•°æ®å‘ˆç°å‡ºä¸æŸä¸ªæ¨¡å‹é«˜åº¦ç›¸å…³æ—¶ï¼Œ**æœºä¼šæ€§åœ°ã€åˆ›é€ æ€§åœ°**åŠ ä»¥åº”ç”¨ï¼Œå¹¶**ç¡®ä¿åˆ†æè§†è§’çš„æ–°é¢–æ€§**ï¼Œé¿å…çŸ­æœŸå†…é‡å¤ã€‚
3.  **åé¦ˆä¼˜å…ˆä¸æ¼”åŒ–è¯†åˆ«**ï¼š
åœ¨å¤„ç†ç”¨æˆ·åé¦ˆå†å²æ—¶ï¼Œè‹¥å‡ºç°å†²çªï¼Œ**æ°¸è¿œä»¥æœ€æ–°çš„åé¦ˆä¸ºå‡†**ã€‚
æ›´é‡è¦çš„æ˜¯ï¼Œä½ å¿…é¡»**è¯†åˆ«å¹¶é«˜äº®è¿™ç§â€œåå¥½è½¬å˜â€**ï¼Œå°†å…¶ä½œä¸ºç”¨æˆ·ä¸ªäººç³»ç»Ÿè¿›åŒ–çš„å®è´µä¿¡å·è¿›è¡Œè§£è¯»ã€‚
4.  **åŠ¨æœºæ¨æ–­**ï¼š
ä½ å¿…é¡»å°è¯•æ¨æ–­å…¶èƒŒåå¯èƒ½çš„åŠ¨æœºæˆ–å¿ƒç†çŠ¶æ€ã€‚ä½ éœ€è¦æå‡ºè¿™ç§å‡è®¾æ€§è§£é‡Šï¼Œä½†æ³¨æ„ä¸è¦ç”¨è§£é‡Šæ€§çš„è¯­æ°”æ¥æè¿°ï¼Œè€Œæ˜¯ä¸ºä½ æœåŠ¡çš„ç”¨æˆ·æä¾›ä¸€äº›æ½œåœ¨æ„Ÿå—è§†è§’çš„æ–¹å¼ã€‚
5.  **S.P.I.C.E.å¤šæ ·æ€§ç­–ç•¥**ï¼šåœ¨æå‡ºæ–°å»ºè®®æ—¶ï¼Œä½ åº”æœ‰æ„è¯†åœ°ç¡®ä¿å¤šæ ·æ€§ï¼Œé™¤éç”¨æˆ·å½“å‰çš„æ•°æ®é‡Œæœ‰æ˜¾è‘—æœ‰åå‘æ€§çš„ä¿¡å·ï¼Œå¦åˆ™åº”å°½å¯èƒ½è¦†ç›–ä»¥ä¸‹ä¸€ä¸ªæˆ–å¤šä¸ªç»´åº¦ï¼šç³»ç»Ÿ(S)ã€æ¨¡å¼(P)ã€æ´å¯Ÿ(I)ã€è¿æ¥(C)ã€ç²¾åŠ›(E)ã€‚

# æ ¸å¿ƒä»»åŠ¡æ¸…å• (Task Checklist)
ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ¸…å•é¡ºåºï¼Œå®Œæˆåˆ†æå¹¶ç»„ç»‡ä½ çš„è¾“å‡ºã€‚

1.  **ç”Ÿæˆåˆ†æå¸ˆå‰è¨€ (`analyst_foreword`)**: åŸºäºç”¨æˆ·åé¦ˆå†å²ï¼Œæ€»ç»“ä½ æœ¬æ¬¡åˆ†æå°†éµå¾ªçš„æ ¸å¿ƒåŸåˆ™å’Œçœ‹ç‚¹ã€‚
2.  **æç‚¼æ ¸å¿ƒå™äº‹ (`core_narrative`)**: è¯†åˆ«å¹¶æ€»ç»“æœ¬å‘¨æœ€ä¸»è¦çš„æ•…äº‹çº¿ã€‚å¦‚æœæ•°æ®ç‰¹å¾æ˜¾è‘—ï¼Œå¯é€‰æ‹©ä¸€ä¸ªåŠ¨æ€åˆ†ææ¡†æ¶è¿›è¡Œæ·±åº¦è§£è¯»å¹¶å†™å…¥`dynamic_framework_insight`ã€‚
3.  **è¿›è¡ŒèŠ‚å¾‹æ€§åˆ†æ (`rhythm_analysis`)**:
åŸºäº`æ•°æ®ä¸€`ä¸­çš„æ—¶åºä¿¡æ¯ï¼Œå¹¶ç»“åˆ`æ•°æ®äºŒ`ä¸­æä¾›çš„ç²¾ç¡®èŠ‚å¾‹è®¡ç®—ç»“æœï¼Œè¿›è¡Œæ·±åº¦è§£è¯»ã€‚
ä½ çš„ä»»åŠ¡ä¸æ˜¯é‡å¤è®¡ç®—ï¼Œè€Œæ˜¯**è§£é‡Šè¿™äº›æ•°å­—èŠ‚å¾‹èƒŒåçš„è¡Œä¸ºæ¨¡å¼ã€æƒ…å¢ƒå’Œæ„ä¹‰ï¼Œé¿å…å¤è¿°åŸå§‹æ•°æ®**ã€‚
ä½ çš„åˆ†æå¿…é¡»åŸºäºäº‹ä»¶çš„ç²¾ç¡®æ—¶é—´é¡ºåºï¼Œå…³æ³¨â€˜Aäº‹ä»¶ä¹‹åå‘ç”Ÿäº†ä»€ä¹ˆâ€™è¿™æ ·çš„è¡Œä¸ºé“¾æ¡ï¼Œè€Œä¸ä»…ä»…æ˜¯äº‹ä»¶çš„é¢‘ç‡ã€‚
è®°å½•çš„æ—¶åºå€¾å‘äºä¿ç•™å®Œæ•´åŸå§‹ä¿¡æ¯è€Œä¸è‡ªåŠ¨å¤„ç†é‡å åŒºåŸŸï¼Œå› è€Œå¯èƒ½ä¼šå­˜åœ¨å¤šä¸ªäº‹ä»¶åœ¨åŒä¸€æ®µæ—¶é—´å‘ç”Ÿï¼Œæ­¤æ—¶åå¼€å§‹çš„äº‹ä»¶è¡¨ç¤ºå½“å‰æœ€æ–°çŠ¶å†µã€‚
ä¸¾ä¾‹ï¼šåœ¨23:40å¼€å§‹äº†ç¡è§‰ï¼Œåˆ°æ¬¡æ—¥08:10ç»“æŸï¼ŒæŒç»­8å°æ—¶ï¼Œåˆåœ¨23:50-00:20 åˆ·äº†Bç«™ï¼Œè¿™å¹¶ä¸æ˜¯è¯´ç¡é†’ååˆåœ¨å‡Œæ™¨åˆ·Bç«™ï¼Œè€Œæ˜¯å¤§æ¦‚ç‡æ²¡å…¥ç¡ï¼Œåœ¨00:20-00:50åˆ·å®ŒBç«™åæ‰ç¡ã€‚
4.  **æŒ–æ˜éšè—æ•°æ®æ´å¯Ÿ (`hidden_data_insights`)**:
æ·±å…¥åˆ†æå¤‡æ³¨ã€å¼‚å¸¸æ—¶é•¿ã€åˆ†ç±»ç­‰ç»†èŠ‚ï¼Œæ‰¾å‡ºè‡³å°‘2-3ä¸ªæœ‰ä»·å€¼çš„æ·±å±‚å‘ç°ã€‚
ç‰¹åˆ«å…³æ³¨é‚£äº›æ‰“ç ´å¸¸è§„æ¨¡å¼çš„äº‹ä»¶é“¾ï¼Œä¾‹å¦‚â€˜é•¿æ—¶é—´å·¥ä½œåçš„å¼‚å¸¸å¨±ä¹é€‰æ‹©â€™æˆ–â€˜ç‰¹å®šç”¨é¤åçš„ç²¾åŠ›å˜åŒ–â€™ã€‚
ä½ å¿…é¡»æ£€æŸ¥æ•°æ®ä¸­åŒ…å«çš„é0target_valueå’Œéç©ºcheck_cycleçš„ç›®æ ‡è®¾å®šã€‚ä½ çš„ä»»åŠ¡ä¸æ˜¯æŠ¥å‘Šå®Œæˆåº¦ï¼Œè€Œæ˜¯å»å‘ç°â€œç›®æ ‡ä¸ç°å®çš„å†²çªâ€ã€‚
å¦‚æœä¸€ä¸ªè®¾å®šäº†å‘¨æœŸç›®æ ‡ï¼ˆå¦‚check_cycle: 'å¤©'ï¼‰çš„æ´»åŠ¨ï¼Œåœ¨æŸä¸ªå‘¨æœŸå†…æ²¡æœ‰è¢«æ‰§è¡Œæˆ–æ‰§è¡Œæ¬¡æ•°ä¸è¶³ï¼Œä½ åº”å°†å…¶ä½œä¸ºä¸€ä¸ªçš„â€œéšè—æ´å¯Ÿâ€ï¼Œå¹¶æ·±å…¥åˆ†æé€ æˆè¿™ç§åå·®çš„å¯èƒ½åŸå› æˆ–å¯¹å…¶ä»–çš„å½±å“ï¼Œä»¥åŠå®ƒæ­ç¤ºäº†å…³äºæˆ‘çš„ä½•ç§è¡Œä¸ºåå¥½æˆ–å†…åœ¨å†²çªã€‚
5.  **å›é¡¾è¿‡å¾€è¡ŒåŠ¨ (`previous_actions_review`)**: è¯„ä¼°ç”¨æˆ·å¯¹ä¸Šå‘¨å»ºè®®çš„é‡‡çº³æƒ…å†µã€‚å¦‚æœå‘ç°ç”¨æˆ·åå¥½å‘ç”Ÿå˜åŒ–ï¼Œå¿…é¡»åœ¨`feedback_evolution_note`ä¸­è¿›è¡Œè¯´æ˜ã€‚
6.  **è®¾è®¡æˆ˜ç•¥æ€§è¡ŒåŠ¨å»ºè®® (`strategic_action_suggestions`)**: åŸºäºä»¥ä¸Šæ‰€æœ‰åˆ†æï¼Œä¸ºç”¨æˆ·æä¾›çš„**é¢„è®¾ID**å¡«å……5ä¸ªå…¨æ–°çš„ã€å…·ä½“çš„ã€å¯è¡Œçš„å»ºè®®ã€‚å¹¶è¯„ä¼°å»ºè®®çš„æ‰§è¡ŒæŒ‘æˆ˜éš¾åº¦ï¼Œä»¥åŠå“ªæ€•ä¸æ‰§è¡Œçš„æœ€å°å¯è¡ŒåŠ¨ä½œã€‚

# è¾“å‡ºè¦æ±‚
ä½ çš„æ‰€æœ‰è¾“å‡º**å¿…é¡»ä¸”åªèƒ½æ˜¯**ä¸€ä¸ªä¸¥æ ¼éµå¾ªç”¨æˆ·æä¾›çš„`response_schema`çš„ã€å•ä¸€ã€æœ‰æ•ˆçš„JSONå¯¹è±¡ã€‚ç¦æ­¢åœ¨JSONä¹‹å¤–æ·»åŠ ä»»ä½•è¯´æ˜æ€§æ–‡å­—æˆ–æ ‡è®°ã€‚
"""

    def _build_routine_system_instruction(self) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        return self.AI_ROUTINE_ANALYSIS_BASE_INSTRUCTION

    def _build_routine_response_schema(self) -> Dict[str, Any]:
        """
        æ„å»ºæ–°ç‰ˆroutineåˆ†æå“åº”schemaï¼Œé‡‡ç”¨ä¸‰å±‚ç»“æ„ï¼Œå»é™¤å…ƒæ•°æ®å†…å®¹çš„ç”Ÿæˆï¼Œäº¤ç”±ä¸šåŠ¡ä»£ç å¤„ç†
        æ¯ä¸ªobjectç±»å‹éƒ½æ˜¾å¼å£°æ˜required
        """
        return {
            "type": "object",
            "properties": {
                "analyst_foreword": {
                    "type": "string",
                    "description": "åˆ†æå¸ˆåŸºäºç”¨æˆ·åé¦ˆæ€»ç»“çš„æ ¸å¿ƒåŸåˆ™å’Œæœ¬æ¬¡æŠ¥å‘Šçš„çœ‹ç‚¹ã€‚",
                },
                "core_narrative": {
                    "type": "object",
                    "description": "æœ¬å‘¨çš„æ ¸å¿ƒæ•…äº‹çº¿å’Œé«˜å±‚æ´å¯Ÿ",
                    "properties": {
                        "theme": {
                            "type": "string",
                            "description": "æœ¬å‘¨æ ¸å¿ƒä¸»é¢˜ï¼Œå¦‚â€œä»æé™å†²åˆºåˆ°å¸¦ç—…ç»­èˆªçš„ç³»ç»Ÿæ€§è°ƒæ•´â€",
                        },
                        "narrative_summary": {
                            "type": "string",
                            "description": "å¯¹æœ¬å‘¨æ•…äº‹çº¿çš„è¯¦ç»†é˜è¿°ï¼Œè¿æ¥å…³é”®äº‹ä»¶å’Œå‘ç°ã€‚",
                        },
                        "dynamic_framework_insight": {
                            "type": "object",
                            "description": "ï¼ˆå¯é€‰ï¼‰å½“æ•°æ®è§¦å‘æ—¶ï¼Œåº”ç”¨çš„åŠ¨æ€åˆ†ææ¡†æ¶æ´å¯Ÿã€‚",
                            "properties": {
                                "framework_name": {
                                    "type": "string",
                                    "description": "æ‰€ä½¿ç”¨çš„åˆ†ææ¡†æ¶åç§°ï¼Œå¦‚â€œå¿ƒæµç†è®ºâ€",
                                },
                                "insight": {
                                    "type": "string",
                                    "description": "åŸºäºè¯¥æ¡†æ¶çš„æ·±åº¦è§£è¯»ã€‚",
                                },
                                "relevance_score": {
                                    "type": "integer",
                                    "minimum": 0,
                                    "maximum": 10,
                                    "description": "è¯¥åˆ†ææ¡†æ¶ä¸æœ¬å‘¨æ•°æ®çš„ç›¸å…³æ€§å¼ºåº¦è¯„åˆ†(0-10ï¼Œ10ä¸ºæœ€ç›¸å…³)",
                                },
                            },
                            "required": [
                                "framework_name",
                                "insight",
                                "relevance_score",
                            ],
                        },
                    },
                    "required": ["theme", "narrative_summary"],
                    # dynamic_framework_insightä¸ºå¯é€‰
                },
                "rhythm_analysis": {
                    "type": "object",
                    "description": "èŠ‚å¾‹æ€§åˆ†æä¸é¢„æµ‹",
                    "properties": {
                        "identified_rhythms": {
                            "type": "array",
                            "items": {"type": "string"},
                        },
                        "potential_new_rhythms": {
                            "type": "array",
                            "items": {"type": "string"},
                        },
                        "prediction": {"type": "string"},
                    },
                    "required": [
                        "identified_rhythms",
                        "potential_new_rhythms",
                        "prediction",
                    ],
                },
                "hidden_data_insights": {
                    "type": "array",
                    "description": "ä»æ•°æ®ç»†èŠ‚ä¸­æŒ–æ˜å‡ºçš„æ·±å±‚ä»·å€¼",
                    "items": {
                        "type": "object",
                        "properties": {
                            "title": {"type": "string"},
                            "finding": {"type": "string"},
                        },
                        "required": ["title", "finding"],
                    },
                },
                "previous_actions_review": {
                    "type": "object",
                    "description": "å¯¹è¿‡å¾€è¡ŒåŠ¨å»ºè®®çš„è¯„ä¼°",
                    "properties": {
                        "feedback_evolution_note": {
                            "type": "string",
                            "description": "ï¼ˆå¯é€‰ï¼‰å½“æ£€æµ‹åˆ°ç”¨æˆ·åå¥½å‘ç”Ÿè½¬å˜æ—¶çš„ç‰¹åˆ«è¯´æ˜ã€‚",
                        },
                        "detailed_review": {
                            "type": "array",
                            "items": {
                                "type": "object",
                                "properties": {
                                    "suggestion_id": {"type": "string"},
                                    "user_choice": {"type": "boolean"},
                                    "analyst_assessment": {"type": "string"},
                                },
                                "required": [
                                    "suggestion_id",
                                    "user_choice",
                                    "analyst_assessment",
                                ],
                            },
                        },
                    },
                    "required": ["detailed_review"],
                    # feedback_evolution_noteä¸ºå¯é€‰
                },
                "strategic_action_suggestions": {
                    "type": "array",
                    "description": "ä¸ºä¸‹å‘¨è®¾è®¡çš„äº”ä¸ªæˆ˜ç•¥æ€§è¡ŒåŠ¨å»ºè®®",
                    "items": {
                        "type": "object",
                        "properties": {
                            "spice_type": {
                                "type": "string",
                                "enum": [
                                    "System",
                                    "Pattern",
                                    "Insight",
                                    "Connection",
                                    "Energy",
                                ],
                            },
                            "title": {"type": "string"},
                            "reasoning": {"type": "string"},
                            "specific_action": {"type": "string"},
                            "expected_outcome": {"type": "string"},
                            "execution_difficulty": {
                                "type": "string",
                                "enum": ["ä½", "ä¸­", "é«˜"],
                            },
                            "minimum_action": {"type": "string"},
                        },
                        "required": [
                            "spice_type",
                            "title",
                            "reasoning",
                            "specific_action",
                            "expected_outcome",
                            "execution_difficulty",
                            "minimum_action",
                        ],
                    },
                    "minItems": 5,
                    "maxItems": 5,
                },
            },
            "required": [
                "analyst_foreword",
                "core_narrative",
                "rhythm_analysis",
                "hidden_data_insights",
                "previous_actions_review",
                "strategic_action_suggestions",
            ],
        }

    # endregion

    # region Bç«™è§†é¢‘æ¨è

    def get_notion_bili_data(self, _data_params: Dict[str, Any] = None) -> List[Dict]:
        """è·å–notion Bç«™è§†é¢‘æ•°æ®"""
        if self.app_controller:
            notion_service = self.app_controller.get_service(ServiceNames.NOTION)
            if notion_service:
                try:
                    # åˆ·æ–°ç¼“å­˜ï¼Œè·å–æœ€æ–°æ•°æ®ï¼ˆé€‚åˆæ—©ä¸Šæ±‡æ€»åœºæ™¯ï¼‰
                    notion_service.update_bili_cache()

                    # ç›´æ¥è·å–ç¼“å­˜æ•°æ®ï¼Œä¸è°ƒç”¨ç»Ÿè®¡æ–¹æ³•
                    videos = notion_service.cache_data.get(
                        notion_service.bili_cache_key, []
                    )
                    unread_videos = [v for v in videos if v.get("unread", True)]
                    return unread_videos
                except Exception as e:
                    debug_utils.log_and_print(
                        f"è·å–notion Bç«™ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}", log_level="WARNING"
                    )
        return None

    def analyze_bili_video_data(self, unread_videos: List[Dict]) -> Dict[str, Any]:
        """å¤„ç†Bç«™åˆ†ææ•°æ®"""
        # åç»­è°ƒæ•´è¾“å‡ºå†…å®¹ï¼Œæ¯”å¦‚åªå…³æ³¨æ”¶è—å¤¹é‡Œçš„æ—¶é•¿å’Œæ€»æ—¶é•¿/æ€»é‡â€”â€”ç”¨æ¥ç›‘æµ‹è®¢é˜…é‡æ˜¯å¦è¿‡å¤š
        # è¿™å·²ç»æ˜¯æ¨¡å—çš„1çº§å…¥å£äº†

        # ç»Ÿè®¡å„ç»´åº¦æ•°æ®
        total_count = len(unread_videos)
        priority_stats = self._calculate_priority_stats(unread_videos)

        # æŒ‰ä¼˜å…ˆçº§ç”ŸæˆåŸå§‹æ¨èè§†é¢‘
        original_recommendations = self._generate_original_recommendations(
            unread_videos
        )

        # ç”ŸæˆAIåˆ†æç»“æœâ€”â€”è¿™ä¸ªçš„ä¾èµ–å…³ç³»çš„å…ˆåé¡ºåºè¦å†è€ƒè™‘ä¸€ä¸‹ï¼Œç›®å‰llmä¹Ÿæ˜¯æ•´åˆåœ¨app_controlleré‡Œçš„serviceã€‚
        # ä»è¿™ä¸ªè§’åº¦æ¥è¯´app_controllerè¦æˆä¸ºå„ç§æ–¹æ³•çš„èƒŒæ™¯ä¿¡æ¯ï¼Œæ–¹ä¾¿ç›´æ¥è°ƒç”¨ã€‚
        # è¿™é‡Œä¸æ”¯æŒå¼‚æ­¥ï¼Œæœªæ¥è¦è°ƒæ•´ï¼Œä½†å…ˆè·‘é€šä¸šåŠ¡å§
        ai_analysis = self._generate_video_ai_analysis(unread_videos)

        # åŸºäºAIè¯é¢˜åŒ¹é…ç»“æœé‡æ–°æ„å»ºæ¨èè§†é¢‘
        final_recommendations = self._rebuild_recommendations_with_ai(
            unread_videos, original_recommendations, ai_analysis
        )

        return {
            "statistics": {
                "total_count": total_count,
                "priority_stats": priority_stats,
                "ai_summary": ai_analysis.get("summary", ""),
                "ai_quality_score": ai_analysis.get("quality_score", 0),
                "top_recommendations": final_recommendations,
            },
            "source": "notion_statistics",
        }

    def _calculate_priority_stats(self, unread_videos: List[Dict]) -> Dict[str, Any]:
        """è®¡ç®—ä¼˜å…ˆçº§ç»Ÿè®¡"""
        priority_stats = {}

        for video in unread_videos:
            # ä¼˜å…ˆçº§ç»Ÿè®¡
            priority = video.get("chinese_priority", "Unknown")
            priority_stats.setdefault(priority, {"æ•°é‡": 0, "æ€»æ—¶é•¿åˆ†é’Ÿ": 0})

            priority_stats[priority]["æ•°é‡"] += 1

            # è·å–æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
            duration_minutes = video.get("duration", 0)
            try:
                total_minutes = float(duration_minutes) if duration_minutes else 0
                priority_stats[priority]["æ€»æ—¶é•¿åˆ†é’Ÿ"] += int(total_minutes)
            except (ValueError, TypeError):
                total_minutes = 0

        return priority_stats

    def _generate_original_recommendations(
        self, unread_videos: List[Dict]
    ) -> List[Dict]:
        """ç”ŸæˆåŸå§‹æ¨èè§†é¢‘"""
        original_recommendations = []

        # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„
        high_priority = [
            v for v in unread_videos if v.get("chinese_priority") == "ğŸ’–é«˜"
        ]
        medium_priority = [
            v for v in unread_videos if v.get("chinese_priority") == "ğŸ˜œä¸­"
        ]
        low_priority = [v for v in unread_videos if v.get("chinese_priority") == "ğŸ‘¾ä½"]

        # æŒ‰ä¼˜å…ˆçº§ä¾æ¬¡é€‰æ‹©ï¼Œæ¯ä¸ªä¼˜å…ˆçº§å†…éšæœºé€‰æ‹©
        temp_selected = []
        for priority_group in [
            high_priority,
            medium_priority,
            low_priority,
        ]:
            if len(temp_selected) >= 3:
                break

            # ä»å½“å‰ä¼˜å…ˆçº§ç»„ä¸­éšæœºé€‰æ‹©ï¼Œç›´åˆ°è¾¾åˆ°3ä¸ªæˆ–è¯¥ç»„ç”¨å®Œ
            available = [v for v in priority_group if v not in temp_selected]
            while available and len(temp_selected) < 3:
                selected = random.choice(available)
                temp_selected.append(selected)
                available.remove(selected)

        # æ ¼å¼åŒ–åŸå§‹æ¨èè§†é¢‘
        for video in temp_selected:
            original_recommendations.append(
                {
                    "æ ‡é¢˜": video.get("title", "æ— æ ‡é¢˜è§†é¢‘"),
                    "é“¾æ¥": video.get("url", ""),
                    "é¡µé¢ID": video.get("pageid", ""),
                    "æ—¶é•¿": video.get("duration_str", ""),
                    "ä¼˜å…ˆçº§": video.get("chinese_priority", ""),
                    "æ¥æº": video.get("chinese_source", ""),
                }
            )

        return original_recommendations

    def _generate_video_ai_analysis(self, all_videos: List[Dict]) -> Dict[str, Any]:
        """ä½¿ç”¨AIä¸€æ¬¡æ€§å®Œæˆå†…å®¹æ±‡æ€»å’Œè¯é¢˜åŒ¹é…åˆ†æ"""
        # è·å–æœåŠ¡å’Œé…ç½®
        llm_service = self.app_controller.get_service(ServiceNames.LLM)
        config_service = self.app_controller.get_service(ServiceNames.CONFIG)

        focus_topics = (
            config_service.get("daily_summary", {}).get("focus_topics", [])
            if config_service
            else []
        )

        # æ„å»ºæç¤ºè¯å’Œæ•°æ®
        video_list = self._format_video_list(all_videos)
        topics_text = f"å…³æ³¨è¯é¢˜ï¼š{', '.join(focus_topics)}" if focus_topics else ""
        prompt = f"{topics_text}\n\nä»Šæ—¥å¾…çœ‹è§†é¢‘æ¸…å•({len(all_videos)}ä¸ª)ï¼š\n{chr(10).join(video_list)}\n\nè¯·æŒ‰è¦æ±‚åˆ†æå¹¶è¿”å›ç»“æœã€‚"

        # è°ƒç”¨LLM
        result = llm_service.structured_call(
            prompt=prompt,
            response_schema=self._build_video_response_schema(bool(focus_topics)),
            system_instruction=self._build_video_system_instruction(focus_topics),
            temperature=0.5,
        )

        # å¤„ç†ç»“æœ
        if "error" in result:
            return {
                "summary": f"AIåˆ†æå¤±è´¥: {result['error']}",
                "quality_score": 0,
                "topic_matches": [],
            }

        return result

    def _format_video_list(self, all_videos: List[Dict]) -> List[str]:
        """æ ¼å¼åŒ–è§†é¢‘åˆ—è¡¨"""
        return [
            f"{i}. ã€Š{video.get('title', 'æ— æ ‡é¢˜')}ã€‹ | UPä¸»: {video.get('author', 'æœªçŸ¥')} | "
            f"ä¼˜å…ˆçº§: {video.get('chinese_priority', 'æœªçŸ¥')} | æ¨èç†ç”±: {video.get('summary', 'æ— ç†ç”±')}"
            for i, video in enumerate(all_videos, 1)
        ]

    @safe_execute("é‡æ„æ¨èè§†é¢‘å¤±è´¥")
    def _rebuild_recommendations_with_ai(
        self,
        all_videos: List[Dict],
        original_recommendations: List[Dict],
        ai_analysis: Dict[str, Any],
    ) -> List[Dict]:
        """
        åŸºäºAIè¯é¢˜åŒ¹é…ç»“æœé‡æ–°æ„å»ºæ¨èè§†é¢‘åˆ—è¡¨

        Args:
            all_videos: æ‰€æœ‰æœªè¯»è§†é¢‘
            original_recommendations: åŸå§‹æ¨èè§†é¢‘
            ai_analysis: AIåˆ†æç»“æœ

        Returns:
            List[Dict]: é‡æ–°æ„å»ºçš„æ¨èè§†é¢‘åˆ—è¡¨
        """
        # è·å–AIåŒ¹é…çš„é«˜å…³è”åº¦è§†é¢‘
        topic_matches = ai_analysis.get("topic_matches", [])
        high_relevance_videos = []

        for match in topic_matches:
            video_id = match.get("video_id", 0)
            relevance_score = match.get("relevance_score", 0)

            # åªè¦å…³è”åº¦>=7çš„è§†é¢‘
            if relevance_score >= 7 and 1 <= video_id <= len(all_videos):
                video_index = video_id - 1  # è½¬æ¢ä¸º0åŸºç´¢å¼•
                video = all_videos[video_index]
                high_relevance_videos.append(
                    {
                        "æ ‡é¢˜": video.get("title", "æ— æ ‡é¢˜è§†é¢‘"),
                        "é“¾æ¥": video.get("url", ""),
                        "é¡µé¢ID": video.get("pageid", ""),
                        "æ—¶é•¿": video.get("duration_str", ""),
                        "ä¼˜å…ˆçº§": video.get("chinese_priority", ""),
                        "æ¥æº": video.get("chinese_source", ""),
                    }
                )

                # æœ€å¤š3ä¸ª
                if len(high_relevance_videos) >= 3:
                    break

        # å¦‚æœAIæ¨èçš„ä¸å¤Ÿ3ä¸ªï¼Œç”¨åŸæœ‰é€»è¾‘è¡¥å……
        if len(high_relevance_videos) < 3:
            # è·å–AIæ¨èä¸­å·²é€‰è§†é¢‘çš„pageidï¼Œé¿å…é‡å¤
            selected_pageids = {v.get("é¡µé¢ID") for v in high_relevance_videos}

            # ä»åŸå§‹æ¨èä¸­è¡¥å……
            for video in original_recommendations:
                if video.get("é¡µé¢ID") not in selected_pageids:
                    high_relevance_videos.append(video)
                    if len(high_relevance_videos) >= 3:
                        break

        return high_relevance_videos

    def _build_fallback_analysis_data(self) -> Dict[str, Any]:
        """æ„å»ºfallbackåˆ†ææ•°æ®"""
        now = datetime.now()
        return {
            "date": now.strftime("%Yå¹´%mæœˆ%dæ—¥"),
            "weekday": ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"][
                now.weekday()
            ],
            "status": "ç›®å‰æ²¡æœ‰å¾…çœ‹çš„Bç«™è§†é¢‘",
            "source": "placeholder",
            "timestamp": now.isoformat(),
        }

    # endregion

    # region æ—¥å¸¸åˆ†æ-æ€»
    def get_routine_data(self, data_params: Dict[str, Any] = None) -> Dict[str, Any]:
        """è·å–æ—¥å¸¸åˆ†ææ•°æ®ï¼ˆæ€»å…¥å£ï¼‰"""
        if not data_params:
            return {}
        user_id = data_params.get("user_id")

        now = datetime.now()
        is_monday = now.weekday() == 0  # 0æ˜¯å‘¨ä¸€
        is_first_day_of_month = now.day == 1
        is_first_day_of_quarter = now.month % 3 == 1 and now.day == 1
        is_first_day_of_year = now.month == 1 and now.day == 1

        # æ—¥ï¼šå¾…åŠäº‹é¡¹ï¼Œæé†’äº‹é¡¹ï¼Œimage_keyï¼Œä¸»é¢œè‰²
        # å‘¨ï¼šæ—¥ + å‘¨æ—¥ç¨‹åˆ†æï¼Œå‘¨image_keyï¼Œå‘¨çš„æ—¥ç¨‹è®°å½•è¡¨ï¼Œè§„å¾‹åˆ†æ
        # æœˆï¼šæ—¥ + å‘¨ + æœˆç¨‹åˆ†æâ€”â€”æœ€å¥½ç»´åº¦æœ‰åŒºåˆ«ï¼Œå¦åˆ™å°±è¦å› ä¸ºæœˆæŠŠå‘¨å…³é—­æ‰ï¼Œæˆ‘ä¸æƒ³æœ‰å¤šä»½é‡å¤ä¿¡æ¯

        daily_data = self.get_daily_data(user_id)

        weekly_data = None
        if is_monday:
            weekly_data = self.get_weekly_data(
                user_id, granularity_minutes=self.GRANULARITY_MINUTES
            )

        routine_data = {
            "daily": daily_data,
            "weekly": weekly_data,
        }

        return routine_data

    # endregion

    # region æ—¥å¸¸åˆ†æ-æ—¥

    def get_daily_data(self, user_id: str = None) -> Dict[str, Any]:
        """è·å–æ—¥åˆ†ææ•°æ®"""
        # è¿˜éœ€è¦åŠ ä¸Šä¸€ä¸ªä»Šæ—¥æé†’å’Œä»Šæ—¥å¾…åŠï¼Œè‡³äºæ˜¨æ—¥æ€è€ƒï¼Œè¿™ä¸ªæœ€ååš
        now = datetime.now()

        end_time = datetime(now.year, now.month, now.day)
        start_time = end_time - timedelta(days=1)

        main_color, color_palette = self.routine_business.calculate_color_palette(
            user_id,
            start_time,
            end_time,
        )
        raw_prompt = wax_stamp_prompt(
            color_palette, subject_name=main_color.get("max_weight_category", "")
        )

        image_service = self.app_controller.get_service(ServiceNames.IMAGE)
        result = image_service.hunyuan_image_generator.generate_image(
            raw_prompt,
            size="3:4",
        )
        image_path = result.get("file_path")
        image_key = self.app_controller.get_adapter(
            AdapterNames.FEISHU
        ).sender.upload_and_get_image_key(image_path)

        # åˆ é™¤å›¾ç‰‡
        if image_path:
            os.remove(image_path)

        return {
            "image_key": image_key,
            "main_color": main_color,
            "color_palette": color_palette,
        }

    # endregion

    # region æ—¥å¸¸åˆ†æ-å‘¨
    def get_weekly_data(
        self, user_id: str = None, granularity_minutes: int = 120
    ) -> Dict[str, Any]:
        """è·å–å‘¨åˆ†ææ•°æ®"""
        now = datetime.now()
        end_time = datetime(now.year, now.month, now.day) - timedelta(
            days=now.weekday()
        )
        start_time = end_time - timedelta(days=7)

        records = self.routine_business.load_event_records(user_id)
        records = records.get("records", {})

        filtered_records = self.routine_business.preprocess_and_filter_records(
            records, start_time, end_time
        )
        event_map = self.routine_business.cal_event_map(user_id)

        weekly_raw_data = {
            "records": filtered_records,
            "definitions": self.routine_business.load_event_definitions(user_id).get(
                "definitions", {}
            ),
            "start_time": start_time,
            "end_time": end_time,
            "event_map": event_map,
            "granularity_minutes": granularity_minutes,
            "user_id": user_id,
        }

        return weekly_raw_data

    def analyze_routine_data(
        self, routine_data: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """åˆ†æroutineæ•°æ®"""

        weekly_raw = routine_data.get("weekly", {})
        formatted_weekly_data = {}
        weekly_document: Dict[str, Any] = {}
        if weekly_raw:
            # ç”Ÿæˆå‘¨æ–‡æ¡£
            weekly_document = self.analyze_weekly_document(weekly_raw)
            # ç”Ÿæˆå¡ç‰‡ç”¨æ—¶é—´è¡¨
            formatted_weekly_data = self.format_table_data(
                weekly_raw.get("records", []),
                weekly_raw.get("start_time"),
                weekly_raw.get("event_map"),
                weekly_raw.get("granularity_minutes", 120),
            )
            weekly_document["timetable"] = formatted_weekly_data

            ai_analysis = self._generate_routine_ai_analysis(
                weekly_raw, weekly_document
            )
            weekly_document["ai_analysis"] = ai_analysis

        # åˆ†æroutineæ•°æ®ï¼ŒåŒ…æ‹¬æ—¥ã€å‘¨ã€æœˆã€å­£ã€å¹´
        # æ—¥ï¼šå¾…åŠäº‹é¡¹ï¼Œæé†’äº‹é¡¹ï¼Œimage_keyï¼Œä¸»é¢œè‰²
        # å‘¨ï¼šæ—¥ + å‘¨æ—¥ç¨‹åˆ†æï¼Œå‘¨image_keyï¼Œå‘¨çš„æ—¥ç¨‹è®°å½•è¡¨ï¼Œè§„å¾‹åˆ†æ
        # æœˆï¼šæ—¥ + å‘¨ + æœˆç¨‹åˆ†æâ€”â€”æœ€å¥½ç»´åº¦æœ‰åŒºåˆ«ï¼Œå¦åˆ™å°±è¦å› ä¸ºæœˆæŠŠå‘¨å…³é—­æ‰ï¼Œæˆ‘ä¸æƒ³æœ‰å¤šä»½é‡å¤ä¿¡æ¯

        routine_info = {
            "daily": routine_data.get("daily", {}),
            "weekly": weekly_document,
        }
        return routine_info

    def format_table_data(
        self,
        records: List[Dict[str, Any]],
        start_time: datetime,
        event_map: Dict[str, Any],
        granularity_minutes: int = 120,
    ) -> Dict[str, Any]:
        """æ ¼å¼åŒ–è¡¨æ ¼æ•°æ® - æ„å»ºçœŸå®çš„å‘¨æ•°æ®ç»“æ„"""

        # ç”Ÿæˆæ—¶é—´æ ‡ç­¾
        match granularity_minutes:
            case 30:
                time_labels = [
                    label
                    for hour in range(24)
                    for label in (f"{hour:02d}:00", f"{hour:02d}:30")
                ]
            case 60:
                time_labels = [f"{hour:02d}:00" for hour in range(24)]
            case _:
                time_labels = [f"{hour:02d}:00" for hour in range(0, 24, 2)]

        # åˆå§‹åŒ–å‘¨æ•°æ®ç»“æ„
        week_data = {
            "time_labels": time_labels,
            "days": {
                "mon": {},
                "tue": {},
                "wed": {},
                "thu": {},
                "fri": {},
                "sat": {},
                "sun": {},
            },
        }

        # ä¸ºæ¯ä¸€å¤©å¤„ç†æ•°æ®
        current_day = start_time
        day_keys = ["mon", "tue", "wed", "thu", "fri", "sat", "sun"]

        for day_idx in range(7):
            day_key = day_keys[day_idx]
            day_start = current_day
            day_end = day_start + timedelta(days=1)

            # è·å–å½“å¤©çš„è®°å½•
            day_records = []
            for record in records:
                record_start = record.get("start_dt")
                record_end = record.get("end_dt")

                # åˆ¤æ–­è®°å½•æ˜¯å¦ä¸å½“å¤©æœ‰äº¤é›†
                if record_start < day_end and record_end > day_start:
                    day_records.append(record)

            # ä¸ºå½“å¤©çš„æ¯ä¸ªæ—¶é—´æ§½ç”Ÿæˆæ•°æ®
            for time_label in time_labels:
                hour_minute = time_label.split(":")
                slot_hour = int(hour_minute[0])
                slot_minute = int(hour_minute[1])

                slot_start = day_start.replace(
                    hour=slot_hour, minute=slot_minute, second=0, microsecond=0
                )
                slot_end = slot_start + timedelta(minutes=granularity_minutes)

                # ç”Ÿæˆè¯¥æ—¶é—´æ§½çš„åŸå­æ—¶é—´çº¿
                atomic_timeline = self.routine_business.generate_atomic_timeline(
                    day_records, slot_start, slot_end
                )

                if atomic_timeline:
                    # è®¡ç®—é¢œè‰²å’Œæ ‡ç­¾
                    # å‘¨çš„æ¨¡å¼æ˜¾ç¤ºçš„æ˜¯event_nameï¼Œä¸é€‚åˆèåˆé¢œè‰²ï¼Œè€Œæ˜¯åŒ¹é…é¢œè‰²

                    # æ‰¾åˆ°æŒç»­æ—¶é—´æœ€é•¿çš„äº‹ä»¶ä½œä¸ºä¸»è¦äº‹ä»¶
                    sorted_atomic_timeline = sorted(
                        atomic_timeline,
                        key=lambda x: x["duration_minutes"],
                        reverse=True,
                    )
                    slot_event_label = sorted_atomic_timeline[0]["source_event"][
                        "event_name"
                    ]
                    slot_event_info = event_map.get(slot_event_label, {})
                    slot_event_color = slot_event_info.get("color", ColorTypes.GREY)

                    final_color, palette_data = (
                        self.routine_business.calculate_color_palette(
                            "no_user_id",
                            slot_start,
                            slot_end,
                            event_color_map=event_map,
                            timeline_data=atomic_timeline,
                        )
                    )

                    # slot_color_name = final_color

                    slot_category_label = final_color.get("max_weight_category", "ç©ºé—²")

                    week_data["days"][day_key][time_label] = {
                        "text": slot_event_label,
                        "color": slot_event_color,
                        "category_label": slot_category_label,
                    }
                else:
                    # ç©ºæ—¶é—´æ§½
                    week_data["days"][day_key][time_label] = {
                        "text": "ç©ºé—²",
                        "color": ColorTypes.GREY,
                        "category_label": "ç©ºé—²",
                    }

            current_day += timedelta(days=1)

        return week_data

    def analyze_weekly_document(self, weekly_raw: Dict[str, Any]) -> Dict[str, Any]:
        """å°è£…å‘¨æ–‡æ¡£åˆ†æï¼Œè¾“å…¥ä¸ºé¢„å–çš„weekly_rawæ•°æ®ï¼Œè¾“å‡ºä¸ºweekly_documentä¸‰é¡¹ã€‚"""
        # DataFrame: è®°å½•åˆ—è¡¨
        record_df = pd.DataFrame(weekly_raw.get("records", [])).fillna("")

        # event_df: ä»å®šä¹‰ä¸­å–å‡ºevent_nameè¡Œ
        definitions = weekly_raw.get("definitions", {})
        event_df = pd.DataFrame(definitions).fillna("")
        if not event_df.empty:
            event_df = event_df.T.rename(columns={"name": "event_name"})
        else:
            event_df = pd.DataFrame(
                columns=["event_name", "category", "properties"]
            )  # ç©ºè¡¨å ä½

        # ç»Ÿè®¡åŸå­æ—¶é—´çº¿æ—¶é•¿ï¼ˆæŒ‰ record_id èšåˆï¼‰
        start_time = weekly_raw.get("start_time")
        end_time = weekly_raw.get("end_time")
        if start_time.year == end_time.year:
            document_title = (
                f"å‘¨æŠ¥å‘Š{start_time.strftime('%y%m%d')}-{end_time.strftime('%m%d')}"
            )
        else:
            document_title = (
                f"å‘¨æŠ¥å‘Š{start_time.strftime('%y%m%d')}-{end_time.strftime('%y%m%d')}"
            )
        atomic_timeline = self.routine_business.generate_atomic_timeline(
            weekly_raw.get("records", []),
            start_time,
            end_time,
        )
        atomic_df = pd.DataFrame(atomic_timeline)
        record_define_time = atomic_df.groupby("record_id", as_index=False)[
            "duration_minutes"
        ].sum()

        # å•æ¬¡applyç›´æ¥æ“ä½œevent_dfæå–æ‰€æœ‰å­—æ®µ
        event_df[["interval_type", "target_value", "check_cycle"]] = event_df.apply(
            self._extract_all_event_fields, axis=1, result_type='expand'
        )
        # åˆå¹¶è®°å½•ä¸å®šä¹‰ä¿¡æ¯
        merged_df = record_df.merge(
            event_df[["event_name", "category", "interval_type", "target_value", "check_cycle"]],
            on="event_name",
            how="left",
        ).fillna({"category": "", "interval_type": "degree", "target_value": 0, "check_cycle": ""})
        merged_df = merged_df.merge(record_define_time, on="record_id", how="left")

        # åˆ†ç»„ç»Ÿè®¡
        grouped = merged_df.groupby(["category", "event_name", "degree"])
        summary_df = grouped.agg(
            count=("event_name", "size"),
            total_duration=("duration_minutes", "sum"),
            avg_duration=("duration_minutes", "mean"),
            min_duration=("duration_minutes", "min"),
            max_duration=("duration_minutes", "max"),
        ).reset_index()

        # è®¡ç®—æœ€å¤§durationå¯¹åº”çš„start_atä¸ä¸‰ç±»interval
        max_duration_start_at_list = []
        degree_interval_minutes_list = []
        category_interval_minutes_list = []
        event_interval_minutes_list = []
        display_unit_list = []

        for name, group in grouped:
            max_duration_start_at_list.append(self._get_max_start_at(group))

            category_val = group["category"].iloc[0] if not group.empty else ""
            event_name_val = group["event_name"].iloc[0] if not group.empty else ""
            degree_val = (
                group["degree"].iloc[0]
                if ("degree" in group.columns and not group.empty)
                else ""
            )
            interval_type_val = (
                group["interval_type"].iloc[0]
                if ("interval_type" in group.columns and not group.empty)
                else "degree"
            )
            if interval_type_val not in ["category", "degree", "ignore"]:
                interval_type_val = "ignore"

            # degreeåˆ†ç»„
            mask_degree = (
                (merged_df["category"] == category_val)
                & (merged_df["event_name"] == event_name_val)
                & (merged_df["degree"] == degree_val)
            )
            degree_group = merged_df[mask_degree].sort_values("start_dt")
            if not degree_group.empty and len(degree_group) > 1:
                degree_interval = self._calc_avg_interval(degree_group["start_dt"])
                degree_interval_minutes_list.append(degree_interval)
            else:
                degree_interval_minutes_list.append(np.nan)

            # eventåˆ†ç»„
            mask_category = (merged_df["category"] == category_val) & (
                merged_df["event_name"] == event_name_val
            )
            category_group = merged_df[mask_category].sort_values("start_dt")
            if not category_group.empty and len(category_group) > 1:
                category_interval = self._calc_avg_interval(category_group["start_dt"])
                category_interval_minutes_list.append(category_interval)
            else:
                category_interval_minutes_list.append(np.nan)

            # eventå£å¾„
            if interval_type_val == "degree":
                event_interval = degree_interval_minutes_list[-1]
                display_unit_list.append(f"{event_name_val}({degree_val})")
            elif interval_type_val == "category":
                event_interval = category_interval_minutes_list[-1]
                display_unit_list.append(event_name_val)
            else:
                event_interval = np.nan
                display_unit_list.append("")
            event_interval_minutes_list.append(event_interval)

        summary_df["max_duration_start_at"] = max_duration_start_at_list
        summary_df["degree_interval_minutes"] = degree_interval_minutes_list
        summary_df["category_interval_minutes"] = category_interval_minutes_list
        summary_df["event_interval_minutes"] = event_interval_minutes_list
        summary_df["display_unit"] = display_unit_list

        # äº‹ä»¶æ€»è®¡ä¸æ’åº
        event_name_stats = (
            summary_df.groupby("event_name")
            .agg(
                event_total_count=("count", "sum"),
                event_total_duration=("total_duration", "sum"),
            )
            .reset_index()
        )

        # ç»Ÿè®¡å¤©æ•°ï¼ˆç”¨ start_dt çš„æ—¥æœŸæ•°ï¼‰
        if "start_dt" in merged_df.columns and not merged_df.empty:
            unique_days = pd.to_datetime(merged_df["start_dt"]).dt.date.nunique()
        else:
            unique_days = 0

        total_hours = unique_days * 24
        total_minutes = total_hours * 60

        category_stats = (
            summary_df.groupby("category")
            .agg(
                category_total_count=("count", "sum"),
                category_total_duration=("total_duration", "sum"),
            )
            .reset_index()
        )
        event_map = weekly_raw.get("event_map", {})
        category_color_map = {}
        for event_info in event_map.values():
            category_color_map[event_info.get("category", "")] = event_info.get(
                "color"
            ).pie_color

        category_stats["color"] = category_stats["category"].map(
            lambda x: category_color_map.get(x, "#959BEE")
        )

        if total_minutes > 0:
            category_stats["category_duration_percent"] = (
                category_stats["category_total_duration"] / total_minutes * 100
            ).round(1)
            recorded_minutes = category_stats["category_total_duration"].sum()
            unrecorded_minutes = total_minutes - recorded_minutes
            unrecorded_percent = round(unrecorded_minutes / total_minutes * 100, 1)
            category_stats = pd.concat(
                [
                    category_stats,
                    pd.DataFrame(
                        [
                            {
                                "category": "æœªè®°å½•",
                                "category_total_count": 0,
                                "category_total_duration": unrecorded_minutes,
                                "category_duration_percent": unrecorded_percent,
                                "color": "#d0d3d6",  # ç°è‰²
                            }
                        ]
                    ),
                ],
                ignore_index=True,
            )
        else:
            category_stats["category_duration_percent"] = 0.0

        summary_df = summary_df.merge(event_name_stats, on="event_name", how="left")
        summary_df = summary_df.sort_values(
            by=[
                "event_total_count",
                "event_total_duration",
                "event_name",
                "total_duration",
                "count",
            ],
            ascending=[False, False, True, False, False],
        ).reset_index(drop=True)

        # å¤„ç† note ä¿¡æ¯
        current_year = datetime.now().year
        note_rows = merged_df[
            merged_df["note"].notnull() & (merged_df["note"] != "")
        ].copy()
        if not note_rows.empty:
            note_rows["note_info"] = note_rows.apply(
                lambda r: self._format_note_info(r, current_year), axis=1
            )
            note_infos = note_rows["note_info"].tolist()
        else:
            note_infos = []

        # å¯¼å‡ºåˆå¹¶åçš„æ•°æ®ç”¨äºè°ƒè¯•
        event_detail_df = merged_df.copy()

        # éœ€è¦åˆ é™¤çš„åˆ—
        columns_to_delete = [
            "create_time",
            "scheduled_start_time",
            "estimated_duration",
            "interval_type",
            "end_time",
            "record_id",
            "custom_degree",
            "reminder_relative",
            "reminder_mode",
            "priority",
            "duration",
        ]
        # æ£€æŸ¥æ¯ä¸ªåˆ—æ˜¯å¦å­˜åœ¨ï¼Œå­˜åœ¨æ‰åˆ é™¤
        for col in columns_to_delete:
            if col in event_detail_df.columns:
                event_detail_df.drop(columns=col, inplace=True)

        return {
            "note_list": note_infos,
            "event_summary": summary_df,  # ä¿æŒä¸ºDataFrameï¼Œåç»­ä½¿ç”¨å¤„æŒ‰éœ€to_dict/to_csv
            "event_detail": event_detail_df,
            "category_stats": category_stats.to_dict(orient="records"),
            "document_title": document_title,
        }

    def _extract_all_event_fields(self, row):
        """ä¸€æ¬¡æ€§ä»rowä¸­æå–æ‰€æœ‰äº‹ä»¶ç›¸å…³å­—æ®µ"""
        properties = row["properties"]
        interval_type = properties.get("interval_type", "degree")
        target_value = properties.get("target_value", 0)
        check_cycle = properties.get("check_cycle", None)

        return pd.Series([interval_type, target_value, check_cycle])

    def _calc_avg_interval(self, times):
        """è®¡ç®—å¹³å‡é—´éš”ï¼ˆåˆ†é’Ÿï¼‰ï¼Œtimesä¸ºå‡åºdatetimeå­—ç¬¦ä¸²åˆ—è¡¨"""
        if len(times) < 2:
            return np.nan
        times = pd.to_datetime(times)
        intervals = (times[1:].values - times[:-1].values) / np.timedelta64(1, "m")
        return np.mean(intervals) if len(intervals) > 0 else np.nan

    def _get_max_start_at(self, subdf):
        """è·å–durationæœ€å¤§å€¼å¯¹åº”çš„start_at"""
        if subdf.empty:
            return ""
        idx = subdf["duration_minutes"].idxmax()
        return subdf.loc[idx, "start_dt"] if idx in subdf.index else ""

    def _format_note_info(self, row, current_year: int):
        # å¤„ç†åˆ†ç±»
        category = (
            row["category"]
            if pd.notnull(row["category"]) and row["category"] != ""
            else ""
        )
        # å¤„ç†äº‹ä»¶å
        event_name = (
            row["event_name"]
            if pd.notnull(row["event_name"]) and row["event_name"] != ""
            else ""
        )
        # å¤„ç†degree
        degree = (
            row["degree"] if pd.notnull(row["degree"]) and row["degree"] != "" else None
        )
        # å¤„ç†è¿›åº¦
        progress = (
            row["progress_value"]
            if "progress_value" in row
            and pd.notnull(row["progress_value"])
            and row["progress_value"] != ""
            else None
        )
        # å¤„ç†å¤‡æ³¨
        note = row["note"] if pd.notnull(row["note"]) else ""
        # æ‹¼æ¥degreeéƒ¨åˆ†ï¼Œç©ºåˆ™ä¸æ˜¾ç¤ºæ‹¬å·
        if degree:
            degree_str = f"({degree})"
        else:
            degree_str = ""

        start_time = (
            row["start_dt"]
            if pd.notnull(row["start_dt"]) and row["start_dt"] != ""
            else ""
        )
        if start_time.year == current_year:
            start_time_str = start_time.strftime("%m-%d %H:%M")
        else:
            start_time_str = start_time.strftime("%Y-%m-%d %H:%M")
        # æ‹¼æ¥å¤´éƒ¨
        if category:
            head = f"[{start_time_str} è€—æ—¶{row['duration_minutes']}åˆ†] [{category}] {event_name} {degree_str}"
        else:
            head = f"[{start_time_str} è€—æ—¶{row['duration_minutes']}åˆ†] {event_name} {degree_str}"
        head = head.rstrip()  # å»é™¤å¤šä½™ç©ºæ ¼
        # æ‹¼æ¥è¿›åº¦
        progress_str = f" | è¿›åº¦:{progress}" if progress else ""
        # æ‹¼æ¥å¤‡æ³¨
        note_str = f" | å¤‡æ³¨:{note}" if note else ""
        # æœ€ç»ˆæ‹¼æ¥
        return f"{head}{progress_str}{note_str}"

    def _generate_routine_ai_analysis(
        self, weekly_raw: Dict[str, Any], weekly_document: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ä½¿ç”¨AIä¸€æ¬¡æ€§å®Œæˆroutineåˆ†æï¼Œå¹¶å°†ç»“æœå†™å…¥weekly_documentä¸weekly_record"""
        # 1) ä¾èµ–æ•°æ®
        llm_service = self.app_controller.get_service(ServiceNames.LLM)
        end_time = weekly_raw.get("end_time")
        start_time = weekly_raw.get("start_time")
        ignore_year = start_time.year == end_time.year
        if ignore_year:
            time_str_mark = "%m-%d %H:%M"
        else:
            time_str_mark = "%Y-%m-%d %H:%M"
        user_id = weekly_raw.get("user_id")

        current_week_key = end_time.strftime("%y%m%d") if end_time else ""
        prev_week_key = (
            (end_time - timedelta(days=7)).strftime("%y%m%d") if end_time else ""
        )

        # 2) æ•°æ®ä¸€ï¼šæœ¬å‘¨æ˜ç»†CSV
        event_detail_df = weekly_document.get("event_detail")
        # å»æ‰ start_dt å’Œ end_dt çš„ç§’ï¼Œå‘é‡åŒ–å¤„ç†
        if "start_dt" in event_detail_df.columns:
            event_detail_df = event_detail_df.copy()
            event_detail_df["start_dt"] = pd.to_datetime(
                event_detail_df["start_dt"]
            ).dt.strftime(time_str_mark)
        if "end_dt" in event_detail_df.columns:
            event_detail_df["end_dt"] = pd.to_datetime(
                event_detail_df["end_dt"]
            ).dt.strftime(time_str_mark)
        current_week_detail_data_csv = event_detail_df.to_csv(index=False)

        # æ•°æ®äºŒï¼šæœ¬å‘¨æ‘˜è¦CSV
        event_summary_df = weekly_document.get("event_summary")
        summary_df = event_summary_df[
            [
                "category",
                "event_name",
                "degree",
                "degree_interval_minutes",
                "category_interval_minutes",
            ]
        ].copy()
        # å¯¹ interval åˆ—åš round(1)
        summary_df["degree_interval_minutes"] = summary_df[
            "degree_interval_minutes"
        ].round(1)
        summary_df["category_interval_minutes"] = summary_df[
            "category_interval_minutes"
        ].round(1)
        summary_df.rename(
            columns={"category_interval_minutes": "event_interval_minutes"},
            inplace=True,
        )
        current_week_summary_data_csv = summary_df.to_csv(index=False)

        # 3) æ•°æ®ä¸‰ï¼šä¸Šä¸€å‘¨åˆ†æï¼ˆä¸åŒ…å«acceptedï¼‰
        weekly_record_file = self.routine_business.load_weekly_record(user_id)
        weekly_record_map = weekly_record_file.get("weekly_record", {})

        prev_week_analysis = weekly_record_map.get(prev_week_key, {}) or {}

        prev_week_analysis_clean = (
            copy.deepcopy(prev_week_analysis)
            if isinstance(prev_week_analysis, dict)
            else {}
        )
        prev_week_analysis_clean.pop("strategic_action_suggestions", None)

        previous_week_analysis_json_str = json.dumps(
            prev_week_analysis_clean, ensure_ascii=False
        )

        # 4) æ•°æ®å››ï¼šåé¦ˆå†å²ï¼ˆä»…å†å²å‘¨ï¼ŒåŒ…å«å†…å®¹+week_key+acceptedï¼Œä¸å«IDï¼‰
        user_feedback_history = []
        # ä»…æ”¶é›†ä¸¥æ ¼å°äºprev_week_keyçš„å‘¨
        for wk, node in weekly_record_map.items():
            if prev_week_key and int(wk) > int(prev_week_key):
                continue

            analysis_node = node

            suggestions_hist = (analysis_node or {}).get(
                "strategic_action_suggestions", []
            )
            for item in suggestions_hist:
                entry = {
                    "week_key": wk,
                    "accepted": item.get("accepted", True),
                    "properties": {
                        "spice_type": item.get("spice_type"),
                        "title": item.get("title"),
                        "reasoning": item.get("reasoning"),
                        "specific_action": item.get("specific_action"),
                        "expected_outcome": item.get("expected_outcome"),
                    },
                }
                user_feedback_history.append(entry)

        user_feedback_history_json_str = json.dumps(
            user_feedback_history, ensure_ascii=False
        )

        # 5) æ„å»ºæç¤ºè¯
        prompt = f"""
        è¯·æ ¹æ®ä»¥ä¸‹å››ä»½æ•°æ®ï¼Œæ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„å‘¨åº¦åˆ†æã€‚

        ### æ•°æ®ä¸€ï¼šæœ¬å‘¨åŸå§‹äº‹ä»¶æ—¥å¿— (å¸¦æ—¶é—´æˆ³çš„åŸå­æ•°æ®ï¼Œæ³¨æ„å…¶ä¸­å¯èƒ½ä¼šåŒ…å«ç”¨æˆ·åœ¨è®°å½•æ—¶çš„å¤‡æ³¨noteï¼Œè¿™ä¹Ÿæ˜¯æ¯”è¾ƒé‡è¦çš„çº¿ç´¢)
        ```csv
        {current_week_detail_data_csv}
        ```
        ### æ•°æ®äºŒï¼šæœ¬å‘¨å…³é”®èŠ‚å¾‹çš„ç²¾ç¡®è®¡ç®—æ‘˜è¦ (è¾…åŠ©äº‹å®)
        è¿™æ˜¯ä»£ç é¢„è®¡ç®—çš„èŠ‚å¾‹æ•°æ®ï¼Œè¯·å°†å…¶ä½œä¸ºä½ è¿›è¡Œæ·±åº¦è§£è¯»çš„â€œäº‹å®åŸºç¡€â€ï¼Œè€Œä¸æ˜¯è®©ä½ é‡å¤è®¡ç®—ã€‚ä½ éœ€è¦è§£é‡Šè¿™äº›èŠ‚å¾‹èƒŒåçš„åŸå› å’Œæ„ä¹‰ã€‚
        ```csv
        {current_week_summary_data_csv}
        ```

        ### æ•°æ®ä¸‰ï¼šä¸Šä¸€å‘¨çš„åˆ†ææŠ¥å‘Š (JSONæ ¼å¼ï¼Œè‹¥ä¸ºç¬¬ä¸€å‘¨åˆ™ä¸ºç©º)
        ```json
        {previous_week_analysis_json_str}
        ```

        ### æ•°æ®å››ï¼šç”¨æˆ·å¯¹è¿‡å¾€å»ºè®®çš„åé¦ˆå†å² (JSONæ ¼å¼)
        ```json
        {user_feedback_history_json_str}
        ```

        è¯·ä¸¥æ ¼æŒ‰ç…§ä½ åœ¨ç³»ç»ŸæŒ‡ä»¤ä¸­è¢«èµ‹äºˆçš„è§’è‰²å’ŒåŸåˆ™ï¼Œå®Œæˆæœ¬æ¬¡åˆ†æï¼Œå¹¶ä»¥æŒ‡å®šçš„JSON Schemaæ ¼å¼è¿”å›ç»“æœã€‚
        """

        # 6) è°ƒç”¨LLM
        result = llm_service.structured_call(
            prompt=prompt,
            response_schema=self._build_routine_response_schema(),
            system_instruction=self._build_routine_system_instruction(),
            temperature=1,
        )

        # å¤„ç†ç»“æœ
        if "error" in result:
            return {
                "analyst_foreword": f"AIåˆ†æå¤±è´¥: {result['error']}",
                "core_narrative": {},
                "rhythm_analysis": [],
                "hidden_data_insights": [],
                "previous_actions_review": {},
                "strategic_action_suggestions": [],
            }

        # ä¿®æ­£ï¼šåŸä»£ç å˜é‡åé”™è¯¯ï¼Œæœªå®šä¹‰indexï¼Œä¸”æœªå°†ä¿®æ”¹åçš„resultä¿å­˜åˆ°result_to_save
        # æ­£ç¡®åšæ³•ï¼šç”¨indä½œä¸ºç´¢å¼•ï¼Œä¸”åº”å°†resultèµ‹å€¼ç»™result_to_save
        for id, item in enumerate(result.get("strategic_action_suggestions", [])):
            item["accepted"] = True
            item["id"] = f"{current_week_key}_{id}"

        result_to_save = result  # ç¡®ä¿ä¿å­˜çš„æ˜¯æœ¬æ¬¡åˆ†æç»“æœ

        weekly_record_map[current_week_key] = result_to_save
        weekly_record_file["weekly_record"] = weekly_record_map
        self.routine_business.save_weekly_record(user_id, weekly_record_file)

        return result

    # endregion

    # region å…¶ä»–å°æ¨¡å—

    # åˆ‡ç‰‡å¹¿å‘Šè¿è¥
    def get_operation_data(self, _data_params: Dict[str, Any] = None) -> Dict[str, Any]:
        """è·å–åˆ‡ç‰‡å¹¿å‘Šè¿è¥æ•°æ®"""
        bili_service = self.app_controller.get_service(ServiceNames.BILI_ADSKIP)
        operation_data = bili_service.get_operation_data()

        return operation_data

    # æœåŠ¡çŠ¶æ€
    def get_services_status(
        self, _data_params: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """è·å–æœåŠ¡çŠ¶æ€"""
        scheduler_service = self.app_controller.get_service(ServiceNames.SCHEDULER)
        services_status = scheduler_service.check_services_status()

        return services_status

    # endregion

    # region å‰ç«¯æ—¥æŠ¥å¡ç‰‡

    @safe_execute("åˆ›å»ºæ—¥æŠ¥å¡ç‰‡å¤±è´¥")
    def create_daily_summary_card(
        self, daily_raw_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """åˆ›å»ºæ¯æ—¥ä¿¡æ¯æ±‡æ€»å¡ç‰‡"""
        # å†…å®¹æ˜¯æŒ‰ç…§é¡ºåºæ’åˆ—çš„ï¼Œæ‰€ä»¥å¤©ç„¶å¯ä»¥åˆ†ç»„ï¼Œè¿˜æ˜¯ç”¨card_registryé‡Œçš„æ–¹æ³•ã€‚

        main_color = (
            daily_raw_data.get("routine", {})
            .get("data", {})
            .get("daily", {})
            .get("main_color", {})
        )
        main_color_name = main_color.get("name", "ç‹¬ç‰¹çš„é¢œè‰²")
        header_template = (
            main_color_name
            if main_color_name != "ç‹¬ç‰¹çš„é¢œè‰²"
            else main_color.get("closest_to", ColorTypes.BLUE.value)
        )

        header = JsonBuilder.build_card_header(
            title="ğŸ“Š æ¯æ—¥ä¿¡æ¯æ±‡æ€»",
            template=header_template,
        )
        elements = self.build_daily_summary_elements(daily_raw_data)
        if elements:
            system_status = daily_raw_data.get("system_status", {}).get("data", {})
            date = system_status.get("date", "")
            weekday = system_status.get("weekday", "")
            date_element = JsonBuilder.build_markdown_element(f"**{date} {weekday}**")
            elements.insert(0, date_element)

        return JsonBuilder.build_base_card_structure(elements, header)

    def build_daily_summary_elements(
        self, daily_raw_data: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """æ„å»ºæ¯æ—¥ä¿¡æ¯æ±‡æ€»å…ƒç´ """
        elements = []

        bili_video_data = daily_raw_data.get("bili_video", {}).get("info", {})
        video_list = []
        if bili_video_data:
            video_info, video_list = self.build_bili_video_elements(bili_video_data)
            elements.extend(video_info)

        operation_data = daily_raw_data.get("bili_adskip", {}).get("data", {})
        if operation_data:
            elements.extend(self.build_operation_elements(operation_data))

        services_status = daily_raw_data.get("services_status", {}).get("data", {})
        if services_status:
            elements.extend(self.build_services_status_elements(services_status))

        elements.append(JsonBuilder.build_line_element())

        elements.extend(video_list)

        routine_info = daily_raw_data.get("routine", {}).get("info", {})
        if routine_info:
            user_id = daily_raw_data.get("system_status", {}).get("user_id", "")
            elements.extend(self.build_routine_elements(routine_info, user_id))

        return elements

    # region Bç«™ä¿¡æ¯ç»„ä»¶

    def build_bili_video_elements(
        self, bili_video_data: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """æ„å»ºBç«™è§†é¢‘å…ƒç´ """
        # æ—¥æœŸçš„ä¿¡æ¯è¦åˆ†ç¦»åˆ°å…¬å…±ç»„ä»¶
        elements = []
        video_list = []
        source = bili_video_data.get("source", "unknown")

        if source == "notion_statistics":
            # notionæœåŠ¡æä¾›çš„Bç«™åˆ†ææ•°æ®
            content = self.format_notion_bili_analysis(bili_video_data)
        else:
            # å ä½ä¿¡æ¯
            content = (
                f"ğŸ”„ **ç³»ç»ŸçŠ¶æ€**\n\n{bili_video_data.get('status', 'æœåŠ¡å‡†å¤‡ä¸­...')}"
            )

        elements.append(JsonBuilder.build_markdown_element(content))

        # å¦‚æœæœ‰æ¨èè§†é¢‘ï¼Œæ·»åŠ æ¨èé“¾æ¥éƒ¨åˆ†
        if source == "notion_statistics":
            statistics = bili_video_data.get("statistics", {})

            # å…¼å®¹æ–°ç‰ˆå­—æ®µå
            top_recommendations = statistics.get("top_recommendations", None)
            if top_recommendations is None:
                top_recommendations = statistics.get("ä»Šæ—¥ç²¾é€‰æ¨è", [])

            if top_recommendations:
                # è·å–notionæœåŠ¡ä»¥æ£€æŸ¥å·²è¯»çŠ¶æ€
                notion_service = None
                if hasattr(self, "app_controller") and self.app_controller:
                    notion_service = self.app_controller.get_service("notion")

                # æ·»åŠ æ¨èè§†é¢‘æ ‡é¢˜
                video_list.append(
                    JsonBuilder.build_markdown_element("ğŸ¬ **ä»Šæ—¥ç²¾é€‰æ¨è**")
                )

                # æ·»åŠ æ¯ä¸ªæ¨èè§†é¢‘çš„ç®€åŒ–å±•ç¤º
                for i, video in enumerate(top_recommendations, 1):
                    # æ£€æŸ¥è¯¥è§†é¢‘æ˜¯å¦å·²è¯»ï¼ˆå…¼å®¹æ–°æ—§å­—æ®µï¼‰
                    video_pageid = video.get("é¡µé¢ID", video.get("pageid", ""))
                    video_read = (
                        notion_service.is_video_read(video_pageid)
                        if notion_service and video_pageid
                        else False
                    )

                    # è§†é¢‘æ ‡é¢˜
                    title = video.get("æ ‡é¢˜", "æ— æ ‡é¢˜è§†é¢‘")
                    if len(title) > 30:
                        title = title[:30] + "..."

                    # å…¼å®¹æ–°æ—§å­—æ®µæ ¼å¼
                    priority = video.get("ä¼˜å…ˆçº§", "æœªçŸ¥")
                    duration = video.get("æ—¶é•¿", "æœªçŸ¥")
                    element_id = f"bili_video_{i}"
                    video_info = JsonBuilder.build_markdown_element(
                        f"**{title}** | ä¼˜å…ˆçº§: {priority} â€¢ æ—¶é•¿: {duration}{' | å·²è¯»' if video_read else ''}",
                        element_id=element_id,
                    )
                    video_list.append(video_info)

                    # è§†é¢‘åŸºæœ¬ä¿¡æ¯å’Œé“¾æ¥æŒ‰é’®
                    video_url = video.get("é“¾æ¥", "")

                    video_button = JsonBuilder.build_button_element(
                        text="ğŸ“º Bç«™",
                        size="tiny",
                        url_data={
                            "default_url": video_url,
                            "pc_url": video_url,
                            "ios_url": video_url,
                            "android_url": convert_to_bili_app_link(video_url),
                        },
                    )

                    video_read_button = JsonBuilder.build_button_element(
                        text="âœ… å·²è¯»",
                        size="tiny",
                        action_data={
                            "card_action": "mark_bili_read_in_daily_summary",
                            "pageid": video_pageid,
                            "video_index": i,  # æ¨èè§†é¢‘åºå· (1,2,3)
                        },
                        element_id=f"mark_bili_read_{i}",
                    )
                    button_list = [video_button]
                    if (not video_read) and video_pageid:
                        button_list.append(video_read_button)

                    button_group = JsonBuilder.build_button_group_element(button_list)
                    video_list.append(button_group)

        return elements, video_list

    def format_notion_bili_analysis(self, data: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–notion Bç«™ç»Ÿè®¡æ•°æ®"""
        content = "ğŸ¯ **Bç«™ä¿¡æ¯åˆ†ææ±‡æ€»**"

        statistics = data.get("statistics", {})

        # æ€»ä½“ç»Ÿè®¡
        total_count = statistics.get("total_count", None)

        content += f"\n\nğŸ“ˆ **æ€»è®¡:** {total_count} ä¸ªæœªè¯»è§†é¢‘"

        if total_count > 0:
            # ä¼˜å…ˆçº§ç»Ÿè®¡ï¼ˆå¢åŠ æ—¶é•¿æ€»è®¡ï¼‰
            priority_stats = statistics.get("priority_stats", {})
            if priority_stats:
                content += "\nğŸ¯ **ä¼˜å…ˆçº§åˆ†å¸ƒ:**"
                for priority, info in priority_stats.items():
                    count = info.get("æ•°é‡", info.get("count", 0))
                    total_minutes = info.get("æ€»æ—¶é•¿åˆ†é’Ÿ", info.get("total_minutes", 0))
                    time_str = format_time_label(total_minutes)
                    content += f"\nâ€¢ {priority}: {count} ä¸ª ({time_str})"

            # AIæ±‡æ€»ï¼ˆåªæ˜¾ç¤ºè´¨é‡è¯„åˆ†>=5çš„ï¼‰
            ai_summary = statistics.get("ai_summary", "")
            ai_quality_score = statistics.get("ai_quality_score", 0)
            if ai_summary and ai_quality_score >= 5:
                content += f"\nğŸŒŸ **AIæ±‡æ€»:**\n{ai_summary}"

        return content

    # endregion

    # region è¿è¥æ•°æ®ç»„ä»¶
    def build_operation_elements(
        self, operation_data: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """æ„å»ºè¿è¥æ•°æ®å…ƒç´ """
        elements = []
        content = self.format_operation_data(operation_data)
        elements.append(JsonBuilder.build_markdown_element(content))
        return elements

    def format_operation_data(
        self, operation_data: Dict[str, Any], detail_mode: bool = False
    ) -> str:
        """æ ¼å¼åŒ–è¿è¥æ•°æ®ä¿¡æ¯"""
        content = "\n\nğŸ“ˆ **è¿è¥æ—¥æŠ¥**"

        # è·å–æ¯æ—¥æ•°æ®
        daily = operation_data.get("daily")
        is_monday = operation_data.get("is_monday", False)

        if daily and daily.get("success", False):
            current = daily.get("current", {})
            comparison = daily.get("comparison", {})

            # åŸºç¡€ç»Ÿè®¡ä¿¡æ¯
            date_str = current.get("stats_date", "æœªçŸ¥æ—¥æœŸ")
            content += f"\nğŸ“… **{date_str} æ•°æ®æ¦‚è§ˆ**"

            # ç”¨æˆ·æ´»è·ƒåº¦
            active_users = current.get("active_users", 0)
            new_users = current.get("new_users", 0)
            content += (
                f"\nğŸ‘¥ **ç”¨æˆ·æ´»è·ƒåº¦:** {active_users} æ´»è·ƒç”¨æˆ· (+{new_users} æ–°å¢)"
            )

            # å†…å®¹ç»Ÿè®¡
            if detail_mode:
                new_videos_user = current.get("new_videos_user", 0)
                new_videos_admin = current.get("new_videos_admin", 0)
                total_requests = current.get("total_user_requests", 0)
                content += f"\nğŸ¬ **å†…å®¹ç»Ÿè®¡:** {new_videos_user} ç”¨æˆ·è§†é¢‘ | {new_videos_admin} ç®¡ç†å‘˜è§†é¢‘"
                content += f"\nğŸ”„ **è¯·æ±‚æ€»æ•°:** {total_requests} æ¬¡"

            # ç¼“å­˜æ•ˆç‡
            cache_hits = current.get("cache_hits", 0)
            cache_rate = current.get("cache_utilization_rate", 0)
            content += f"\nâš¡ **ç¼“å­˜æ•ˆç‡:** {cache_hits} æ¬¡å‘½ä¸­ ({cache_rate:.1%})"

            # æ‹’ç»ç»Ÿè®¡
            total_rejections = current.get("total_rejections", 0)
            rejected_users = current.get("rejected_users", 0)
            if rejected_users > 0:
                rejected_rate = total_rejections / rejected_users
                content += f"\nğŸš« **æ‹’ç»è¯·æ±‚:** {total_rejections} æ¬¡ ({rejected_users} ç”¨æˆ·ï¼Œäººå‡ {rejected_rate:.1f} æ¬¡)"
            else:
                content += (
                    f"\nğŸš« **æ‹’ç»è¯·æ±‚:** {total_rejections} æ¬¡ ({rejected_users} ç”¨æˆ·)"
                )

            if detail_mode:
                # æ˜¾ç¤ºå…³é”®å˜åŒ–è¶‹åŠ¿
                if comparison:
                    trends = []

                    # æ£€æŸ¥ç”¨æˆ·æ´»è·ƒåº¦å˜åŒ–
                    if "active_users" in comparison:
                        change = comparison["active_users"].get("change", 0)
                        trend = comparison["active_users"].get("trend", "")
                        if abs(change) >= 5:  # æ˜¾è‘—å˜åŒ–
                            trend_emoji = "ğŸ“ˆ" if trend == "up" else "ğŸ“‰"
                            trends.append(f"æ´»è·ƒç”¨æˆ·{trend_emoji}{abs(change)}")

                    # æ£€æŸ¥è¯·æ±‚é‡å˜åŒ–
                    if "total_user_requests" in comparison:
                        change = comparison["total_user_requests"].get("change", 0)
                        trend = comparison["total_user_requests"].get("trend", "")
                        if abs(change) >= 20:  # æ˜¾è‘—å˜åŒ–
                            trend_emoji = "ğŸ“ˆ" if trend == "up" else "ğŸ“‰"
                            trends.append(f"è¯·æ±‚é‡{trend_emoji}{abs(change)}")

                    if trends:
                        content += f"\nğŸ“Š **ä»Šæ—¥å˜åŒ–:** {' | '.join(trends)}"

                # å¹¿å‘Šæ£€æµ‹ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰ï¼‰
                ads_detected = current.get("ads_detected", 0)
                total_ad_duration = current.get("total_ad_duration", 0)
                ad_rate = ads_detected / total_requests if total_requests > 0 else 0
                if ads_detected > 0:
                    ad_minutes = int(total_ad_duration / 60) if total_ad_duration else 0
                    content += f"\nğŸ¯ **å¹¿å‘Šæ£€æµ‹:** {ads_detected} ä¸ªå¹¿å‘Šï¼Œæ€»æ—¶é•¿ {ad_minutes} åˆ†é’Ÿï¼Œå æ¯” {ad_rate:.1%}"

        # å¦‚æœæ˜¯å‘¨ä¸€ï¼Œæ·»åŠ å‘¨æŠ¥æ•°æ®
        if is_monday:
            weekly = operation_data.get("weekly")
            if weekly and weekly.get("success", False):
                content += self.format_weekly_operation_data(weekly.get("data", {}))

        return content

    def format_weekly_operation_data(self, weekly_data: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–å‘¨è¿è¥æ•°æ®"""
        content = "\n\nğŸ“… **æœ¬å‘¨è¿è¥æ¦‚è§ˆ**"

        # å‘¨æœŸä¿¡æ¯
        week_start = weekly_data.get("week_start_date", "")
        week_end = weekly_data.get("week_end_date", "")
        if week_start and week_end:
            content += f"\nğŸ—“ï¸ **ç»Ÿè®¡å‘¨æœŸ:** {week_start} è‡³ {week_end}"

        # ç”¨æˆ·ç»Ÿè®¡
        total_users = weekly_data.get("total_users", 0)
        weekly_new_users = weekly_data.get("weekly_new_users", 0)
        weekly_churned_users = weekly_data.get("weekly_churned_users", 0)
        active_users = weekly_data.get("active_users", 0)
        content += f"\nğŸ‘¥ **ç”¨æˆ·æ¦‚å†µ:** {total_users} æ€»ç”¨æˆ· | {active_users} æ´»è·ƒ | +{weekly_new_users} æ–°å¢ | -{weekly_churned_users} æµå¤±"

        # ä»˜è´¹ç”¨æˆ·
        free_users = weekly_data.get("free_users", 0)
        paid_users = weekly_data.get("paid_users", 0)
        if paid_users > 0:
            paid_rate = (
                paid_users / (free_users + paid_users) * 100
                if (free_users + paid_users) > 0
                else 0
            )
            content += f"\nğŸ’° **ä»˜è´¹æƒ…å†µ:** {paid_users} ä»˜è´¹ç”¨æˆ· ({paid_rate:.1f}%)"

        # å†…å®¹åˆ†æ
        weekly_unique_videos = weekly_data.get("weekly_unique_videos", 0)
        weekly_requests = weekly_data.get("weekly_total_requests", 0)
        cache_rate = weekly_data.get("weekly_cache_utilization_rate", 0)
        content += f"\nğŸ“Š **å†…å®¹æ´»åŠ¨:** {weekly_unique_videos} è§†é¢‘ | {weekly_requests} è¯·æ±‚ | ç¼“å­˜å‘½ä¸­ç‡ {cache_rate:.1%}"

        # å¹¿å‘Šåˆ†æ
        weekly_ad_videos = weekly_data.get("weekly_ad_videos", 0)
        weekly_ad_time_ratio = weekly_data.get("weekly_ad_time_ratio", 0)
        if weekly_ad_videos > 0:
            content += f"\nğŸ¯ **å¹¿å‘Šåˆ†æ:** {weekly_ad_videos} ä¸ªå¹¿å‘Šè§†é¢‘ ({weekly_ad_time_ratio:.2%} æ—¶é•¿å æ¯”)"

        return content

    # endregion

    # region æœåŠ¡çŠ¶æ€ç»„ä»¶
    def build_services_status_elements(
        self, services_status: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """æ„å»ºæœåŠ¡çŠ¶æ€å…ƒç´ """
        elements = []
        content = self.format_services_status(services_status)
        elements.append(JsonBuilder.build_markdown_element(content))
        return elements

    def format_services_status(self, services_status: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æœåŠ¡çŠ¶æ€ä¿¡æ¯"""
        content = ""
        # ä¸¤ä¸ª\nå¼€å¤´ä¼šè¢«è‡ªåŠ¨å¤„ç†æ‰ï¼Œæ‰€ä»¥ä¸ç”¨é¢å¤–å†™ä»£ç 

        services = services_status.get("services", {})

        # Bç«™APIæœåŠ¡çŠ¶æ€ï¼Œåªåœ¨å¼‚å¸¸æ˜¯æ˜¾ç¤º
        bili_api = services.get("bilibili_api", {})
        if bili_api.get("enabled", False):
            status = bili_api.get("status", "unknown")
            message = bili_api.get("message", "")
            response_time = bili_api.get("response_time", "")
            url = bili_api.get("url", "")

            status_emoji = {
                "healthy": "âœ…",
                "warning": "âš ï¸",
                "error": "âŒ",
                "disabled": "â¸ï¸",
            }.get(status, "â“")

            if status != "healthy":
                content += f"\n\n{status_emoji} **{bili_api.get('service_name', 'Bç«™APIæœåŠ¡')}**"
                content += f"\nçŠ¶æ€: {message}"
                if response_time:
                    content += f" ({response_time})"
                if url and status != "error":
                    # æˆªæ–­é•¿URLæ˜¾ç¤º
                    display_url = url if len(url) <= 40 else url[:37] + "..."
                    content += f"\nåœ°å€: {display_url}"

        else:
            content += "\n\nâ¸ï¸ **Bç«™APIæœåŠ¡**: æœªå¯ç”¨"

        # GradioæœåŠ¡çŠ¶æ€
        gradio = services.get("gradio", {})
        if gradio.get("enabled", False):
            status = gradio.get("status", "unknown")
            message = gradio.get("message", "")
            response_time = gradio.get("response_time", "")
            url = gradio.get("url", "")

            status_emoji = {
                "healthy": "âœ…",
                "warning": "âš ï¸",
                "error": "âŒ",
                "disabled": "â¸ï¸",
            }.get(status, "â“")

            content += (
                f"\n\n{status_emoji} **{gradio.get('service_name', 'Gradioå›¾åƒæœåŠ¡')}**"
            )
            if status != "healthy":
                content += f"\nçŠ¶æ€: {message}"
                if response_time:
                    content += f" ({response_time})"
            if url and status != "error":
                # æˆªæ–­é•¿URLæ˜¾ç¤º
                display_url = url if len(url) <= 40 else url[:37] + "..."
                content += f"\nåœ°å€: {display_url}"

            # æ˜¾ç¤ºä»¤ç‰Œä¿¡æ¯
            token_info = gradio.get("token_info", {})
            if token_info.get("has_token", False):
                token_status = token_info.get("status", "unknown")
                if token_status == "valid":
                    expires_in_hours = token_info.get("expires_in_hours", 0)
                    expires_at = token_info.get("expires_at", "")
                    # æ ¼å¼åŒ–æ—¶é—´ä¸º mm-dd hh:mm
                    formatted_expires_at = ""
                    if expires_at:
                        try:
                            # å…¼å®¹å¸¦æ—¶åŒºçš„ISOæ ¼å¼
                            if "+" in expires_at or "Z" in expires_at:
                                # å»æ‰æ—¶åŒºä¿¡æ¯
                                expires_at_clean = expires_at.split("+")[0].replace(
                                    "Z", ""
                                )
                            else:
                                expires_at_clean = expires_at
                            dt = datetime.fromisoformat(expires_at_clean)
                            formatted_expires_at = dt.strftime("%m-%d %H:%M")
                        except Exception:
                            formatted_expires_at = expires_at  # è§£æå¤±è´¥åˆ™åŸæ ·è¾“å‡º
                    if expires_in_hours <= 24:  # 24å°æ—¶å†…è¿‡æœŸæ˜¾ç¤ºè­¦å‘Š
                        content += f"\nâš ï¸ ä»¤ç‰Œå°†åœ¨ {expires_in_hours}å°æ—¶ åè¿‡æœŸ ({formatted_expires_at})"
                    else:
                        content += f"\nğŸ”‘ ä»¤ç‰Œæœ‰æ•ˆæœŸè‡³: {formatted_expires_at}"
                elif token_status == "expired":
                    expires_at = token_info.get("expires_at", "")
                    formatted_expires_at = ""
                    if expires_at:
                        try:
                            if "+" in expires_at or "Z" in expires_at:
                                expires_at_clean = expires_at.split("+")[0].replace(
                                    "Z", ""
                                )
                            else:
                                expires_at_clean = expires_at
                            dt = datetime.fromisoformat(expires_at_clean)
                            formatted_expires_at = dt.strftime("%m-%d %H:%M")
                        except Exception:
                            formatted_expires_at = expires_at
                    content += f"\nâŒ ä»¤ç‰Œå·²äº{formatted_expires_at}è¿‡æœŸï¼Œéœ€è¦æ›´æ–°"
                elif token_status == "parse_error":
                    content += "\nâš ï¸ ä»¤ç‰Œæ—¶é—´è§£æå¼‚å¸¸"
                elif token_status == "no_expiry_info":
                    content += "\nğŸ”‘ ä»¤ç‰Œå·²é…ç½® (æ— è¿‡æœŸä¿¡æ¯)"
        else:
            content += "\n\nâ¸ï¸ **Gradioå›¾åƒæœåŠ¡**: æœªå¯ç”¨"

        return content

    # endregion

    # region æ—¥å¸¸ç»„ä»¶-æ€»

    def build_routine_elements(
        self, routine_data: Dict[str, Any], user_id: str
    ) -> List[Dict[str, Any]]:
        """æ„å»ºæ—¥å¸¸å…ƒç´ """
        elements = []
        image_key = routine_data.get("daily", {}).get("image_key", "")
        main_color = routine_data.get("daily", {}).get("main_color", {})
        weekly_data = routine_data.get("weekly", {})

        if image_key:
            image_element = JsonBuilder.build_image_element(
                image_key=image_key,
                alt=f"æ˜¨å¤©ä½ çš„{main_color.get('max_weight_category', '')}å°ç« ",
                title="æ˜¨æ—¥ä¸ªæ€§å°ç« ",
                corner_radius="5px",
                scale_type="crop_center",
                size="80px 90px",
            )
            elements.append(image_element)

        if weekly_data:
            # å…ˆå¢åŠ cardé‡Œçš„å†…å®¹ï¼Œå†æŠŠå…¶ä»–å†…å®¹åˆ›å»ºæˆæ–‡æ¡£
            pie_raw_data = weekly_data.get("category_stats", [])

            if pie_raw_data:
                pie_data = []
                color_mapping = {}  # ç”¨äºå­˜å‚¨ç±»å‹åˆ°é¢œè‰²çš„æ˜ å°„
                for item in pie_raw_data:
                    type_name = item.get("category", "") or "æ— åˆ†ç±»"
                    color = item.get("color", "#959BEE")  # é»˜è®¤é¢œè‰²

                    pie_data.append(
                        {
                            "type": type_name,
                            "value": round(
                                item.get("category_total_duration", 0) / 60, 1
                            ),
                        }
                    )
                    color_mapping[type_name] = color
                pie_element = JsonBuilder.build_chart_element(
                    chart_type="pie",
                    title="ä¸Šå‘¨æ—¶é—´ç»Ÿè®¡",
                    data=pie_data,
                    color_mapping=color_mapping,
                    formatter="{type}: {value}å°æ—¶,{_percent_}%",
                )
                elements.append(pie_element)

            # è¿™é‡Œç›´æ¥æ·»åŠ æ–‡æ¡£ï¼Œè¿˜éœ€è¦å¼‚æ­¥è°ƒç”¨llmï¼Ÿè¿™ä¸ªä¼¼ä¹ä¸åº”è¯¥æ˜¯å‰ç«¯åšçš„äº‹ï¼Œé‚£å°±å…ˆå¢åŠ æ–‡æ¡£å§ã€‚
            # è¿™é‡Œçš„ä¸šåŠ¡é€»è¾‘ç»“æœå°±æ˜¯å¾€ä¸€ä¸ªtokensçš„æ–‡ä»¶å¤¹å¢åŠ ä¸€ä¸ªpageï¼Œå­˜åœ¨æœ¬åœ°
            weekly_record = self.routine_business.load_weekly_record(user_id)
            root_folder_token = weekly_record.get("root_folder_token", "")
            business_folder_token = weekly_record.get("business_folder_token", {}).get(
                "å‘¨æŠ¥å‘Š", ""
            )
            document_manager = self.app_controller.get_adapter(
                AdapterNames.FEISHU
            ).cloud_manager

            need_update_tokens = False
            if not root_folder_token:
                root_folder_token = document_manager.get_user_root_folder_token(user_id)
                weekly_record["root_folder_token"] = root_folder_token
                need_update_tokens = True
            if not business_folder_token:
                business_folder_token = document_manager.get_user_business_folder_token(
                    user_id, "å‘¨æŠ¥å‘Š", root_folder_token
                )
                weekly_record["business_folder_token"]["å‘¨æŠ¥å‘Š"] = business_folder_token
                need_update_tokens = True

            if need_update_tokens:
                self.routine_business.save_weekly_record(user_id, weekly_record)

            title = weekly_data.get("document_title", "")
            # åŸå­åŒ–åŒæ­¥è°ƒç”¨ï¼šå…ˆåˆ›å»ºæ–‡æ¡£ï¼Œå†å†™å…¥å—ï¼ˆå‡å¸¦æŒ‡æ•°é€€é¿ï¼‰ã€‚å¦‚éœ€éé˜»å¡ï¼Œæœªæ¥åˆ‡æ¢åˆ°å¼‚æ­¥å®¢æˆ·ç«¯ç»Ÿä¸€è°ƒåº¦ã€‚
            doc_data = document_manager.create_document(
                folder_token=business_folder_token,
                document_title=title,
            )
            # SDK è¿”å›è·¯å¾„ï¼šdata.document.document_id
            document_id = (
                getattr(getattr(doc_data, "document", None), "document_id", None)
                if doc_data
                else None
            )
            if document_id:
                content = self.generate_weekly_document_content(routine_data)
                block_resp = document_manager.create_document_block_descendant(
                    document_id=document_id,
                    block_data=content,
                    document_title=title,
                )
                url = f"https://ddsz-peng13.feishu.cn/docx/{document_id}"
                folder_url = f"https://ddsz-peng13.feishu.cn/drive/folder/{business_folder_token}"
                # è¦çœ‹çœ‹æ€ä¹ˆè®¾ç½®ä¸ºé»˜è®¤æ‰“å¼€é“¾æ¥ï¼Œä½†è¿™æ˜¯å°äº‹ï¼Œè¿˜æ˜¯è¦å…ˆåŠ å†…å®¹ï¼Œä»¥åŠåç»­ç¨å¾®äººå¤šä¸€ç‚¹ä¹‹å‰å°±è¦åšå¼‚æ­¥çš„æ”¹é€ ï¼ŒåŒ…æ‹¬é…åˆLLM
                markdown_element = JsonBuilder.build_markdown_element(
                    content=f"[æŸ¥çœ‹åˆ†æï¼š{title}]({url})\n[è®¿é—®æŠ¥å‘Šæ–‡ä»¶å¤¹]({folder_url})"
                )
                elements.append(markdown_element)
                action_suggestions_data = weekly_data.get("ai_analysis", {}).get(
                    "strategic_action_suggestions", []
                )
                if action_suggestions_data:
                    markdown_element = JsonBuilder.build_markdown_element(
                        content=f":MeMeMe: **æœ¬å‘¨è¡ŒåŠ¨å»ºè®®**"
                    )
                    elements.append(markdown_element)
                    for action in action_suggestions_data:
                        action_data = {
                            "card_action": "mark_weekly_action_accepted",
                            "action_id": action.get("id", ""),
                        }
                        checker_element = JsonBuilder.build_checker_element(
                            text=f"{action.get('execution_difficulty', '')}éš¾åº¦: {action.get('title', '')}",
                            checked=action.get("accepted", False),
                            disabled=False,
                            action_data=action_data,
                        )
                        markdown_element = JsonBuilder.build_markdown_element(
                            content=action.get("specific_action", ""),
                            text_size="small",
                        )
                        elements.extend([checker_element, markdown_element])

            else:
                debug_utils.log_and_print("åˆ›å»ºå‘¨æŠ¥å‘Šæ–‡æ¡£å¤±è´¥", log_level="ERROR")

        return elements

    # endregion

    # region æ—¥å¸¸ç»„ä»¶-å‘¨æŠ¥å‘Š

    def generate_weekly_document_content(
        self, routine_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ç”Ÿæˆå‘¨æŠ¥å‘Šæ–‡æ¡£å†…å®¹(ä¹Ÿå¯èƒ½å…¼å®¹æˆæœˆæŠ¥)"""
        # ä»¥åµŒå¥—å—çš„æ–¹å¼ä¸€æ¬¡æ€§ç»„è£…å¥½
        # æ¯ä¸ªå…ƒç´ éƒ½åŒ…å«äº†è‡ªå·±çš„idè¿›childrenå’Œè‡ªå·±çš„å†…å®¹ï¼Œè¿›descendants
        weekly_data = routine_data.get("weekly", {})
        weekly_table_data = weekly_data.get("timetable", {})

        children = []
        descendants = []
        # å…ˆæ„å»ºè¡¨æ ¼
        document_manager = self.app_controller.get_adapter(
            AdapterNames.FEISHU
        ).cloud_manager

        # å®‰å…¨è·å–æ•°æ®
        time_labels: List[str] = weekly_table_data.get("time_labels", [])
        days_data: Dict[str, Any] = weekly_table_data.get("days", {})

        # é¡¶å±‚ childrenï¼ˆä¸¤ä¸ªå—ï¼šæ ‡é¢˜ + è¡¨æ ¼ï¼‰
        # æ–‡æ¡£å¤§æ¦‚è¦åœ¨è¿™é‡Œå¤„ç†ï¼Œé‚£ä¹ˆchildrenå’Œdescendentsè¦ä¸€èµ·åŠ å’¯ï¼Ÿç„¶åå†è¿½åŠ ä¹‹å‰çš„è¡¨æ ¼ï¼Œè¿™ä¸ªä½œä¸ºä¸€ä¸ªæ€»å®¹å™¨è¿˜æ˜¯ä¸é”™çš„
        heading_block_id = "heading_timetable"
        table_block_id = "table_timetable"
        children = [heading_block_id, table_block_id]

        # æ ‡é¢˜å—ï¼ˆé‡‡ç”¨ heading1ï¼‰
        heading_block = document_manager.create_formated_text_block(
            block_id=heading_block_id,
            text="ä¸ªäººæ—¶é—´è¡¨",
            block_type="heading1",
        )
        descendants.append(heading_block)

        # è¡¨å¤´æ˜ å°„
        day_label_map = {
            "mon": "å‘¨ä¸€",
            "tue": "å‘¨äºŒ",
            "wed": "å‘¨ä¸‰",
            "thu": "å‘¨å››",
            "fri": "å‘¨äº”",
            "sat": "å‘¨å…­",
            "sun": "å‘¨æ—¥",
        }
        day_keys: List[str] = list(day_label_map.keys())

        # è¡¨æ ¼ children é¡ºåºï¼šæŒ‰è¡Œ (header -> æ¯ä¸ªæ—¶é—´ç‚¹)ï¼Œæ¯è¡ŒæŒ‰åˆ— (time -> mon..sun)
        table_children_ids: List[str] = []

        # è¡¨å¤´è¡Œ cell ä¸æ–‡æœ¬
        header_cell_ids = ["cell_header_time"] + [
            f"cell_header_{day}" for day in day_keys
        ]
        header_text_ids = ["text_header_time"] + [
            f"text_header_{day}" for day in day_keys
        ]
        table_children_ids.extend(header_cell_ids)

        # æ·»åŠ è¡¨å¤´ cell ä¸ text å—
        # æ—¶é—´åˆ—è¡¨å¤´
        descendants.append(
            document_manager.create_table_cell_block(
                block_id=header_cell_ids[0], children=[header_text_ids[0]]
            )
        )
        descendants.append(
            document_manager.create_text_block(
                block_id=header_text_ids[0], text="æ—¶é—´", align=2
            )
        )
        # æ˜ŸæœŸåˆ—è¡¨å¤´
        for idx, day in enumerate(day_keys, start=1):
            descendants.append(
                document_manager.create_table_cell_block(
                    block_id=header_cell_ids[idx], children=[header_text_ids[idx]]
                )
            )
            descendants.append(
                document_manager.create_text_block(
                    block_id=header_text_ids[idx], text=day_label_map[day], align=2
                )
            )

        # æ•°æ®è¡Œ cell ä¸æ–‡æœ¬
        for time_label in time_labels:
            # ä½¿ç”¨å°æ—¶ä½œä¸º id ç‰‡æ®µï¼Œå¦‚ "00"ã€"02"ã€"12" ç­‰
            row_cell_ids = [f"cell_{time_label}"] + [
                f"cell_{time_label}_{day}" for day in day_keys
            ]
            row_text_ids = [f"text_{time_label}"] + [
                f"text_{time_label}_{day}" for day in day_keys
            ]
            table_children_ids.extend(row_cell_ids)

            # æ—¶é—´åˆ—å•å…ƒæ ¼
            descendants.append(
                document_manager.create_table_cell_block(
                    block_id=row_cell_ids[0], children=[row_text_ids[0]]
                )
            )
            descendants.append(
                document_manager.create_text_block(
                    block_id=row_text_ids[0], text=time_label, align=2
                )
            )

            # æ¯å¤©åˆ—å•å…ƒæ ¼
            for col_index, day in enumerate(day_keys, start=1):
                # å–å¯¹åº”æ§½ä½æ•°æ®
                slot_info: Dict[str, Any] = days_data.get(day, {}).get(time_label, {})
                slot_text: str = slot_info.get("text", "")
                slot_color = slot_info.get("color", None)
                background_color_id = (
                    slot_color.background_color_id
                    if hasattr(slot_color, "background_color_id")
                    else -1
                )

                descendants.append(
                    document_manager.create_table_cell_block(
                        block_id=row_cell_ids[col_index],
                        children=[row_text_ids[col_index]],
                    )
                )
                descendants.append(
                    document_manager.create_text_block(
                        block_id=row_text_ids[col_index],
                        text=slot_text,
                        background_color=background_color_id,
                        align=2,
                    )
                )

        # è¡¨æ ¼å—
        row_size = 1 + len(time_labels)
        column_size = 1 + len(day_keys)
        table_block = document_manager.create_table_block(
            row_size=row_size,
            column_size=column_size,
            block_id=table_block_id,
            children=table_children_ids,
            column_width=[70] + [110] * len(day_keys),
            header_row=True,
            header_column=True,
        )
        descendants.append(table_block)

        # æ·»åŠ AIåˆ†ææŠ¥å‘Šå’Œé‡è¦æŠ¥å‘Šå’Œæ´»åŠ¨æ˜ç»†
        from collections import defaultdict

        ai_analysis = weekly_data.get("ai_analysis", {})
        event_records = weekly_data.get("event_summary", [])
        # å¦‚æœä¸ºDataFrameï¼ŒæŒ‰éœ€è½¬æ¢ä¸ºrecords
        if hasattr(event_records, "to_dict"):
            event_records = event_records.to_dict(orient="records")
        category_stats = weekly_data.get("category_stats", [])

        # === AIåˆ†ææŠ¥å‘Š ===
        if ai_analysis:
            core_narrative = ai_analysis.get("core_narrative", {})
            ai_title = "AIåˆ†ææŠ¥å‘Š"
            if core_narrative["theme"]:
                ai_title += f':{core_narrative["theme"]}'
            children.append("heading_ai_analysis")
            descendants.append(
                document_manager.create_formated_text_block(
                    block_id="heading_ai_analysis",
                    text=ai_title,
                    block_type="heading1",
                )
            )

            # åˆ†æå¸ˆå‰è¨€
            if ai_analysis.get("analyst_foreword"):
                children.append("heading_analyst_foreword")
                descendants.append(
                    document_manager.create_formated_text_block(
                        block_id="heading_analyst_foreword",
                        text="åˆ†æå¸ˆå‰è¨€",
                        block_type="heading2",
                    )
                )
                children.append("text_analyst_foreword")
                descendants.append(
                    document_manager.create_text_block(
                        block_id="text_analyst_foreword",
                        text=ai_analysis["analyst_foreword"],
                    )
                )

            # æ ¸å¿ƒå™äº‹
            if core_narrative:
                children.append("heading_core_narrative")
                descendants.append(
                    document_manager.create_formated_text_block(
                        block_id="heading_core_narrative",
                        text="æ ¸å¿ƒå™äº‹",
                        block_type="heading2",
                    )
                )

                if core_narrative.get("narrative_summary"):
                    children.append("heading_narrative_summary")
                    descendants.append(
                        document_manager.create_formated_text_block(
                            block_id="heading_narrative_summary",
                            text="å™äº‹æ€»ç»“",
                            block_type="heading3",
                        )
                    )
                    children.append("text_narrative_summary")
                    descendants.append(
                        document_manager.create_text_block(
                            block_id="text_narrative_summary",
                            text=core_narrative["narrative_summary"],
                        )
                    )

                # åŠ¨æ€æ¡†æ¶æ´å¯Ÿ
                dynamic_framework = core_narrative.get("dynamic_framework_insight", {})
                if (
                    dynamic_framework
                    and dynamic_framework.get("relevance_score", -1) > 6
                ):
                    children.append("heading_dynamic_framework")
                    descendants.append(
                        document_manager.create_formated_text_block(
                            block_id="heading_dynamic_framework",
                            text="åŠ¨æ€æ¡†æ¶æ´å¯Ÿ",
                            block_type="heading3",
                        )
                    )

                    framework_text = ""
                    if dynamic_framework.get("framework_name"):
                        framework_text += (
                            f"æ¡†æ¶ï¼š{dynamic_framework['framework_name']}\n\n"
                        )
                    if dynamic_framework.get("insight"):
                        framework_text += dynamic_framework["insight"]

                    children.append("text_dynamic_framework")
                    descendants.append(
                        document_manager.create_text_block(
                            block_id="text_dynamic_framework", text=framework_text
                        )
                    )

            # èŠ‚å¾‹åˆ†æ
            rhythm_analysis = ai_analysis.get("rhythm_analysis", {})
            if rhythm_analysis:
                children.append("heading_rhythm_analysis")
                descendants.append(
                    document_manager.create_formated_text_block(
                        block_id="heading_rhythm_analysis",
                        text="èŠ‚å¾‹åˆ†æ",
                        block_type="heading2",
                    )
                )

                # å·²è¯†åˆ«çš„èŠ‚å¾‹
                identified_rhythms = rhythm_analysis.get("identified_rhythms", [])
                if identified_rhythms:
                    children.append("heading_identified_rhythms")
                    descendants.append(
                        document_manager.create_formated_text_block(
                            block_id="heading_identified_rhythms",
                            text="å·²çŸ¥çš„èŠ‚å¾‹",
                            block_type="heading3",
                        )
                    )
                    children.append("text_identified_rhythms")
                    descendants.append(
                        document_manager.create_text_block(
                            block_id="text_identified_rhythms",
                            text="\n".join(
                                [f"â€¢ {rhythm}" for rhythm in identified_rhythms]
                            ),
                        )
                    )

                # æ½œåœ¨æ–°èŠ‚å¾‹
                potential_new_rhythms = rhythm_analysis.get("potential_new_rhythms", [])
                if potential_new_rhythms:
                    children.append("heading_potential_new_rhythms")
                    descendants.append(
                        document_manager.create_formated_text_block(
                            block_id="heading_potential_new_rhythms",
                            text="æ½œåœ¨èŠ‚å¾‹",
                            block_type="heading3",
                        )
                    )
                    children.append("text_potential_new_rhythms")
                    descendants.append(
                        document_manager.create_text_block(
                            block_id="text_potential_new_rhythms",
                            text="\n".join(
                                [f"â€¢ {rhythm}" for rhythm in potential_new_rhythms]
                            ),
                        )
                    )

                # é¢„æµ‹
                if rhythm_analysis.get("prediction"):
                    children.append("heading_rhythm_prediction")
                    descendants.append(
                        document_manager.create_formated_text_block(
                            block_id="heading_rhythm_prediction",
                            text="èŠ‚å¾‹é¢„æµ‹",
                            block_type="heading3",
                        )
                    )
                    children.append("text_rhythm_prediction")
                    descendants.append(
                        document_manager.create_text_block(
                            block_id="text_rhythm_prediction",
                            text=rhythm_analysis["prediction"],
                        )
                    )

            # éšè—æ•°æ®æ´å¯Ÿ
            hidden_insights = ai_analysis.get("hidden_data_insights", [])
            if hidden_insights:
                children.append("heading_hidden_insights")
                descendants.append(
                    document_manager.create_formated_text_block(
                        block_id="heading_hidden_insights",
                        text="æ•°æ®æ´å¯Ÿ",
                        block_type="heading2",
                    )
                )

                for i, insight in enumerate(hidden_insights):
                    if insight.get("title"):
                        children.append(f"heading_insight_{i}")
                        descendants.append(
                            document_manager.create_formated_text_block(
                                block_id=f"heading_insight_{i}",
                                text=insight["title"],
                                block_type="heading3",
                            )
                        )

                    if insight.get("finding"):
                        children.append(f"text_insight_{i}")
                        descendants.append(
                            document_manager.create_text_block(
                                block_id=f"text_insight_{i}", text=insight["finding"]
                            )
                        )

            # è¿‡å¾€è¡ŒåŠ¨å›é¡¾
            previous_actions = ai_analysis.get("previous_actions_review", {})
            if previous_actions:
                children.append("heading_previous_actions")
                descendants.append(
                    document_manager.create_formated_text_block(
                        block_id="heading_previous_actions",
                        text="ä¸ŠæœŸå»ºè®®å›é¡¾",
                        block_type="heading2",
                    )
                )

                # åé¦ˆæ¼”åŒ–è¯´æ˜
                if previous_actions.get("feedback_evolution_note"):
                    children.append("heading_feedback_evolution")
                    descendants.append(
                        document_manager.create_formated_text_block(
                            block_id="heading_feedback_evolution",
                            text="ä½ çš„å˜åŒ–",
                            block_type="heading3",
                        )
                    )
                    children.append("text_feedback_evolution")
                    descendants.append(
                        document_manager.create_text_block(
                            block_id="text_feedback_evolution",
                            text=previous_actions["feedback_evolution_note"],
                        )
                    )

                # è¯¦ç»†å›é¡¾
                detailed_review = previous_actions.get("detailed_review", [])
                if detailed_review:
                    children.append("heading_detailed_review")
                    descendants.append(
                        document_manager.create_formated_text_block(
                            block_id="heading_detailed_review",
                            text="è¯¦ç»†å»ºè®®å›é¡¾",
                            block_type="heading3",
                        )
                    )

                    for i, review in enumerate(detailed_review):
                        suggestion_id = review.get("suggestion_id", f"å»ºè®®{i+1}")
                        user_choice = review.get("user_choice", False)
                        assessment = review.get("analyst_assessment", "")

                        children.append(f"heading_review_{i}")
                        descendants.append(
                            document_manager.create_formated_text_block(
                                block_id=f"heading_review_{i}",
                                text=f"{suggestion_id} (å“åº”: {'é‡‡çº³' if user_choice else 'æ‹’ç»'})",
                                block_type="heading4",
                            )
                        )

                        if assessment:
                            children.append(f"text_review_{i}")
                            descendants.append(
                                document_manager.create_text_block(
                                    block_id=f"text_review_{i}", text=assessment
                                )
                            )

            # æˆ˜ç•¥æ€§è¡ŒåŠ¨å»ºè®®
            strategic_suggestions = ai_analysis.get("strategic_action_suggestions", [])
            if strategic_suggestions:
                children.append("heading_strategic_suggestions")
                descendants.append(
                    document_manager.create_formated_text_block(
                        block_id="heading_strategic_suggestions",
                        text="æœ¬å‘¨è¡ŒåŠ¨å»ºè®®",
                        block_type="heading2",
                    )
                )

                for i, suggestion in enumerate(strategic_suggestions):
                    if suggestion.get("title"):
                        title_text = suggestion["title"]

                        children.append(f"heading_suggestion_{i}")
                        descendants.append(
                            document_manager.create_formated_text_block(
                                block_id=f"heading_suggestion_{i}",
                                text=title_text,
                                block_type="heading3",
                            )
                        )

                        suggestion_content = ""
                        if suggestion.get("reasoning"):
                            suggestion_content += f"ç†ç”±ï¼š{suggestion['reasoning']}\n\n"

                        if suggestion.get("specific_action"):
                            suggestion_content += (
                                f"å…·ä½“è¡ŒåŠ¨ï¼š{suggestion['specific_action']}\n\n"
                            )

                        if suggestion.get("execution_difficulty"):
                            suggestion_content += (
                                f"æ‰§è¡Œéš¾åº¦ï¼š{suggestion['execution_difficulty']}\n\n"
                            )

                        if suggestion.get("expected_outcome"):
                            suggestion_content += (
                                f"é¢„æœŸç»“æœï¼š{suggestion['expected_outcome']}\n\n"
                            )
                        if suggestion.get("minimum_action"):
                            suggestion_content += (
                                f"æœ€å°è¡ŒåŠ¨ï¼š{suggestion['minimum_action']}"
                            )

                        if suggestion_content:
                            children.append(f"text_suggestion_{i}")
                            descendants.append(
                                document_manager.create_text_block(
                                    block_id=f"text_suggestion_{i}",
                                    text=suggestion_content,
                                )
                            )

        # === é‡è¦æŠ¥å‘Š ===
        children.append("heading_important_report")
        descendants.append(
            document_manager.create_formated_text_block(
                block_id="heading_important_report",
                text="é‡è¦æŠ¥å‘Š",
                block_type="heading1",
            )
        )

        children.append("heading_important_report_interval")
        descendants.append(
            document_manager.create_formated_text_block(
                block_id="heading_important_report_interval",
                text="äº‹ä»¶é—´éš”",
                block_type="heading2",
            )
        )

        important_lines = []
        # ç­›é€‰æœ‰é—´éš”ä¸”display_unitä¸ä¸ºç©ºçš„è®°å½•
        valid_records = []
        for record in event_records:
            if (
                record.get("event_interval_minutes")
                and not pd.isna(record.get("event_interval_minutes"))
                and record.get("display_unit")
            ):
                valid_records.append(record)

        # æŒ‰é—´éš”ä»å°åˆ°å¤§æ’åº
        sorted_records = sorted(
            valid_records, key=lambda x: x.get("event_interval_minutes", float("inf"))
        )

        # å»é‡ï¼šåŸºäºdisplay_unitå’Œevent_interval_minutes
        seen = set()
        unique_records = []
        for record in sorted_records:
            key = (record["display_unit"], record["event_interval_minutes"])
            if key not in seen:
                seen.add(key)
                unique_records.append(record)

        # ç”Ÿæˆæ˜¾ç¤ºæ–‡æœ¬
        for record in unique_records:
            display_unit = record["display_unit"]
            minutes = int(round(float(record["event_interval_minutes"])))
            interval_label = format_time_label(minutes)
            important_lines.append(
                f"{display_unit}é—´éš”ï¼š{interval_label} | {minutes} åˆ†é’Ÿ"
            )

        children.append("text_important_overview")
        descendants.append(
            document_manager.create_text_block(
                block_id="text_important_overview", text="\n".join(important_lines)
            )
        )

        # === æ´»åŠ¨æ•°æ®åˆ†ç±»æ˜ç»† ===
        children.append("heading_category_details")
        descendants.append(
            document_manager.create_formated_text_block(
                block_id="heading_category_details",
                text="æ´»åŠ¨æ•°æ®åˆ†ç±»æ˜ç»†",
                block_type="heading1",
            )
        )

        # åˆ†ç±»æ’åºï¼šæœªè®°å½•æœ€åï¼Œå…¶ä»–æŒ‰æ€»æ—¶é•¿é™åº
        category_totals = {
            stat["category"]: stat["category_total_duration"] for stat in category_stats
        }
        sorted_categories = sorted(
            category_totals.keys(),
            key=lambda x: (1 if x == "æœªè®°å½•" else 0, -category_totals[x]),
        )

        # æŒ‰åˆ†ç±»åˆ†ç»„äº‹ä»¶è®°å½•
        category_events = defaultdict(lambda: defaultdict(list))
        for record in event_records:
            category_events[record["category"]][record["event_name"]].append(record)

        def format_duration_stats(record):
            """æ ¼å¼åŒ–æ—¶é•¿ç»Ÿè®¡ä¿¡æ¯"""
            count = int(record["count"])
            force_new_line = False
            if count <= 1:
                return "", force_new_line

            avg = int(round(record["avg_duration"]))
            min_dur = int(round(record["min_duration"]))
            max_dur = int(round(record["max_duration"]))

            if avg == min_dur == max_dur or (min_dur != 0 and max_dur / min_dur < 1.2):
                return f"å¹³å‡æ—¶é•¿ï¼š{format_time_label(avg, 'hour')}", force_new_line

            force_new_line = True

            final_str = f"å¹³å‡æ—¶é•¿ï¼š{format_time_label(avg, 'hour')}ï½œæœ€çŸ­ï¼š{format_time_label(min_dur, 'hour')}ï½œæœ€é•¿ï¼š{format_time_label(max_dur, 'hour')}"

            if max_dur > 30:
                max_start = str(record["max_duration_start_at"])[:16]
                week_day = day_label_map[
                    record["max_duration_start_at"].strftime("%a").lower()
                ]
                final_str += f"ï¼Œ{max_start} {week_day}"

            return final_str, force_new_line

        # ç”Ÿæˆå„åˆ†ç±»å†…å®¹
        for category in sorted_categories:
            # åˆ†ç±»æ ‡é¢˜
            children.extend([f"heading_cat_{category}", f"text_cat_{category}"])
            descendants.extend(
                [
                    document_manager.create_formated_text_block(
                        block_id=f"heading_cat_{category}",
                        text=f"ğŸ“œ {category if category else 'æ— åˆ†ç±»'}",
                        block_type="heading2",
                    ),
                    document_manager.create_text_block(
                        block_id=f"text_cat_{category}",
                        text=f"æ€»æ—¶é•¿ï¼š{format_time_label(category_totals[category], 'hour')}",
                    ),
                ]
            )

            # è¯¥åˆ†ç±»ä¸‹çš„äº‹ä»¶ï¼ŒæŒ‰äº‹ä»¶æ€»æ—¶é•¿æ’åº
            events = category_events[category]
            sorted_events = sorted(
                events.items(),
                key=lambda x: x[1][0].get("event_total_duration", 0),
                reverse=True,
            )

            for event_name, records in sorted_events:
                # äº‹ä»¶æ ‡é¢˜
                children.extend(
                    [
                        f"heading_ev_{category}_{event_name}",
                        f"text_ev_{category}_{event_name}",
                    ]
                )
                descendants.append(
                    document_manager.create_formated_text_block(
                        block_id=f"heading_ev_{category}_{event_name}",
                        text=event_name,
                        block_type="heading3",
                    )
                )

                # äº‹ä»¶åŸºæœ¬ä¿¡æ¯
                first_record = records[0]
                info_parts = [
                    f"æ€»æ—¶é•¿ï¼š{format_time_label(first_record['event_total_duration'], 'hour')}",
                    f"äº‹ä»¶æ¬¡æ•°ï¼š{int(first_record['event_total_count'])}",
                ]

                # æ·»åŠ åˆ†ç±»é—´éš”ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                if first_record.get("category_interval_minutes") and not pd.isna(
                    first_record.get("category_interval_minutes")
                ):
                    minutes = first_record["category_interval_minutes"]
                    interval_label = format_time_label(minutes)
                    info_parts.append(f"äº‹ä»¶é—´éš”ï¼š{interval_label}")

                # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæˆæ–¹å¼è®°å½•
                degree_records = [r for r in records if r.get("degree")]
                no_degree_records = [r for r in records if not r.get("degree")]

                final_str = " ï½œ ".join(info_parts)

                # å¦‚æœæ²¡æœ‰å®Œæˆæ–¹å¼è®°å½•ï¼Œåœ¨äº‹ä»¶çº§æ˜¾ç¤ºç»Ÿè®¡
                if not degree_records and no_degree_records:
                    extra_str, force_new_line = format_duration_stats(
                        no_degree_records[0]
                    )
                    if extra_str:
                        if force_new_line or len(info_parts) > 2:
                            final_str += "\n"
                        final_str += extra_str

                descendants.append(
                    document_manager.create_text_block(
                        block_id=f"text_ev_{category}_{event_name}", text=final_str
                    )
                )

                # å¤„ç†å®Œæˆæ–¹å¼è®°å½•
                if degree_records:
                    # åˆ›å»ºå®Œæˆæ–¹å¼å¼•ç”¨å®¹å™¨çš„childrenåˆ—è¡¨
                    degree_children = []

                    for record in sorted(
                        degree_records,
                        key=lambda x: x.get("total_duration", 0),
                        reverse=True,
                    ):
                        degree = record.get("degree", "æœªåˆ†çº§")
                        degree_children.extend(
                            [
                                f"heading_deg_{category}_{event_name}_{degree}",
                                f"text_deg_{category}_{event_name}_{degree}",
                            ]
                        )

                        descendants.append(
                            document_manager.create_formated_text_block(
                                block_id=f"heading_deg_{category}_{event_name}_{degree}",
                                text=degree,
                                block_type="heading4",
                            )
                        )

                        # å®Œæˆæ–¹å¼ç»Ÿè®¡ä¿¡æ¯
                        parts = [
                            f"æ€»æ—¶é•¿ï¼š{format_time_label(record['total_duration'], 'hour')}",
                            f"æ¬¡æ•°ï¼š{int(record['count'])}",
                        ]
                        if record.get("degree_interval_minutes") and not pd.isna(
                            record.get("degree_interval_minutes")
                        ):
                            interval_minutes = int(
                                round(float(record["degree_interval_minutes"]))
                            )
                            interval_label = format_time_label(interval_minutes)
                            parts.append(
                                f"é—´éš”æ—¶é—´ï¼š{interval_label} ({interval_minutes} åˆ†é’Ÿ)"
                            )

                        degree_str = " ï½œ ".join(parts)
                        extra_str, force_new_line = format_duration_stats(record)
                        if extra_str:
                            if force_new_line or len(parts) > 2:
                                degree_str += "\n"
                            degree_str += extra_str

                        descendants.append(
                            document_manager.create_text_block(
                                block_id=f"text_deg_{category}_{event_name}_{degree}",
                                text=degree_str,
                            )
                        )

                    # åˆ›å»ºå®Œæˆæ–¹å¼å¼•ç”¨å®¹å™¨
                    quote_block_id = f"quote_deg_{category}_{event_name}"
                    children.append(quote_block_id)
                    descendants.append(
                        document_manager.create_quote_block(
                            block_id=quote_block_id, children=degree_children
                        )
                    )

        # ç»„åˆé¡¶å±‚å†…å®¹
        content = document_manager.create_descendant_block_body(
            index=0, children=children, descendants=descendants
        )
        return content

    # endregion

    # region å›è°ƒå¤„ç†

    @require_service("notion", "æ ‡è®°æœåŠ¡æš‚æ—¶ä¸å¯ç”¨")
    @safe_execute("å¤„ç†Bç«™æ ‡è®°å·²è¯»å¤±è´¥")
    def mark_bili_read_v2(self, action_value: Dict[str, Any]) -> ProcessResult:
        """å¤„ç†Bç«™è§†é¢‘æ ‡è®°å·²è¯»çš„å›è°ƒ"""
        # è·å–notionæœåŠ¡
        notion_service = self.app_controller.get_service(ServiceNames.NOTION)

        # è·å–å‚æ•°
        pageid = action_value.get("pageid", "")
        video_index = action_value.get("video_index", 1)

        # æ‰§è¡Œæ ‡è®°ä¸ºå·²è¯»æ“ä½œ
        success = notion_service.mark_video_as_read(pageid)
        if not success:
            return ProcessResult.error_result("æ ‡è®°ä¸ºå·²è¯»å¤±è´¥")

        return ProcessResult.success_result(
            ResponseTypes.SCHEDULER_CARD_UPDATE_BILI_BUTTON,
            {
                "toast": {
                    "type": "success",
                    "content": f"å·²æ ‡è®°ç¬¬{video_index}ä¸ªæ¨èä¸ºå·²è¯»",
                },
                "remove_element_id": f"mark_bili_read_{video_index}",
                "text_element_id": f"bili_video_{video_index}",
            },
        )

    # endregion

    # region å†å²æ–¹æ³•ç¼“å­˜
    def generate_weekly_card_content(
        self, weekly_table_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ç”Ÿæˆå‘¨æŠ¥å‘Šå¡ç‰‡å†…å®¹"""
        elements = []
        elements.append(JsonBuilder.build_markdown_element("ä¸Šå‘¨æ—¶é—´è¡¨"))
        columns = []
        columns.append(
            JsonBuilder.build_table_column_element(
                name="time",
                display_name="æ—¶é—´",
                data_type="text",
                width="80px",
            )
        )
        day_dict = {
            "mon": "å‘¨ä¸€",
            "tue": "å‘¨äºŒ",
            "wed": "å‘¨ä¸‰",
            "thu": "å‘¨å››",
            "fri": "å‘¨äº”",
            "sat": "å‘¨å…­",
            "sun": "å‘¨æ—¥",
        }
        for day_key, day_name in day_dict.items():
            columns.append(
                JsonBuilder.build_table_column_element(
                    name=day_key,
                    display_name=day_name,
                    data_type="options",
                    width="120px",
                )
            )
        table_element = JsonBuilder.build_table_element(
            columns=columns,
            rows=[],
            freeze_first_column=True,
        )

        time_labels = weekly_table_data.get("time_labels", [])
        days_data = weekly_table_data.get("days", {})

        DEFAULT_SLOT_DATA = {
            "text": "ç©ºé—²",
            "color": ColorTypes.GREY,
            "category_label": "ç©ºé—²",
        }

        for time_label in time_labels:
            row = {"time": time_label}

            for day_key in day_dict.keys():
                day_data = days_data.get(day_key, {})
                slot_data = day_data.get(time_label, DEFAULT_SLOT_DATA)

                row[day_key] = [
                    {
                        "text": slot_data.get("text", DEFAULT_SLOT_DATA.get("text")),
                        "color": slot_data.get(
                            "color", DEFAULT_SLOT_DATA.get("color")
                        ).option_value,
                    }
                ]

            table_element["rows"].append(row)

        elements.append(table_element)

        return elements

    # endregion
