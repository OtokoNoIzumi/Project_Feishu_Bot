"""
æ—¥å¸¸äº‹é¡¹è®°å½•ä¸šåŠ¡

å¤„ç†æ—¥å¸¸äº‹é¡¹è®°å½•çš„å®Œæ•´ä¸šåŠ¡é€»è¾‘ï¼ŒåŒ…æ‹¬ï¼š
1. ç”¨æˆ·ç‹¬ç«‹æ–‡ä»¶å¤¹æ•°æ®å­˜å‚¨
2. äº‹é¡¹åˆ›å»ºå’Œè®°å½•ç®¡ç†
3. å‰ç½®æŒ‡ä»¤è¯†åˆ«å’Œå¤„ç†
4. æŸ¥è¯¢å’Œå±•ç¤ºåŠŸèƒ½
5. äº‹ä»¶å®šä¹‰ä¸è®°å½•åˆ†ç¦»çš„æ•°æ®æ¨¡å‹
"""

import os
import json
import copy
import math
from typing import Dict, Any, Optional, Tuple
from datetime import datetime, timedelta
from collections import OrderedDict


from Module.Common.scripts.common import debug_utils
from Module.Business.shared_process import (
    hex_to_hsl,
    safe_parse_number,
    hsl_to_hex,
)
from Module.Services.constants import (
    ServiceNames,
    RoutineTypes,
    RouteTypes,
    RoutineCheckCycle,
    RoutineProgressTypes,
    RoutineTargetTypes,
    RoutineRecordModes,
    ColorTypes,
)
from Module.Business.processors.base_processor import (
    BaseProcessor,
    ProcessResult,
    safe_execute,
)
from Module.Business.processors import RouteResult


# ä»ä¸€å¼€å§‹å°±ç”¨æŠ½è±¡å±‚
class EventStorage:
    def save_event(self, event_data):
        pass

    def load_events(self, user_data_path, user_id):
        pass

    def query_events(self, filter_func):
        pass


class JSONEventStorage(EventStorage):
    def save_event(self, event_data):
        # JSONå®ç°
        pass

    def load_events(self, user_data_path, user_id):
        # JSONå®ç°
        pass

    def query_events(self, filter_func):
        # JSONå®ç°
        pass


class RoutineRecord(BaseProcessor):
    """
    æ—¥å¸¸äº‹é¡¹è®°å½•ä¸šåŠ¡

    è´Ÿè´£å¤„ç†æ—¥å¸¸äº‹é¡¹è®°å½•çš„å®Œæ•´ä¸šåŠ¡æµç¨‹ï¼Œæ”¯æŒï¼š
    - äº‹ä»¶å®šä¹‰ä¸è®°å½•åˆ†ç¦»
    - å¤æ‚å±æ€§ç®¡ç†ï¼ˆåˆ†ç±»ã€ç¨‹åº¦ã€å…³è”ç­‰ï¼‰
    - é€‚é…å™¨æ— å…³çš„æ•°æ®æ¨¡å‹
    - ä½¿ç”¨æŠ½è±¡æ–¹æ³•å‡†å¤‡å¤šä¸ªæ•°æ®å‚¨å­˜é€»è¾‘çš„è¯ï¼Œæœ€å¥½ç”¨ä¸€ä¸ªset storageçš„æ¥å£ï¼Œåœ¨åˆå§‹åŒ–çš„å†…éƒ¨åšä¸€ä¸ªè®¾ç½®ï¼Ÿå¥½åƒä¹Ÿæ²¡å¿…è¦setï¼Œç›´æ¥èµ‹å€¼å°±è¡Œã€‚
    """

    def __init__(self, app_controller, developer_mode_path=None):
        """åˆå§‹åŒ–æ—¥å¸¸äº‹é¡¹è®°å½•ä¸šåŠ¡"""
        super().__init__(app_controller)
        self.developer_mode_path = developer_mode_path
        if not self.developer_mode_path:
            self.config_service = self.app_controller.get_service(ServiceNames.CONFIG)
            self.user_permission_service = self.app_controller.get_service(
                ServiceNames.USER_BUSINESS_PERMISSION
            )
        self.storage = JSONEventStorage()

    # region Routeå’Œå…¥å£

    @safe_execute("æ£€æµ‹å‰ç½®æŒ‡ä»¤å¤±è´¥")
    def detect_prefix_command(self, message_text: str) -> Optional[Tuple[str, str]]:
        """
        æ£€æµ‹æ¶ˆæ¯ä¸­çš„å‰ç½®æŒ‡ä»¤

        Args:
            message_text: ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯æ–‡æœ¬

        Returns:
            Optional[Tuple[str, str]]: (æŒ‡ä»¤ç±»å‹, äº‹é¡¹åç§°) æˆ– None
        """
        if not message_text:
            return None

        message_text = message_text.strip()

        # æ£€æµ‹åˆ›å»ºæŒ‡ä»¤
        if message_text.startswith("r "):
            event_name = message_text[2:].strip()
            if event_name:
                return ("create", event_name)

        if message_text.startswith("æ—¥ç¨‹ "):
            event_name = message_text[3:].strip()
            if event_name:
                return ("create", event_name)

        # æ£€æµ‹æŸ¥è¯¢æŒ‡ä»¤
        if message_text in ["rs", "æŸ¥çœ‹æ—¥ç¨‹"]:
            return ("query", "")

        return None

    @safe_execute("å¤„ç†æ¶ˆæ¯è·¯ç”±å¤±è´¥")
    def route_message(self, context, user_msg: str):
        """
        å¤„ç†routineç›¸å…³çš„æ¶ˆæ¯è·¯ç”±

        Args:
            context: æ¶ˆæ¯ä¸Šä¸‹æ–‡
            user_msg: ç”¨æˆ·æ¶ˆæ¯

        Returns:
            ProcessResult æˆ– None:
            - ProcessResult: å¯ç›´æ¥è¿”å›çš„å¤„ç†ç»“æœ
            - None: è¯¥æ¶ˆæ¯ä¸æ˜¯routineç›¸å…³
        """
        # 1. æ£€æŸ¥å‰ç½®æŒ‡ä»¤
        command_result = self.detect_prefix_command(user_msg)
        if command_result:
            command_type, item_name = command_result
            match command_type:
                case "create":
                    debug_utils.log_and_print(
                        f"ğŸ“ {context.user_name} è§¦å‘æ—¥ç¨‹åˆ›å»ºæŒ‡ä»¤ï¼š{item_name}",
                        log_level="INFO",
                    )
                    return self.process_routine_create(context.user_id, item_name)
                case "query":
                    debug_utils.log_and_print(
                        f"ğŸ“‹ {context.user_name} è§¦å‘æ—¥ç¨‹æŸ¥è¯¢æŒ‡ä»¤", log_level="INFO"
                    )
                    return self.process_routine_query(context.user_id)

        return None

    # endregion

    # region ç”¨æˆ·ç›¸å…³æ–¹æ³•
    def check_user_permission(self, user_id: str) -> bool:
        """
        æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰routine_recordæƒé™

        Args:
            user_id: ç”¨æˆ·ID

        Returns:
            bool: æ˜¯å¦æœ‰æƒé™
        """
        if self.developer_mode_path:
            return True

        if not self.user_permission_service:
            debug_utils.log_and_print("ç”¨æˆ·æƒé™æœåŠ¡ä¸å¯ç”¨", log_level="WARNING")
            return False

        return self.user_permission_service.check_business_permission(
            user_id, "routine_record"
        )

    def _get_user_data_path(self, user_id: str) -> str:
        """
        è·å–ç”¨æˆ·æ•°æ®å­˜å‚¨è·¯å¾„

        Args:
            user_id: ç”¨æˆ·ID

        Returns:
            str: ç”¨æˆ·æ•°æ®æ–‡ä»¶å¤¹è·¯å¾„
        """
        if self.developer_mode_path:
            return f"{self.developer_mode_path}/user_data/{user_id}"

        storage_path = self.config_service.get(
            "routine_record.storage_path", "user_data/"
        )

        # å¦‚æœä¸æ˜¯ç»å¯¹è·¯å¾„ï¼ŒåŸºäºé¡¹ç›®æ ¹è·¯å¾„è§£æ
        if not os.path.isabs(storage_path):
            project_root = self.config_service.project_root_path
            storage_path = os.path.join(project_root, storage_path)

        user_folder = os.path.join(storage_path, user_id)

        # ç¡®ä¿ç”¨æˆ·æ–‡ä»¶å¤¹å­˜åœ¨
        os.makedirs(user_folder, exist_ok=True)

        return user_folder

    def _get_event_definitions_file_path(self, user_id: str) -> str:
        """
        è·å–ç”¨æˆ·äº‹ä»¶å®šä¹‰æ–‡ä»¶è·¯å¾„

        Args:
            user_id: ç”¨æˆ·ID

        Returns:
            str: äº‹ä»¶å®šä¹‰æ–‡ä»¶è·¯å¾„
        """
        user_folder = self._get_user_data_path(user_id)
        return os.path.join(user_folder, "event_definitions.json")

    def _get_event_records_file_path(self, user_id: str) -> str:
        """
        è·å–ç”¨æˆ·äº‹ä»¶è®°å½•æ–‡ä»¶è·¯å¾„

        Args:
            user_id: ç”¨æˆ·ID

        Returns:
            str: äº‹ä»¶è®°å½•æ–‡ä»¶è·¯å¾„
        """
        user_folder = self._get_user_data_path(user_id)
        return os.path.join(user_folder, "event_records.json")

    # endregion

    # region å®šä¹‰å’Œæ•°æ®ç»“æ„
    def _create_event_definition(
        self, event_name: str, event_type: str = RoutineTypes.INSTANT.value
    ) -> Dict[str, Any]:
        """
        åˆ›å»ºäº‹ä»¶å®šä¹‰

        Args:
            event_name: äº‹ä»¶åç§°
            event_type: äº‹ä»¶ç±»å‹

        Returns:
            Dict[str, Any]: äº‹ä»¶å®šä¹‰
        """
        # å…¶å®è¿˜éœ€è¦å¥—ç”¨ä¸€äº›é»˜è®¤çš„ä¸åŒç±»å‹çš„å±æ€§ï¼Œç­‰åšåˆ°äº†å†è¯´
        current_time = self._get_formatted_time()
        return {
            "name": event_name,
            "type": event_type,
            "category": "",
            "description": "",
            "properties": {
                # å…³è”å±æ€§
                "related_start_event": None,
                "related_events": [],
                # æ˜¾ç¤ºå±æ€§
                "include_in_daily_check": False,
                # å¿«æ·è®¿é—®å±æ€§
                "quick_access": False,
                # ç¨‹åº¦/å±‚æ¬¡å±æ€§
                "degree_options": [],
                "default_degree": "",
                # æ—¶é—´å±æ€§
                "future_date": None,
                # ç›®æ ‡å±æ€§
                "check_cycle": None,
                "custom_cycle_config": None,
                "target_type": RoutineTargetTypes.NONE.value,  # æ¬¡æ•°/æ—¶é•¿
                "target_value": None,  # ç›®æ ‡å€¼
                # æŒ‡æ ‡å±æ€§
                "progress_type": RoutineProgressTypes.NONE.value,  # è¿›åº¦ç±»å‹
            },
            "stats": {
                "record_count": 0,
                "cycle_count": 0,
                "last_cycle_count": 0,
                "duration": {
                    "recent_values": [],  # æœ€è¿‘Næ¬¡çš„è€—æ—¶å€¼
                    "window_size": 10,  # æ»‘åŠ¨çª—å£å¤§å°
                    "duration_count": 0,  # æœ‰è€—æ—¶è®°å½•çš„æ¬¡æ•°
                    "avg_all_time": 0,  # å†å²å¹³å‡è€—æ—¶
                },
                "last_refresh_date": None,
                "last_record_id": None,
            },
            "created_time": current_time,
            "last_record_time": None,
            "last_updated": current_time,
        }

    def _create_event_record(
        self,
        event_name: str,
        user_id: str,
        record_mode: str,
    ) -> Dict[str, Any]:
        """
        åˆ›å»ºäº‹ä»¶è®°å½•

        Args:
            event_name: äº‹ä»¶åç§°
            user_id: ç”¨æˆ·ID
            record_mode: è®°å½•æ¨¡å¼
        Returns:
            Dict[str, Any]: äº‹ä»¶è®°å½•
        """
        current_time = self._get_formatted_time()
        match record_mode:
            case RoutineRecordModes.ADD | RoutineRecordModes.QUERY:
                record_id = ""
            case RoutineRecordModes.RECORD:
                record_id = self._get_next_record_id(user_id, event_name)

        return {
            "record_id": record_id,
            "event_name": event_name,
            "create_time": current_time,
        }

    @safe_execute("è¯»å–äº‹ä»¶å®šä¹‰æ–‡ä»¶å¤±è´¥")
    def load_event_definitions(self, user_id: str) -> Dict[str, Any]:
        """
        åŠ è½½ç”¨æˆ·çš„äº‹ä»¶å®šä¹‰

        Args:
            user_id: ç”¨æˆ·ID

        Returns:
            Dict[str, Any]: äº‹ä»¶å®šä¹‰æ•°æ®
        """
        file_path = self._get_event_definitions_file_path(user_id)

        if not os.path.exists(file_path):
            # åˆ›å»ºç©ºæ•°æ®ç»“æ„
            current_time = self._get_formatted_time()
            default_data = {
                "user_id": user_id,
                "definitions": {},
                "categories": [],
                "created_time": current_time,
                "last_updated": current_time,
            }
            self.save_event_definitions(user_id, default_data)
            return default_data

        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)
            return data

    @safe_execute("åŠ è½½äº‹ä»¶è®°å½•å¤±è´¥")
    def load_event_records(self, user_id: str) -> Dict[str, Any]:
        """
        åŠ è½½ç”¨æˆ·çš„äº‹ä»¶è®°å½•

        Args:
            user_id: ç”¨æˆ·ID

        Returns:
            Dict[str, Any]: äº‹ä»¶è®°å½•æ•°æ®
        """
        file_path = self._get_event_records_file_path(user_id)

        if not os.path.exists(file_path):
            # åˆ›å»ºç©ºè®°å½•ç»“æ„
            current_time = self._get_formatted_time()
            default_data = {
                "user_id": user_id,
                "active_records": OrderedDict(),
                "records": OrderedDict(),
                "created_time": current_time,
                "last_updated": current_time,
            }
            self.save_event_records(user_id, default_data)
            return default_data

        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)
            return data

    @safe_execute("ä¿å­˜äº‹ä»¶å®šä¹‰å¤±è´¥")
    def save_event_definitions(self, user_id: str, data: Dict[str, Any]) -> bool:
        """
        ä¿å­˜ç”¨æˆ·çš„äº‹ä»¶å®šä¹‰

        Args:
            user_id: ç”¨æˆ·ID
            data: è¦ä¿å­˜çš„æ•°æ®

        Returns:
            bool: ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        file_path = self._get_event_definitions_file_path(user_id)

        # æ›´æ–°æœ€åä¿®æ”¹æ—¶é—´
        if "last_updated" not in data:
            data["last_updated"] = self._get_formatted_time()

        try:
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            debug_utils.log_and_print(f"ä¿å­˜äº‹ä»¶å®šä¹‰æ–‡ä»¶å¤±è´¥: {e}", log_level="ERROR")
            return False

    @safe_execute("ä¿å­˜äº‹ä»¶è®°å½•å¤±è´¥")
    def save_event_records(self, user_id: str, data: Dict[str, Any]) -> bool:
        """
        ä¿å­˜ç”¨æˆ·çš„äº‹ä»¶è®°å½•

        Args:
            user_id: ç”¨æˆ·ID
            data: è¦ä¿å­˜çš„æ•°æ®

        Returns:
            bool: ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        file_path = self._get_event_records_file_path(user_id)

        # æ›´æ–°æœ€åä¿®æ”¹æ—¶é—´
        if "last_updated" not in data:
            data["last_updated"] = self._get_formatted_time()

        try:
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            debug_utils.log_and_print(f"ä¿å­˜äº‹ä»¶è®°å½•æ–‡ä»¶å¤±è´¥: {e}", log_level="ERROR")
            return False

    # endregion

    # region record_idç›¸å…³

    def _get_next_record_id(self, user_id: str, event_name: str) -> str:
        """
        ç”Ÿæˆä¸‹ä¸€ä¸ªè®°å½•IDï¼ŒåŸºäºäº‹ä»¶å®šä¹‰ä¸­çš„record_countç»Ÿè®¡
        é«˜æ•ˆä¸”å¯é çš„IDç”Ÿæˆæ–¹æ³•

        Args:
            user_id: ç”¨æˆ·ID
            event_name: äº‹ä»¶åç§°

        Returns:
            str: è®°å½•IDï¼Œæ ¼å¼ä¸º event_name_00001
        """
        # ä¼˜å…ˆä½¿ç”¨äº‹ä»¶å®šä¹‰ä¸­çš„ç»Ÿè®¡ä¿¡æ¯
        definitions_data = self.load_event_definitions(user_id)
        definitions = definitions_data.get("definitions", {})

        if event_name in definitions:
            # äº‹ä»¶å®šä¹‰å­˜åœ¨ï¼Œä½¿ç”¨record_countç”ŸæˆID
            current_count = (
                definitions[event_name].get("stats", {}).get("record_count", 0)
            )
            next_num = current_count + 1
            candidate_id = f"{event_name}_{next_num:05d}"

            # éªŒè¯IDå”¯ä¸€æ€§ï¼ˆé˜²å¾¡æ€§ç¼–ç¨‹ï¼‰
            if self._verify_id_uniqueness(user_id, candidate_id):
                return candidate_id

                # å¦‚æœç»Ÿè®¡ä¸å‡†ç¡®ï¼Œå›é€€åˆ°æ‰«ææ–¹å¼å¹¶ä¿®å¤ç»Ÿè®¡
                return self._generate_id_with_scan_and_fix(user_id, event_name)

            # äº‹ä»¶å®šä¹‰ä¸å­˜åœ¨ï¼Œæ‰«æç°æœ‰è®°å½•ç”ŸæˆID
            return self._generate_id_with_scan(user_id, event_name)

    def _verify_id_uniqueness(self, user_id: str, candidate_id: str) -> bool:
        """
        éªŒè¯IDåœ¨æ‰€æœ‰è®°å½•ä¸­çš„å”¯ä¸€æ€§

        Args:
            user_id: ç”¨æˆ·ID
            candidate_id: å€™é€‰ID

        Returns:
            bool: IDæ˜¯å¦å”¯ä¸€
        """
        records_data = self.load_event_records(user_id)

        # æ£€æŸ¥recordsä¸­æ˜¯å¦å­˜åœ¨
        if candidate_id in records_data.get("records", {}):
            return False

        # æ£€æŸ¥active_recordsä¸­æ˜¯å¦å­˜åœ¨
        if candidate_id in records_data.get("active_records", {}):
            return False

        return True

    def _generate_id_with_scan(self, user_id: str, event_name: str) -> str:
        """
        é€šè¿‡æ‰«æç°æœ‰è®°å½•ç”ŸæˆIDï¼ˆç”¨äºäº‹ä»¶å®šä¹‰ä¸å­˜åœ¨çš„æƒ…å†µï¼‰

        Args:
            user_id: ç”¨æˆ·ID
            event_name: äº‹ä»¶åç§°

        Returns:
            str: è®°å½•ID
        """
        records_data = self.load_event_records(user_id)
        existing_ids = set()

        # æ”¶é›†åŒåäº‹ä»¶çš„æ‰€æœ‰ID
        for record_dict in [
            records_data.get("records", {}),
            records_data.get("active_records", {}),
        ]:
            for record_id, record in record_dict.items():
                if record.get("event_name") == event_name:
                    existing_ids.add(record_id)

        # æ‰¾åˆ°ä¸‹ä¸€ä¸ªå¯ç”¨åºå·
        next_num = 1
        while True:
            candidate_id = f"{event_name}_{next_num:05d}"
            if candidate_id not in existing_ids:
                return candidate_id
            next_num += 1

            if next_num > 99999:
                raise ValueError(f"æ— æ³•ä¸ºäº‹ä»¶ '{event_name}' ç”Ÿæˆå”¯ä¸€ID")

    def _generate_id_with_scan_and_fix(self, user_id: str, event_name: str) -> str:
        """
        æ‰«æç”ŸæˆIDå¹¶ä¿®å¤äº‹ä»¶å®šä¹‰ä¸­çš„ç»Ÿè®¡ä¿¡æ¯

        Args:
            user_id: ç”¨æˆ·ID
            event_name: äº‹ä»¶åç§°

        Returns:
            str: è®°å½•ID
        """
        # å…ˆç”¨æ‰«ææ–¹å¼ç”ŸæˆID
        new_id = self._generate_id_with_scan(user_id, event_name)

        # ä¿®å¤äº‹ä»¶å®šä¹‰ä¸­çš„record_count
        definitions_data = self.load_event_definitions(user_id)
        if event_name in definitions_data.get("definitions", {}):
            # è®¡ç®—å®é™…è®°å½•æ•°é‡
            actual_count = self._count_records_for_event(user_id, event_name)
            definitions_data["definitions"][event_name]["stats"][
                "record_count"
            ] = actual_count
            self.save_event_definitions(user_id, definitions_data)

        return new_id

    def _count_records_for_event(self, user_id: str, event_name: str) -> int:
        """
        ç»Ÿè®¡æŒ‡å®šäº‹ä»¶çš„å®é™…è®°å½•æ•°é‡

        Args:
            user_id: ç”¨æˆ·ID
            event_name: äº‹ä»¶åç§°

        Returns:
            int: è®°å½•æ•°é‡
        """
        records_data = self.load_event_records(user_id)
        count = 0

        # ç»Ÿè®¡recordsä¸­çš„è®°å½•
        for record in records_data.get("records", {}).values():
            if record.get("event_name") == event_name:
                count += 1

        # ç»Ÿè®¡active_recordsä¸­çš„è®°å½•
        for record in records_data.get("active_records", {}).values():
            if record.get("event_name") == event_name:
                count += 1

        return count

    # endregion

    # region äº‹é¡¹åˆ›å»ºæˆ–è®°å½•

    @safe_execute("å¤„ç†äº‹é¡¹åˆ›å»ºå¤±è´¥")
    def process_routine_create(self, user_id: str, item_name: str):
        """
        å¤„ç†äº‹é¡¹åˆ›å»ºæˆ–è®°å½•

        Args:
            user_id: ç”¨æˆ·ID
            item_name: äº‹é¡¹åç§°

        Returns:
            RouteResult: è·¯ç”±ç»“æœï¼ŒæŒ‡å‘å¯¹åº”çš„å¡ç‰‡
        """
        # æ£€æŸ¥æƒé™
        # ä¸‰æ˜æ²»ç»“æ„ï¼šæƒé™-æ ¸å¿ƒæ•°æ®-è·¯ç”±
        if not self.check_user_permission(user_id):
            return ProcessResult.error_result("æ‚¨æš‚æ— ä½¿ç”¨æ—¥å¸¸äº‹é¡¹è®°å½•åŠŸèƒ½çš„æƒé™")

        routine_business_data = self.build_record_business_data(user_id, item_name)

        route_result = RouteResult.create_route_result(
            route_type=RouteTypes.ROUTINE_RECORD_CARD,
            route_params={
                "business_data": routine_business_data,
            },
        )
        return route_result

    @safe_execute("æ„å»ºæ—¥ç¨‹è®°å½•å¡ç‰‡æ•°æ®å¤±è´¥")
    def build_record_business_data(
        self,
        user_id: str,
        event_name: str,
        record_mode: str = "",
        current_record_data: Dict[str, Any] = None,
    ) -> Dict[str, Any]:
        """
        æ„å»ºæ—¥ç¨‹è®°å½•å¡ç‰‡æ•°æ®
        ä¸åšæƒé™æ ¡éªŒï¼Œå°±æ˜¯ç”Ÿäº§æ•°æ®
        """
        definitions_data = self.load_event_definitions(user_id)
        event_definition = definitions_data["definitions"].get(event_name, {})

        # query/record/add
        record_mode = record_mode or (
            RoutineRecordModes.RECORD if event_definition else RoutineRecordModes.ADD
        )

        # åŸºç¡€æ•°æ®
        business_data = {
            "record_mode": record_mode,
            "user_id": user_id,
            "event_name": event_name,
        }

        if record_mode == RoutineRecordModes.QUERY and current_record_data:
            # å› ä¸ºæ•°æ®ç¼“å­˜å’Œæ“ä½œçš„é—´éš”ï¼Œéœ€è¦æ·±æ‹·è´ï¼Œé˜²æ­¢æ“ä½œæ—¶æ±¡æŸ“æ•°æ®
            new_record_data = copy.deepcopy(current_record_data)
            last_record_time = new_record_data.get("create_time", None)
        else:
            new_record_data = self._create_event_record(
                event_name, user_id, record_mode
            )
            last_record_time = event_definition.get("last_record_time", None)

        # å…¬å…±çš„è®¡ç®—å¯ä»¥æ”¾åœ¨å¤–é¢
        computed_data = {}
        # è®¡ç®—æ—¶é—´å·®
        if last_record_time:
            last_time = datetime.strptime(last_record_time, "%Y-%m-%d %H:%M")
            diff_minutes = round((datetime.now() - last_time).total_seconds() / 60, 1)
            computed_data["diff_minutes"] = diff_minutes

        match record_mode:
            case RoutineRecordModes.ADD:
                event_definition["type"] = RoutineTypes.INSTANT.value

            case RoutineRecordModes.RECORD | RoutineRecordModes.QUERY:
                last_record_id = event_definition.get("stats", {}).get(
                    "last_record_id", ""
                )
                if last_record_id:
                    event_records = self.load_event_records(user_id)
                    last_record_data = event_records.get("records", {}).get(
                        last_record_id
                    )
                    if not last_record_data:
                        last_record_data = event_records.get("active_records", {}).get(
                            last_record_id, {}
                        )
                    business_data["last_record_data"] = last_record_data

                avg_duration = self._calculate_average_duration(user_id, event_name)
                if avg_duration > 0:
                    computed_data["avg_duration"] = avg_duration

                target_type = event_definition.get("properties", {}).get(
                    "target_type", ""
                )

                match target_type:
                    case RoutineTargetTypes.COUNT.value:
                        target_progress_value = event_definition.get("stats", {}).get(
                            "record_count", 0
                        )
                    case RoutineTargetTypes.TIME.value:
                        target_progress_value = self._calculate_total_duration(
                            user_id, event_name
                        )
                    case _:
                        target_progress_value = 0
                computed_data["total_target_progress_value"] = target_progress_value

                # è®¡ç®—å‘¨æœŸä¿¡æ¯
                check_cycle = event_definition.get("properties", {}).get(
                    "check_cycle", None
                )

                if check_cycle:
                    cycle_count = event_definition.get("stats", {}).get(
                        "cycle_count", 0
                    )
                    last_refresh_date = event_definition.get("stats", {}).get(
                        "last_refresh_date", None
                    )

                    # ç»Ÿä¸€åˆ†æå‘¨æœŸçŠ¶æ€
                    cycle_status = self._analyze_cycle_status(
                        last_refresh_date, check_cycle
                    )
                    if cycle_status["need_refresh"]:
                        last_cycle_count = cycle_count
                        last_refresh_date = self._get_formatted_time()
                        cycle_count = 0
                    else:
                        last_cycle_count = event_definition.get("stats", {}).get(
                            "last_cycle_count", 0
                        )

                    cycle_info = {
                        "cycle_count": cycle_count,
                        "last_cycle_count": last_cycle_count,
                        "last_cycle_description": cycle_status["description"],
                        "last_refresh_date": last_refresh_date,
                    }
                    computed_data["cycle_info"] = cycle_info

        # æ„å»ºåˆ†ç±»é€‰é¡¹
        categories_data = definitions_data.get("categories", [])
        category_names = set()

        # ä»åˆ†ç±»æ•°æ®ä¸­æ”¶é›†åˆ†ç±»åç§°
        for category_obj in categories_data:
            category_name = category_obj.get("name", "")
            if category_name:
                category_names.add(category_name)

        # ä»æ‰€æœ‰äº‹ä»¶å®šä¹‰ä¸­æ”¶é›†åˆ†ç±»
        for _, definition in definitions_data.get("definitions", {}).items():
            category = definition.get("category")
            if category:
                category_names.add(category)

        # è¿”å›åˆ†ç±»åç§°åˆ—è¡¨ï¼ˆç”¨äºå‰ç«¯æ„å»ºé€‰é¡¹ï¼‰
        category_options = sorted(c for c in category_names if c)

        business_data["event_definition"] = event_definition
        business_data["record_data"] = new_record_data
        business_data["computed_data"] = computed_data
        business_data["category_options"] = category_options
        business_data["categories"] = definitions_data.get(
            "categories", []
        )  # ä¼ é€’å®Œæ•´çš„åˆ†ç±»æ•°æ®

        return business_data

    def _calculate_average_duration(self, user_id: str, event_name: str) -> float:
        """
        è®¡ç®—äº‹é¡¹çš„å¹³å‡è€—æ—¶
        """
        definitions_data = self.load_event_definitions(user_id)
        event_definition = definitions_data.get("definitions", {}).get(event_name, {})
        return self._calculate_avg_duration(event_definition)

    def _calculate_total_duration(self, user_id: str, event_name: str) -> float:
        """
        è®¡ç®—äº‹é¡¹çš„å¹³å‡è€—æ—¶
        """
        definitions_data = self.load_event_definitions(user_id)
        event_duration_info = (
            definitions_data.get("definitions", {})
            .get(event_name, {})
            .get("stats", {})
            .get("duration", {})
        )
        duration_count = event_duration_info.get("duration_count", 0)
        avg_duration = event_duration_info.get("avg_all_time", 0)
        return round(avg_duration * duration_count, 1)

    @safe_execute("åˆ›å»ºç›´æ¥è®°å½•å¤±è´¥")
    def create_direct_record(
        self, user_id: str, dup_business_data: Dict[str, Any]
    ) -> Tuple[bool, str]:
        """
        åˆ›å»ºå¹¶ä¿å­˜è®°å½•åˆ° event_records.json
        å¯¹äºé future ç±»å‹çš„äº‹é¡¹ï¼ŒåŒæ—¶åˆ›å»ºäº‹ä»¶å®šä¹‰

        Args:
            user_id: ç”¨æˆ·ID
            record_data: è¡¨å•æ•°æ®

        Returns:
            Tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, æ¶ˆæ¯)
        """
        # éªŒè¯æ•°æ®
        record_data = dup_business_data.get("record_data", {})
        event_definition = dup_business_data.get("event_definition", {})
        record_mode = dup_business_data.get("record_mode", "")
        source_record_id = dup_business_data.get("source_record_id", "")

        # ç”Ÿæˆè®°å½•ID
        event_name = record_data.get("event_name", "").strip()

        # æ„å»ºè®°å½•æ•°æ®
        current_time = self._get_formatted_time()
        event_type = event_definition.get("type", RoutineTypes.FUTURE.value)

        # æ„å»ºè®°å½•æ•°æ®ï¼Œè¿‡æ»¤ç©ºå€¼å’Œå†—ä½™å­—æ®µ
        new_record = {}

        # å¤åˆ¶æœ‰æ•ˆçš„è¡¨å•æ•°æ®ï¼ˆè¿‡æ»¤ç©ºå€¼ï¼‰
        for key, value in record_data.items():
            if value is not None and value != "":
                new_record[key] = value

        # æ·»åŠ ç³»ç»Ÿå­—æ®µ
        if "record_id" not in new_record:
            record_id = self._get_next_record_id(user_id, event_name)
            new_record["record_id"] = record_id
        else:
            record_id = new_record.get("record_id", "")

        if (event_type == RoutineTypes.INSTANT.value) or (
            record_mode == RoutineRecordModes.QUERY
        ):
            new_record["end_time"] = current_time

        # é’ˆå¯¹ä¸åŒäº‹ä»¶ç±»å‹çš„ç‰¹æ®Šå¤„ç†
        if event_type == RoutineTypes.FUTURE.value:
            # æœªæ¥äº‹é¡¹ï¼šç§»é™¤durationï¼Œä½¿ç”¨estimated_duration
            if "duration" in new_record:
                duration_value = new_record.pop("duration")  # ç§»é™¤duration
                if duration_value:  # åªæœ‰éç©ºå€¼æ‰è®¾ç½®
                    new_record["estimated_duration"] = duration_value
            # æœªæ¥äº‹é¡¹ä¸éœ€è¦has_definitionå­—æ®µ

        # åŠ è½½è®°å½•æ•°æ®
        records_data = self.load_event_records(user_id)
        source_record_data = {}
        if source_record_id:
            source_record_data = records_data.get("active_records", {}).get(
                source_record_id, {}
            ) or records_data.get("records", {}).get(source_record_id, {})
            if source_record_data:
                source_record_data.setdefault("related_records", {})
                source_record_data["related_records"].setdefault(event_name, [])
                if record_id not in source_record_data["related_records"][event_name]:
                    source_record_data["related_records"][event_name].append(record_id)
                source_record_data["last_updated"] = current_time

        # å¯¹äºé future ç±»å‹çš„äº‹é¡¹ï¼Œåˆ›å»ºäº‹ä»¶å®šä¹‰
        if event_type != RoutineTypes.FUTURE.value:
            self._update_event_definition(
                user_id,
                event_name,
                dup_business_data,
                record_id,
                record_mode,
                source_record_data.get("event_name", ""),
            )

        # ç‰¹æ®Šå¤„ç† QUERY æ¨¡å¼ï¼šç¼–è¾‘å·²æœ‰çš„ active_record
        if record_mode == RoutineRecordModes.QUERY:
            # ä» active_records ä¸­ç§»é™¤åŸè®°å½•
            if record_id in records_data.get("active_records", {}):
                del records_data["active_records"][record_id]

            # å°†æ›´æ–°åçš„è®°å½•æ·»åŠ åˆ° records çš„æœ€å‰é¢
            new_records = OrderedDict()
            new_records[record_id] = new_record
            new_records.update(records_data.get("records", {}))
            records_data["records"] = new_records

            records_data["last_updated"] = current_time

            # ä¿å­˜æ•°æ®
            if self.save_event_records(user_id, records_data):
                return True, "æˆåŠŸå®Œæˆè®°å½•"

            return False, "ä¿å­˜è®°å½•å¤±è´¥"

        # å¸¸è§„å¤„ç†ï¼šæ ¹æ®äº‹ä»¶ç±»å‹å†³å®šå­˜å‚¨ä½ç½®
        if event_type in [
            RoutineTypes.START.value,
            RoutineTypes.ONGOING.value,
            RoutineTypes.FUTURE.value,
        ]:
            # å¼€å§‹ã€æŒç»­ã€æœªæ¥äº‹é¡¹å­˜å‚¨åˆ° active_records
            new_record_field = "active_records"
        else:
            # å…¶ä»–ç±»å‹è®°å½•æ·»åŠ åˆ°records
            new_record_field = "records"

        new_records = OrderedDict()
        new_records[record_id] = new_record
        new_records.update(records_data[new_record_field])
        records_data[new_record_field] = new_records

        records_data["last_updated"] = current_time

        # ä¿å­˜æ•°æ®
        if self.save_event_records(user_id, records_data):
            return True, "æˆåŠŸåˆ›å»ºè®°å½•"

        return False, "ä¿å­˜è®°å½•å¤±è´¥"

    # endregion

    # region èœå•å¡ç‰‡ç›¸å…³
    @safe_execute("å¤„ç†å¿«é€Ÿè®°å½•èœå•è·¯ç”±å¤±è´¥")
    def quick_record_menu_route_choice(self, user_id: str):
        """
        å¤„ç†å¿«é€Ÿè®°å½•èœå•è·¯ç”±é€‰æ‹©

        Args:
            user_id: ç”¨æˆ·ID

        Returns:
            RouteResult: è·¯ç”±ç»“æœï¼ŒæŒ‡å‘å¿«é€Ÿé€‰æ‹©è®°å½•å¡ç‰‡
        """
        # æ£€æŸ¥æƒé™
        if not self.check_user_permission(user_id):
            return ProcessResult.error_result("æ‚¨æš‚æ— ä½¿ç”¨æ—¥å¸¸äº‹é¡¹è®°å½•åŠŸèƒ½çš„æƒé™")

        # æ„å»ºå¡ç‰‡æ•°æ®ï¼Œæ”¯æŒé›†æˆæ¨¡å¼
        menu_shortcut_data = self.build_quick_select_card_data(
            user_id=user_id,
        )

        # æ„å»ºè·¯ç”±ç»“æœï¼ŒæŒ‡å‘routineå¡ç‰‡çš„å¿«é€Ÿé€‰æ‹©æ¨¡å¼
        route_result = RouteResult.create_route_result(
            route_type=RouteTypes.ROUTINE_QUICK_SELECT_CARD,
            route_params={"business_data": menu_shortcut_data},
        )

        return route_result

    @safe_execute("æ„å»ºå¿«é€Ÿé€‰æ‹©è®°å½•å¡ç‰‡æ•°æ®å¤±è´¥")
    def build_quick_select_card_data(
        self, user_id: str, max_items: int = 6
    ) -> Dict[str, Any]:
        """
        æ„å»ºå¿«é€Ÿé€‰æ‹©è®°å½•å¡ç‰‡æ•°æ®ï¼ˆæ‰©å±•ç‰ˆæœ¬ï¼šæ”¯æŒé›†æˆæ¨¡å¼ï¼‰

        Args:
            user_id: ç”¨æˆ·ID
            max_items: æœ€å¤§æ˜¾ç¤ºäº‹ä»¶æ•°é‡

        Returns:
            Dict[str, Any]: å¡ç‰‡æ•°æ®
        """
        # ä¸šåŠ¡æ•°æ®æœªå¿…éƒ½éœ€è¦åœ¨è¿™é‡Œå®šä¹‰ï¼Œæ˜¯å¦è¿ç»­æ›´æ–°æ˜¯å‰ç«¯çš„äº‹ï¼Œå–å€¼æˆ–è€…è®¾å®šå€¼ï¼Œè¿™é‡Œæ˜¯ä¸šåŠ¡é€»è¾‘çš„æ•°æ®ã€‚
        definitions_data = self.load_event_definitions(user_id)
        quick_events = []
        definitions = definitions_data.get("definitions", {})

        if definitions:
            # åˆ†ç¦»å¿«é€Ÿè®¿é—®äº‹ä»¶å’Œæœ€è¿‘äº‹ä»¶
            quick_access_events = []
            recent_events = []

            for event_name, event_def in definitions.items():
                event_info = {
                    "name": event_name,
                    "type": event_def.get("type", RoutineTypes.INSTANT.value),
                    "properties": event_def.get("properties", {}),
                    "last_updated": event_def.get("last_updated", ""),
                    "definition": event_def,  # ä¿ç•™å®Œæ•´å®šä¹‰ï¼Œç”¨äºå¿«é€Ÿè®°å½•
                }

                if event_def.get("properties", {}).get("quick_access", False):
                    quick_access_events.append(event_info)
                else:
                    recent_events.append(event_info)

            # æ’åºå¹¶åˆå¹¶äº‹ä»¶åˆ—è¡¨
            quick_access_events.sort(key=lambda x: x["last_updated"], reverse=True)
            recent_events.sort(key=lambda x: x["last_updated"], reverse=True)

            # ç¡®ä¿å¿«é€Ÿè®¿é—®äº‹ä»¶ä¼˜å…ˆæ˜¾ç¤º
            result = quick_access_events[:3]
            remaining_slots = max_items - len(result)
            if remaining_slots > 0:
                result.extend(recent_events[:remaining_slots])
            quick_events = result

        # åŠ è½½active_recordsæ•°æ®
        records_data = self.load_event_records(user_id)
        active_records = records_data.get("active_records", {})

        # æ„å»ºåŸºç¡€å¡ç‰‡æ•°æ®
        quick_select_data = {
            "user_id": user_id,
            "quick_events": quick_events,
            "active_records": active_records,
        }

        return quick_select_data

    # endregion

    # region æŸ¥è¯¢ç›¸å…³
    # å› ä¸ºè¦æ”¯æŒå‰ç«¯è¿‡æ»¤ï¼Œæ‰€ä»¥æ•°æ®æå–åˆ°ç¼“å­˜é‡Œä¼šæ¯”è¾ƒå¥½ï¼Ÿ
    @safe_execute("å¤„ç†æŸ¥è¯¢è¯·æ±‚å¤±è´¥")
    def process_routine_query(self, user_id: str):
        """
        å¤„ç†äº‹é¡¹æŸ¥è¯¢

        Args:
            user_id: ç”¨æˆ·ID

        Returns:
            RouteResult: è·¯ç”±ç»“æœï¼ŒæŒ‡å‘æŸ¥è¯¢ç»“æœå¡ç‰‡
        """
        # æ£€æŸ¥æƒé™
        if not self.check_user_permission(user_id):
            return ProcessResult.error_result("æ‚¨æš‚æ— ä½¿ç”¨æ—¥å¸¸äº‹é¡¹è®°å½•åŠŸèƒ½çš„æƒé™")

        query_business_data = self.build_query_business_data(user_id)

        # æ„å»ºè·¯ç”±ç»“æœï¼ŒæŒ‡å‘æŸ¥è¯¢ç»“æœå¡ç‰‡
        route_result = RouteResult.create_route_result(
            route_type=RouteTypes.ROUTINE_QUERY_RESULTS_CARD,
            route_params={"business_data": query_business_data},
        )

        return route_result

    def build_query_business_data(self, user_id: str) -> Dict[str, Any]:
        """
        æ„å»ºæŸ¥è¯¢æ•°æ®
        """
        # å‰ç«¯ä¸åº”è¯¥ç»„è£…ï¼Œæ‰€ä»¥è¿™é‡Œè¦ç»„è£…ï¼Œå¯¹äºactive_recordsï¼Œä¸€ä¸ªeventå¯èƒ½å¯ä»¥æœ‰å¤šä¸ªï¼Œé‚£å°±è¦ä¿ç•™å¤šä¸ªåšå¤‡é€‰
        event_data = self.load_event_definitions(user_id)
        records_data = self.load_event_records(user_id)
        active_records = records_data.get("active_records", {})

        # æ”¶é›†active_recordsä¸­çš„äº‹ä»¶åç§°å’Œåˆ†ç±»
        active_event_names = set()
        categories_data = event_data.get("categories", [])
        category_names = set()

        # ä»åˆ†ç±»æ•°æ®ä¸­æ”¶é›†åˆ†ç±»åç§°
        for category_obj in categories_data:
            category_name = category_obj.get("name", "")
            if category_name:
                category_names.add(category_name)

        # ä¸€æ¬¡éå†active_recordsï¼ŒæŒ‰ç±»å‹åˆ†ç»„ï¼ŒåŒæ—¶æ”¶é›†åˆ†ç±»
        today = datetime.now().strftime("%Y-%m-%d")
        start_events = []
        future_today = []
        future_other = []
        ongoing_events = []

        for record_id, record in active_records.items():
            event_name = record.get("event_name", "")
            active_event_names.add(event_name)
            event_def = event_data.get("definitions", {}).get(event_name, {})
            event_type = event_def.get("type", RoutineTypes.FUTURE.value)
            category = event_def.get("category", "æœªåˆ†ç±»")
            category_names.add(category)

            record_element = {
                "record_type": "active_record",
                "record_id": record_id,
                "event_name": event_name,
                "event_type": event_type,
                "category": category,
                "data": record,
                "related_events": event_def.get("properties", {}).get(
                    "related_events", []
                ),
            }

            match event_type:
                case RoutineTypes.START.value:
                    start_events.append(record_element)
                case RoutineTypes.FUTURE.value:
                    scheduled_date = record.get("scheduled_start_time", "")[
                        :10
                    ]  # "2025-07-28 10:00" -> "2025-07-28"
                    if scheduled_date == today:
                        future_today.append(record_element)
                    else:
                        future_other.append(record_element)
                case RoutineTypes.ONGOING.value:
                    ongoing_events.append(record_element)

        merged_records = []
        merged_records.extend(start_events)
        merged_records.extend(future_today)
        merged_records.extend(future_other)
        merged_records.extend(ongoing_events)

        # å¤„ç†definitionsï¼šæ‰€æœ‰æœªåœ¨active_recordsä¸­çš„definitionsï¼ŒæŒ‰quick_accesså’Œlast_updatedæ’åº
        definitions = event_data.get("definitions", {})
        priority_definitions = []

        for event_name, definition in definitions.items():
            # è·³è¿‡å·²ç»åœ¨active_recordsä¸­çš„äº‹ä»¶
            if event_name in active_event_names:
                continue

            # æ”¶é›†åˆ†ç±»
            category = definition.get("category")
            if category:
                category_names.add(category)

            # ä¸ºevent_definitionè®¡ç®—ç›¸å…³æ•°æ®
            avg_duration = self._calculate_avg_duration(definition)
            definition["avg_duration"] = avg_duration

            # è·å–æœ€åè®°å½•æ•°æ®
            last_record_id = definition.get("stats", {}).get("last_record_id", "")
            if last_record_id:
                last_record_data = records_data.get("records", {}).get(last_record_id)
                if not last_record_data:
                    last_record_data = active_records.get(last_record_id, {})
                definition["last_record_data"] = last_record_data

            priority_definitions.append((event_name, definition))

        # æŒ‰quick_accesså’Œlast_updatedæ’åºdefinitions
        priority_definitions.sort(
            key=lambda x: (
                not x[1].get("quick_access", False),
                x[1].get("last_updated", ""),
            ),
            reverse=True,
        )

        # é™åˆ¶å¤„ç†æ•°é‡ï¼Œé¿å…è¿‡å¤šè®¡ç®—
        for event_name, definition in priority_definitions:
            event_type = definition.get("type", "")

            definition_element = {
                "record_type": "event_definition",
                "event_name": event_name,
                "event_type": event_type,
                "category": definition.get("category", "æœªåˆ†ç±»"),
                "data": definition,
                "last_updated": definition.get("last_updated", ""),
                "quick_access": definition.get("quick_access", False),
            }
            merged_records.append(definition_element)

        # å…ˆåˆ†ç¦»"æœªåˆ†ç±»"ï¼Œå…¶ä½™æ’åºåæ‹¼æ¥ï¼Œ"æœªåˆ†ç±»"æ”¾æœ€å
        category_list = [c for c in category_names if c]
        if "æœªåˆ†ç±»" in category_list:
            category_list.remove("æœªåˆ†ç±»")
            category_options = ["å…¨éƒ¨"] + sorted(category_list) + ["æœªåˆ†ç±»"]
        else:
            category_options = ["å…¨éƒ¨"] + sorted(category_list)

        query_business_data = {
            "category_options": category_options,
            "query_data": merged_records,
            "categories": event_data.get("categories", []),  # ä¼ é€’å®Œæ•´çš„åˆ†ç±»æ•°æ®
        }

        return query_business_data

    # endregion

    # region æ›´æ–°eventå®šä¹‰

    def _update_event_definition(
        self,
        user_id: str,
        event_name: str,
        dup_business_data: Dict[str, Any],
        record_id: str,
        record_mode: str = "",
        source_record_name: str = "",
    ) -> bool:
        """
        ä»ç›´æ¥è®°å½•çš„business_dataåˆ›å»ºäº‹ä»¶å®šä¹‰

        Args:
            user_id: ç”¨æˆ·ID
            event_name: äº‹ä»¶åç§°
            dup_business_data: å®Œæ•´business_dataæ•°æ®
            record_id: è®°å½•ID
            record_mode: è®°å½•æ¨¡å¼
            source_record_name: æºè®°å½•åç§°

        Returns:
            bool: æ˜¯å¦æˆåŠŸåˆ›å»ºäº‹ä»¶å®šä¹‰
        """
        # åŠ è½½ç°æœ‰äº‹ä»¶å®šä¹‰
        # åˆ†ç¦»ä¸€ä»½ä¸´æ—¶çš„èšåˆæ•°æ®å¯¼è‡´ç¼–è¾‘æ¨¡å¼æœ‰æŒºå¤§çš„é—®é¢˜ï¼Œä½†ä¸ç‰¹åˆ«è‡´å‘½ï¼Œå¤‡æ³¨ä¸€ä¸‹ã€‚
        # é€»è¾‘ä¸Šåˆ†æˆä¸¤éƒ¨åˆ†ï¼Œéstatsçš„ï¼Œå’Œstatsçš„ã€‚
        # å¯¹äºpropertiesçš„ï¼Œæ˜¯åŸå­æ“ä½œï¼Œä¸”å…¼å®¹åç»­ç¼–è¾‘event_definitionï¼Œç›´æ¥æ›´æ–°ã€‚
        # å¯¹äºstatsçš„ï¼Œæ˜¯å¤åˆæ“ä½œï¼Œä»é…ç½®é‡ŒåŠ è½½ï¼Œè®¡ç®—ï¼Œå†æ›´æ–°ã€‚
        event_definitions = self.load_event_definitions(user_id)
        event_definition = dup_business_data.get("event_definition", {})
        catagory_options = dup_business_data.get("category_options", [])
        event_type = event_definition.get("type", RoutineTypes.INSTANT.value)
        computed_data = dup_business_data.get("computed_data", {})
        cycle_info = computed_data.get("cycle_info", {})

        record_data = dup_business_data.get("record_data", {})
        target_type = (
            dup_business_data.get("computed_data", {})
            .get("target_info", {})
            .get("target_type", "")
        )

        current_time = self._get_formatted_time()

        # æ£€æŸ¥äº‹ä»¶å®šä¹‰æ˜¯å¦å·²å­˜åœ¨
        if event_name in event_definitions.get("definitions", {}):
            # äº‹ä»¶å®šä¹‰å·²å­˜åœ¨
            # ç›®å‰è¿™é‡Œçš„æ•ˆæœæ˜¯æ›´æ–°degree_optionsï¼Œå…¶ä»–æ˜¯åç»­åŠŸèƒ½è‡ªåŠ¨æ”¯æŒã€‚
            existing_def = event_definitions["definitions"][event_name]
            existing_def["properties"] = event_definition.get("properties", {})
            existing_def["category"] = event_definition.get(
                "category", existing_def["category"]
            )

            # stats
            existing_def_stats = event_definitions["definitions"][event_name].get(
                "stats", {}
            )

            if record_mode != RoutineRecordModes.QUERY:
                existing_def_stats["record_count"] = (
                    existing_def_stats.get("record_count", 0) + 1
                )

            # æ›´æ–°è€—æ—¶ç»Ÿè®¡
            duration = safe_parse_number(record_data.get("duration"))
            if duration > 0:
                self._update_duration_stats(existing_def_stats, duration)

            # æ›´æ–°å‘¨æœŸç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if cycle_info:
                # åœ¨åˆ›å»ºäº‹ä»¶æ˜¯åŒ…å«äº†é¢„åˆ·æ–°æ£€æµ‹ï¼Œæ‰€ä»¥è¦ç”¨computed_dataé‡Œçš„cycle_info
                if target_type == RoutineTargetTypes.TIME.value:
                    existing_def_stats["cycle_count"] = (
                        cycle_info.get("cycle_count", 0) + duration
                    )
                else:
                    existing_def_stats["cycle_count"] = (
                        cycle_info.get("cycle_count", 0) + 1
                    )

                existing_def_stats["last_cycle_count"] = cycle_info.get(
                    "last_cycle_count", 0
                )
                existing_def_stats["last_refresh_date"] = cycle_info.get(
                    "last_refresh_date", ""
                )

            existing_def_stats["last_record_id"] = record_id

            # æ›´æ–°æŒ‡æ ‡ç»Ÿè®¡
            progress_type = event_definition.get("properties", {}).get("progress_type")
            if progress_type and progress_type != RoutineProgressTypes.NONE.value:
                progress_value = safe_parse_number(record_data.get("progress_value"))
                self._update_progress_stats(
                    existing_def_stats, progress_type, progress_value
                )

            existing_def["last_record_time"] = current_time
            existing_def["last_updated"] = current_time

        else:
            # åˆ›å»ºæ–°çš„äº‹ä»¶å®šä¹‰
            new_definition = self._create_event_definition(event_name, event_type)

            # ä»è¡¨å•æ•°æ®ä¸­æå–å¹¶è®¾ç½®å±æ€§
            self._populate_definition_from_business_data(
                new_definition, dup_business_data, current_time
            )

            category = event_definition.get("category", "")
            new_definition["category"] = category

            new_definition["last_record_id"] = record_id
            # æ·»åŠ åˆ°å®šä¹‰é›†åˆä¸­
            event_definitions["definitions"][event_name] = new_definition

            if category and category not in catagory_options:
                categories_data = dup_business_data.get("categories", [])
                # ä»åˆ†ç±»æ•°æ®ä¸­æŸ¥æ‰¾å¯¹åº”çš„é¢œè‰²
                for category_obj in categories_data:
                    if category_obj.get("name") == category:
                        new_color = category_obj.get("color", "")
                        break
                if not new_color:
                    new_color = ColorTypes.get_random_color().value
                event_definitions["categories"].append(
                    {
                        "name": category,
                        "color": new_color,
                    }
                )

        if source_record_name:
            source_definition = event_definitions["definitions"].get(
                source_record_name, {}
            )
            if event_name not in source_definition["properties"]["related_events"]:
                source_definition["properties"]["related_events"].append(event_name)
            source_definition["last_updated"] = current_time
        # æ›´æ–°å…¨å±€æ—¶é—´æˆ³
        event_definitions["last_updated"] = current_time
        event_definitions["last_record_time"] = current_time

        # ä¿å­˜äº‹ä»¶å®šä¹‰
        return self.save_event_definitions(user_id, event_definitions)

    def _populate_definition_from_business_data(
        self,
        definition: Dict[str, Any],
        dup_business_data: Dict[str, Any],
        current_time: str,
    ) -> None:
        """
        ä»è¡¨å•æ•°æ®å¡«å……äº‹ä»¶å®šä¹‰çš„å±æ€§

        Args:
            definition: äº‹ä»¶å®šä¹‰å­—å…¸
            record_data: è¡¨å•æ•°æ®
            current_time: å½“å‰æ—¶é—´
        """
        event_definition = dup_business_data.get("event_definition", {})
        properties = definition["properties"].update(
            event_definition.get("properties", {})
        )

        stats = definition["stats"]
        record_data = dup_business_data.get("record_data", {})

        # è®¾ç½®ç¨‹åº¦é€‰é¡¹
        degree = record_data.get("degree")
        if degree:
            if degree not in properties["degree_options"]:
                properties["degree_options"].append(degree)

        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        stats["record_count"] = 1

        definition["last_record_time"] = current_time

        # è®¾ç½®è€—æ—¶ç»Ÿè®¡ï¼ˆæ•°æ®å·²åœ¨å¡ç‰‡å±‚æ ¼å¼åŒ–ï¼‰
        duration = record_data.get("duration")
        if duration and duration > 0:
            self._update_duration_stats(stats, duration)

        # è®¾ç½®æŒ‡æ ‡ç»Ÿè®¡ï¼ˆæ•°æ®å·²åœ¨å¡ç‰‡å±‚æ ¼å¼åŒ–ï¼‰
        progress_type = event_definition.get("properties", {}).get("progress_type")
        if progress_type and progress_type != RoutineProgressTypes.NONE.value:
            progress_value = record_data.get("progress_value")
            if progress_value is not None:
                self._update_progress_stats(stats, progress_type, progress_value)

    def _update_duration_stats(self, stats: Dict[str, Any], duration: float) -> None:
        """
        æ›´æ–°äº‹ä»¶å®šä¹‰çš„è€—æ—¶ç»Ÿè®¡

        Args:
            stats: äº‹ä»¶å®šä¹‰
            duration: æ–°çš„è€—æ—¶å€¼
        """
        duration_info = stats["duration"]
        recent_values = duration_info.get("recent_values", [])

        # æ·»åŠ æ–°çš„è€—æ—¶å€¼
        recent_values.append(duration)
        window_size = duration_info.get("window_size", 10)
        if len(recent_values) > window_size:
            recent_values.pop(0)

        # æ›´æ–°è®¡æ•°å’Œå¹³å‡å€¼
        duration_count = duration_info.get("duration_count", 0) + 1
        duration_info["duration_count"] = duration_count

        # è®¡ç®—æ–°çš„å¹³å‡å€¼
        try:
            old_avg = duration_info.get("avg_all_time", 0) or 0
            old_count = duration_count - 1
            total_duration = old_avg * old_count + duration
            duration_info["avg_all_time"] = total_duration / duration_count
        except (TypeError, ZeroDivisionError):
            duration_info["avg_all_time"] = duration

    def _update_progress_stats(
        self, stats: Dict[str, Any], progress_type: str, progress_value: float
    ) -> None:
        """
        æ›´æ–°äº‹ä»¶å®šä¹‰çš„æŒ‡æ ‡ç»Ÿè®¡

        Args:
            stats: äº‹ä»¶å®šä¹‰
            progress_type: æŒ‡æ ‡ç±»å‹
            progress_value: æŒ‡æ ‡å€¼
        """
        # ç›®å‰åªæœ‰modifyï¼Œvalueçš„last_progress_valueå·²ç»è½¬ç§»åˆ°last_record_idçš„é€»è¾‘é‡Œ
        if progress_type == RoutineProgressTypes.MODIFY.value and progress_value != 0:
            current_total = stats.get("total_progress_value", 0) or 0
            stats["total_progress_value"] = round(current_total + progress_value, 3)

    # endregion

    # region è¾…åŠ©æ–¹æ³•
    # ä¸éœ€è¦ user_id ã€selfç­‰ä¿¡æ¯ï¼Œåˆé€‚çš„æƒ…å†µå¯ä»¥è¿ç§»å‡ºå»
    def _get_formatted_time(self) -> str:
        """
        è·å–æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸²

        Returns:
            str: æ ¼å¼åŒ–æ—¶é—´ "2025-07-10 09:07"
        """
        return datetime.now().strftime("%Y-%m-%d %H:%M")

    def _analyze_cycle_status(
        self, last_refresh_date: str, check_cycle: str
    ) -> Dict[str, Any]:
        """
        åˆ†æå‘¨æœŸçŠ¶æ€ï¼Œç»Ÿä¸€å¤„ç†å‘¨æœŸç›¸å…³çš„æ‰€æœ‰è®¡ç®—

        Args:
            last_refresh_date: ä¸Šæ¬¡åˆ·æ–°æ—¶é—´
            check_cycle: æ£€æŸ¥å‘¨æœŸ

        Returns:
            Dict[str, Any]: åŒ…å«ä»¥ä¸‹å­—æ®µçš„å­—å…¸
                - need_refresh: bool - æ˜¯å¦éœ€è¦åˆ·æ–°
                - cycle_gap: int - è·¨è¶Šçš„å‘¨æœŸæ•°é‡
                - description: str - å‘¨æœŸæè¿°
        """
        if not check_cycle:
            return {"need_refresh": False, "cycle_gap": 0, "description": ""}

        if not last_refresh_date:
            return {
                "need_refresh": True,
                "cycle_gap": 0,
                "description": f"å‰ä¸€{check_cycle}",
            }

        last_refresh = datetime.strptime(last_refresh_date, "%Y-%m-%d %H:%M")
        now = datetime.now()

        # ç»Ÿä¸€è®¡ç®—å‘¨æœŸå·®å¼‚
        cycle_gap = 0
        need_refresh = False

        match check_cycle:
            case RoutineCheckCycle.DAILY.value:
                days_diff = (now.date() - last_refresh.date()).days
                cycle_gap = max(0, days_diff)
                need_refresh = days_diff > 0
            case RoutineCheckCycle.WEEKLY.value:
                last_week = last_refresh.isocalendar()[1]
                current_week = now.isocalendar()[1]
                last_year = last_refresh.year
                current_year = now.year

                if current_year == last_year:
                    cycle_gap = max(0, current_week - last_week)
                else:
                    # è·¨å¹´è®¡ç®—
                    weeks_in_last_year = 52 if last_year % 4 != 0 else 53
                    cycle_gap = max(
                        0, (current_week - 1) + (weeks_in_last_year - last_week)
                    )
                need_refresh = cycle_gap > 0
            case RoutineCheckCycle.MONTHLY.value:
                months_diff = (current_year - last_year) * 12 + (
                    now.month - last_refresh.month
                )
                cycle_gap = max(0, months_diff)
                need_refresh = cycle_gap > 0
            case RoutineCheckCycle.SEASONALLY.value:
                last_season = (last_refresh.month - 1) // 3
                current_season = (now.month - 1) // 3
                seasons_diff = (current_year - last_year) * 4 + (
                    current_season - last_season
                )
                cycle_gap = max(0, seasons_diff)
                need_refresh = cycle_gap > 0
            case RoutineCheckCycle.YEARLY.value:
                cycle_gap = max(0, current_year - last_year)
                need_refresh = cycle_gap > 0
            case _:
                raise ValueError(f"ä¸æ”¯æŒçš„ check_cycle: {check_cycle}")
        # ç”Ÿæˆæè¿°
        gap_description = "å‰ä¸€" if cycle_gap <= 1 else f"å‰{cycle_gap}"

        # ä½¿ç”¨é›†ä¸­çš„æè¿°å•ä½
        description_unit = RoutineCheckCycle.get_description_unit(check_cycle)
        description = f"{gap_description}{description_unit}"

        return {
            "need_refresh": need_refresh,
            "cycle_gap": cycle_gap,
            "description": description,
        }

    def _calculate_avg_duration(self, event_definition: Dict[str, Any]) -> float:
        """
        è®¡ç®—äº‹ä»¶å®šä¹‰çš„å¹³å‡è€—æ—¶

        Args:
            event_definition: äº‹ä»¶å®šä¹‰

        Returns:
            float: å¹³å‡è€—æ—¶ï¼Œå¦‚æœæ²¡æœ‰æ•°æ®åˆ™è¿”å›0
        """
        event_duration_records = (
            event_definition.get("stats", {})
            .get("duration", {})
            .get("recent_values", [])
        )
        if event_duration_records:
            return round(sum(event_duration_records) / len(event_duration_records), 1)
        return 0

    # endregion

    # region æŠ¥è¡¨è®¡ç®—

    def preprocess_and_filter_records(
        self, all_records_dict: Dict[str, Any], start_range, end_range
    ):
        """
        é¢„å¤„ç†å’Œè¿‡æ»¤è®°å½•æ•°æ®
        1. å°†å­—å…¸è½¬ä¸ºåˆ—è¡¨ï¼Œå¹¶è½¬æ¢æ—¶é—´æ ¼å¼
        2. ç­›é€‰å‡ºä¸æ—¶é—´èŒƒå›´æœ‰äº¤é›†çš„è®°å½•
        3. æŒ‰å¼€å§‹æ—¶é—´å‡åºæ’åº
        """
        record_list = []
        for record in all_records_dict.values():
            try:
                # å…¼å®¹ä¸åŒçš„æ—¶é—´å­—æ®µå
                create_time_str = record.get("create_time") or record.get(
                    "created_time", ""
                )
                end_time_str = record.get("end_time", "")

                if not create_time_str:
                    continue

                start_time = datetime.fromisoformat(create_time_str.replace(" ", "T"))

                # å¦‚æœæ²¡æœ‰end_timeï¼Œä½¿ç”¨create_timeä½œä¸ºend_timeï¼ˆå³æ—¶äº‹ä»¶ï¼‰
                if not end_time_str:
                    end_time = start_time
                    start_time = start_time - timedelta(
                        minutes=record.get("duration", 0)
                    )
                else:
                    end_time = datetime.fromisoformat(end_time_str.replace(" ", "T"))

                if start_time < end_range and end_time > start_range:
                    record["start_dt"] = start_time
                    record["end_dt"] = end_time
                    record_list.append(record)
            except (ValueError, KeyError) as e:
                print(
                    f"Skipping record due to error: {record.get('record_id', 'N/A')}, {e}"
                )
                continue

        record_list.sort(key=lambda x: x["start_dt"])
        return record_list

    def generate_atomic_timeline(self, sorted_records, start_range, end_range):
        """
        ç”Ÿæˆä¸€ä¸ªç”±ä¸é‡å çš„"åŸå­æ—¶é—´å—"æ„æˆçš„æœ‰åºåˆ—è¡¨ã€‚
        æ¯ä¸ªå—éƒ½åŒ…å«å…¶å½’å±çš„åŸå§‹äº‹ä»¶ä¿¡æ¯ã€‚
        """
        if not sorted_records:
            return []

        # 1. æ”¶é›†æ‰€æœ‰ä¸é‡å¤çš„æ—¶é—´ç‚¹ï¼Œå¹¶é™åˆ¶åœ¨åˆ†æèŒƒå›´å†…
        time_points = {start_range, end_range}
        for r in sorted_records:
            clamped_start = max(r["start_dt"], start_range)
            clamped_end = min(r["end_dt"], end_range)
            if clamped_start < clamped_end:
                time_points.add(clamped_start)
                time_points.add(clamped_end)

        sorted_points = sorted(list(time_points))
        atomic_timeline = []

        # 2. éå†ç”±æ—¶é—´ç‚¹åˆ‡å‰²å‡ºçš„æ¯ä¸ªå¾®å°æ—¶é—´æ®µ
        for i in range(len(sorted_points) - 1):
            segment_start, segment_end = sorted_points[i], sorted_points[i + 1]

            if segment_start >= segment_end:
                continue

            # 3. æ‰¾å‡ºè¦†ç›–è¿™ä¸ªæ—¶é—´æ®µçš„ã€å¼€å§‹æ—¶é—´æœ€æ™šçš„äº‹ä»¶ ("é¡¶å±‚äº‹ä»¶")
            top_event = None
            for record in sorted_records:
                if (
                    record["start_dt"] <= segment_start
                    and record["end_dt"] >= segment_end
                ):
                    top_event = record  # å› ä¸ºå·²æ’åºï¼Œæœ€åä¸€ä¸ªåŒ¹é…çš„å°±æ˜¯æœ€é¡¶å±‚çš„

            # 4. å¦‚æœæ‰¾åˆ°å½’å±äº‹ä»¶ï¼Œåˆ™åˆ›å»ºåŸå­å—
            if top_event:
                atomic_block = {
                    "start_time": segment_start,
                    "end_time": segment_end,
                    "duration_minutes": (segment_end - segment_start).total_seconds()
                    / 60.0,
                    "source_event": top_event,  # å…³é”®ï¼ä¿ç•™å®Œæ•´çš„åŸå§‹äº‹ä»¶å¼•ç”¨
                }
                atomic_timeline.append(atomic_block)

        return atomic_timeline

    def aggregate_for_color_blending(self, atomic_timeline, event_map):
        """
        èšåˆåŸå­æ—¶é—´çº¿ï¼ŒæŒ‰é¢œè‰²åˆ†ç±»èšåˆæ•°æ®
        """
        # æŒ‰é¢œè‰²ç±»å‹èšåˆ
        color_aggregated_data = {}

        for block in atomic_timeline:
            event_name = block["source_event"]["event_name"]
            record_id = block["source_event"]["record_id"]
            duration = block["duration_minutes"]

            # è·å–åŸå§‹è®°å½•çš„durationï¼Œå¦‚æœå­˜åœ¨çš„è¯
            original_duration = block["source_event"].get("duration", None)

            # è·å–é¢œè‰²ç±»å‹â€”â€”å¯¹äºæœªæ¥äº‹ä»¶è¿™æ ·æ²¡æœ‰definitionçš„ï¼Œè®¾ç½®ç°è‰²
            color_type = event_map.get(event_name, {}).get("color", ColorTypes.GREY)

            # æ‰¾åˆ°å¯¹åº”çš„åˆ†ç±»åç§°
            category_name = event_map.get(event_name, {}).get("category", "æ— åˆ†ç±»")

            # ä½¿ç”¨åˆ†ç±»åç§°ä½œä¸ºèšåˆé”®
            if category_name not in color_aggregated_data:
                color_aggregated_data[category_name] = {
                    "duration": 0,
                    "count": 0,
                    "records": set(),
                    "color_type": color_type,
                    "record_durations": {},
                }

            # ç´¯è®¡æ—¶é—´ï¼Œä½†æ¯ä¸ªè®°å½•ä¸è¶…è¿‡å…¶åŸå§‹duration
            if original_duration is not None:
                # æ£€æŸ¥è¿™ä¸ªrecord_idæ˜¯å¦å·²ç»è¢«å¤„ç†è¿‡
                if record_id not in color_aggregated_data[category_name]["records"]:
                    # ç¬¬ä¸€æ¬¡å¤„ç†è¿™ä¸ªè®°å½•
                    color_aggregated_data[category_name]["records"].add(record_id)
                    color_aggregated_data[category_name]["count"] += 1
                    color_aggregated_data[category_name]["record_durations"][
                        record_id
                    ] = 0

                # è®¡ç®—è¿™ä¸ªè®°å½•IDå·²ç»ç´¯è®¡çš„æ—¶é—´
                current_record_duration = color_aggregated_data[category_name][
                    "record_durations"
                ].get(record_id, 0)
                # è®¡ç®—è¿˜èƒ½ç´¯è®¡å¤šå°‘æ—¶é—´ï¼ˆä¸è¶…è¿‡åŸå§‹durationï¼‰
                remaining_duration = max(0, original_duration - current_record_duration)
                # å®é™…ç´¯è®¡çš„æ—¶é—´
                actual_duration = min(duration, remaining_duration)

                color_aggregated_data[category_name]["duration"] += actual_duration
                color_aggregated_data[category_name]["record_durations"][
                    record_id
                ] += actual_duration
            else:
                # æ²¡æœ‰åŸå§‹durationé™åˆ¶ï¼Œç›´æ¥ç´¯è®¡
                color_aggregated_data[category_name]["duration"] += duration
                if record_id not in color_aggregated_data[category_name]["records"]:
                    color_aggregated_data[category_name]["records"].add(record_id)
                    color_aggregated_data[category_name]["count"] += 1

        # æ ¼å¼åŒ–ä¸ºæœ€ç»ˆè¾“å‡º
        final_list = []
        for category_name, data in color_aggregated_data.items():
            final_list.append(
                {
                    "category_color": data["color_type"],
                    "category_name": category_name,
                    "duration": data["duration"],
                    "count": data["count"],
                }
            )
        return final_list

    def _calculate_nonlinear_weight(
        self, duration, count, duration_importance=0.7, count_importance=0.3
    ):
        """
        ä½¿ç”¨åŠ æƒæ±‚å’Œçš„æ–¹å¼è®¡ç®—å½±å“åŠ›ã€‚
        duration_importance å’Œ count_importance çš„å’Œåº”è¯¥ä¸º1ã€‚
        """
        if duration <= 0 or count <= 0:
            return 0

        # 1. å¯¹æ—¶é•¿å’Œæ¬¡æ•°è¿›è¡Œå½’ä¸€åŒ–æˆ–å‡½æ•°å˜æ¢ï¼Œä½¿å…¶å¤„äºå¯æ¯”è¾ƒçš„èŒƒå›´
        #    æˆ‘ä»¬ä»ç„¶ä½¿ç”¨ä¹‹å‰çš„å‡½æ•°å˜æ¢æ¥å‹ç¼©æ•°å€¼
        duration_component = math.sqrt(duration)
        #    æ¬¡æ•°åˆ†é‡å¯ä»¥ç¨å¾®åŠ å¼ºä¸€ä¸‹ï¼Œå› ä¸ºå®ƒçš„åŸå§‹æ•°å€¼å°
        count_component = (1 + math.log2(count)) * 5  # ä¹˜ä»¥ä¸€ä¸ªç³»æ•°æ¥æ”¾å¤§å®ƒçš„åŸºç¡€å€¼

        # 2. åŠ æƒæ±‚å’Œ
        #    è¿™é‡Œï¼Œæˆ‘ä»¬å‡è®¾æ—¶é•¿çš„é‡è¦æ€§å 70%ï¼Œæ¬¡æ•°çš„é‡è¦æ€§å 30%
        #    ä½ å¯ä»¥æ ¹æ®ä½ çš„æ„Ÿè§‰æ¥è°ƒæ•´è¿™ä¸¤ä¸ªç³»æ•°ï¼
        additive_score = (duration_component * duration_importance) + (
            count_component * count_importance
        )

        # ä¹˜ä»¥ä¸€ä¸ªå¸¸æ•°è®©æ•°å€¼å˜å¤§
        return additive_score * 5

    # endregion

    # region é¢œè‰²è®¡ç®—

    def calculate_daily_color(
        self, user_id: str, target_date: str = None
    ) -> Dict[str, Any]:
        """
        è®¡ç®—æŒ‡å®šæ—¥æœŸçš„é¢œè‰²å€¼ï¼ˆä½¿ç”¨åŸå­æ—¶é—´çº¿ç®—æ³•ï¼‰

        Args:
            user_id: ç”¨æˆ·ID
            target_date: ç›®æ ‡æ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤ä¸ºæ˜¨å¤©

        Returns:
            str: è®¡ç®—å‡ºçš„é¢œè‰²å€¼
        """

        # ç¡®å®šç›®æ ‡æ—¥æœŸ
        if target_date is None:
            yesterday = datetime.now() - timedelta(days=1)
            target_date = yesterday.strftime("%Y-%m-%d")

        # å®šä¹‰åˆ†æèŒƒå›´
        target_date_dt = datetime.strptime(target_date, "%Y-%m-%d")
        day_start = target_date_dt
        day_end = day_start + timedelta(days=1)
        return self.calculate_color_palette(user_id, day_start, day_end)

    def calculate_weekly_color(
        self, user_id: str, target_week_start: str = None
    ) -> str:
        """
        è®¡ç®—æŒ‡å®šå‘¨çš„é¢œè‰²å€¼

        Args:
            user_id: ç”¨æˆ·ID
            target_week_start: ç›®æ ‡å‘¨å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤ä¸ºä¸Šå‘¨

        Returns:
            str: è®¡ç®—å‡ºçš„é¢œè‰²å€¼
        """

        # ç¡®å®šç›®æ ‡å‘¨
        if target_week_start is None:
            today = datetime.now()
            days_since_monday = today.weekday()
            last_monday = today - datetime.timedelta(days=days_since_monday + 7)
            target_week_start = last_monday.strftime("%Y-%m-%d")

        # è®¡ç®—å‘¨ç»“æŸæ—¥æœŸ
        start_date = datetime.strptime(target_week_start, "%Y-%m-%d")
        end_date = start_date + datetime.timedelta(days=6)
        return self.calculate_color_palette(user_id, start_date, end_date)

    def calculate_color_palette(
        self,
        user_id: str,
        day_start: datetime = None,
        day_end: datetime = None,
    ) -> Dict[str, Any]:
        """
        è®¡ç®—é¢œè‰²è°ƒè‰²ç›˜
        """

        default_return = {
            "type": "default",
            "name": "è“è‰²",
            "hex": ColorTypes.BLUE.light_color,
            "distance": 0,
        }

        # è·å–è®°å½•æ•°æ®
        records_data = self.load_event_records(user_id)
        records = records_data.get("records", {})

        if not records:
            return default_return  # é»˜è®¤é¢œè‰²

        # åŠ è½½åˆ†ç±»æ•°æ®
        definitions_data = self.load_event_definitions(user_id)
        categories_data = definitions_data.get("categories", [])

        # åˆ›å»ºäº‹ä»¶ååˆ°é¢œè‰²ç±»å‹çš„æ˜ å°„
        event_to_color_map = {}
        for event_name, event_def in definitions_data.get("definitions", {}).items():
            category = event_def.get("category", "")
            cata_info = {}
            if category:
                # æŸ¥æ‰¾åˆ†ç±»å¯¹åº”çš„é¢œè‰²
                cata_info["category"] = category
                for category_obj in categories_data:
                    if category_obj.get("name") == category:
                        color_value = category_obj.get("color", ColorTypes.BLUE.value)
                        cata_info["color"] = ColorTypes.get_by_value(color_value)
                        break
            else:
                cata_info["category"] = "æ— åˆ†ç±»"
                cata_info["color"] = ColorTypes.GREY
            event_to_color_map[event_name] = cata_info

        # 1. é¢„å¤„ç†å’Œæ’åº
        relevant_records = self.preprocess_and_filter_records(
            records, day_start, day_end
        )
        if not relevant_records:
            return default_return

        # 2. ç”Ÿæˆæ ¸å¿ƒæ•°æ®ç»“æ„ï¼šåŸå­æ—¶é—´çº¿
        atomic_timeline = self.generate_atomic_timeline(
            relevant_records, day_start, day_end
        )

        # 3. èšåˆæ•°æ®ç”¨äºé¢œè‰²æ··åˆ
        category_data = self.aggregate_for_color_blending(
            atomic_timeline, event_to_color_map
        )

        if not category_data:
            return default_return

        # 4. è®¡ç®—åˆ†ç±»æƒé‡
        category_weights = {}
        max_weight_category = None
        max_weight = 0
        for item in category_data:
            category_name = item["category_name"]
            duration = item["duration"]
            count = item["count"]

            weight = self._calculate_nonlinear_weight(duration, count)
            if category_name not in category_weights:
                category_weights[category_name] = {}
                category_weights[category_name]["color"] = item["category_color"]
                category_weights[category_name]["weight"] = 0

            category_weights[category_name]["weight"] += weight
            if category_weights[category_name]["weight"] > max_weight:
                max_weight = category_weights[category_name]["weight"]
                max_weight_category = category_name

        # 5. è®¡ç®—æœ€ç»ˆé¢œè‰²
        final_color = self._blend_colors_by_weights(category_weights)
        if max_weight_category:
            final_color["max_weight_category"] = max_weight_category
        palette_data = self.prepare_palette_data(category_weights)

        return final_color, palette_data

    def _blend_colors_by_weights(
        self, category_weights: Dict[str, float]
    ) -> Dict[str, Any]:
        """
        æ ¹æ®æƒé‡æ··åˆé¢œè‰²ï¼ˆåœ¨HSLè‰²å½©ç©ºé—´ä¸­è¿›è¡Œè®¡ç®—ï¼‰

        Args:
            category_weights: åˆ†ç±»æƒé‡å­—å…¸

        Returns:
            str: æ··åˆåçš„é¢œè‰²å€¼
        """
        # åœ¨HSLè‰²å½©ç©ºé—´ä¸­æ··åˆé¢œè‰²
        blended_hsl = self._blend_colors_in_hsl_space(category_weights)

        # æ‰¾åˆ°æœ€æ¥è¿‘çš„é¢„å®šä¹‰é¢œè‰²
        return self._find_closest_color_from_hsl(blended_hsl)

    def _blend_colors_in_hsl_space(self, category_weights: Dict[str, float]) -> tuple:
        """
        åœ¨HSLè‰²å½©ç©ºé—´ä¸­æ··åˆé¢œè‰²

        Args:
            category_weights: åˆ†ç±»æƒé‡å­—å…¸
            categories_data: åˆ†ç±»æ•°æ®åˆ—è¡¨

        Returns:
            tuple: (H, S, L) æ··åˆåçš„HSLå€¼
        """
        sum_h_x, sum_h_y = 0, 0
        total_s, total_l, total_h = 0, 0, 0
        total_weight = sum(
            category_info["weight"] for category_info in category_weights.values()
        )

        if total_weight == 0:
            return 0, 0, 0.5  # è¿”å›ä¸€ä¸ªä¸­æ€§ç°è‰²

        for _, category_info in category_weights.items():
            # æŸ¥æ‰¾åˆ†ç±»å¯¹åº”çš„é¢œè‰²
            weight = category_info["weight"]
            category_color = category_info["color"]

            # è·å–é¢œè‰²å¯¹åº”çš„HSLå€¼
            color_type = ColorTypes.get_by_value(category_color.value)
            hex_color = color_type.light_color  # ä½¿ç”¨äº®è‰²

            # è½¬æ¢åå…­è¿›åˆ¶ä¸ºHSL
            color_h, color_s, color_l = hex_to_hsl(hex_color)

            # æŒ‰æƒé‡ç´¯åŠ HSLå€¼
            total_s += color_s * weight
            total_l += color_l * weight
            total_h += color_h * weight

            # 2. å¯¹è‰²ç›¸(H)è¿›è¡Œå‘é‡åŠ æƒå¹³å‡
            #    é¦–å…ˆå°†è§’åº¦è½¬æ¢ä¸ºå¼§åº¦
            color_h_rad = math.radians(color_h)
            #    è®¡ç®—å‘é‡çš„x, yåˆ†é‡å¹¶æŒ‰æƒé‡ç´¯åŠ 
            sum_h_x += math.cos(color_h_rad) * weight
            sum_h_y += math.sin(color_h_rad) * weight

        final_s = total_s / total_weight
        final_l = total_l / total_weight
        final_h_rad = math.atan2(sum_h_y, sum_h_x)
        # å°†å¼§åº¦è½¬æ¢å›è§’åº¦ï¼ˆ0-360åº¦ï¼‰
        final_h_deg = math.degrees(final_h_rad)
        if final_h_deg < 0:
            final_h_deg += 360

        return (final_h_deg, final_s, final_l)

    def _find_closest_color_from_hsl(
        self, target_hsl: tuple, threshold: float = 10
    ) -> Dict[str, Any]:
        """
        ä»HSLå€¼æ‰¾åˆ°æœ€æ¥è¿‘çš„é¢„å®šä¹‰é¢œè‰²

        Args:
            target_hsl: ç›®æ ‡HSLå€¼ (H, S, L)

        Returns:
            str: æœ€æ¥è¿‘çš„é¢œè‰²å€¼
        """
        min_distance = float("inf")
        closest_color = ColorTypes.BLUE

        for color_type in ColorTypes:
            if color_type.value == "grey":  # è·³è¿‡ç°è‰²
                continue

            hex_color = color_type.light_color
            color_hsl = hex_to_hsl(hex_color)

            # è®¡ç®—HSLè·ç¦»
            distance = self._calculate_hsl_distance(target_hsl, color_hsl)

            if distance < min_distance:
                min_distance = distance
                closest_color = color_type

        if closest_color and min_distance < threshold:
            return {
                "type": "predefined",
                "name": closest_color.value,
                "hex": closest_color.light_color,
                "distance": round(min_distance, 2),
            }

        hex_color = hsl_to_hex(target_hsl[0], target_hsl[1], target_hsl[2])
        return {
            "type": "unique",
            "name": "ç‹¬ç‰¹çš„é¢œè‰²",  # ä¸´æ—¶åå­—
            "hex": hex_color,
            "closest_to": closest_color.value if closest_color else "N/A",
            "distance_to_closest": round(min_distance, 2),
        }

    def _calculate_hsl_distance(self, hsl1: tuple, hsl2: tuple) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªHSLé¢œè‰²ä¹‹é—´çš„è·ç¦»

        Args:
            hsl1, hsl2: HSLå€¼å…ƒç»„

        Returns:
            float: é¢œè‰²è·ç¦»
        """
        h1, s1, l1 = hsl1
        h2, s2, l2 = hsl2

        # è‰²ç›¸è·ç¦»ï¼ˆè€ƒè™‘ç¯å½¢ï¼‰
        h_diff = min(abs(h1 - h2), 360 - abs(h1 - h2))

        # é¥±å’Œåº¦å’Œäº®åº¦è·ç¦»
        s_diff = s1 - s2
        l_diff = l1 - l2

        # åŠ æƒè·ç¦»ï¼ˆè‰²ç›¸æƒé‡æ›´é«˜ï¼‰
        distance = math.sqrt(
            (h_diff * 1.5) ** 2 + (s_diff * 1.0) ** 2 + (l_diff * 1.0) ** 2
        )
        return distance

    def prepare_palette_data(self, category_weights):
        """
        å°†æƒé‡å­—å…¸è½¬æ¢ä¸ºç”¨äºç»˜å›¾çš„è°ƒè‰²ç›˜æ•°æ®åˆ—è¡¨ã€‚
        """
        total_weight = sum(info["weight"] for info in category_weights.values())
        if total_weight == 0:
            return []

        palette_data = []
        for category_name, info in category_weights.items():
            palette_data.append(
                {
                    "name": category_name,
                    "color_enum": info["color"],
                    "color_hex": info["color"].light_color,
                    "weight": info["weight"],
                    "percentage": (info["weight"] / total_weight) * 100.0,
                }
            )

        # æŒ‰ç™¾åˆ†æ¯”é™åºæ’åºï¼Œæ–¹ä¾¿åç»­ç»˜å›¾
        palette_data.sort(key=lambda x: x["percentage"], reverse=True)

        return palette_data

    # endregion


# region ç»˜å›¾æç¤ºè¯
def color_desc(color_name, color_hex):
    """æ ¹æ®é¢œè‰²åå’Œè‰²å€¼ç”Ÿæˆè‹±æ–‡æè¿°"""
    color_map = {
        "turquoise": "brilliant turquoise",
        "blue": "soft light pastel blue",
        "wathet": "serene sky blue",
        "carmine": "gentle pink",
        "orange": "warm vibrant apricot orange",
        "purple": "soft lavender purple",
        "grey": "pearlescent off-white",
        "red": "delicate soft rose red",
        "green": "fresh lively mint green",
        "lime": "zesty lime green",
        "sunflower": "bright sunflower yellow",
    }
    # ä¼˜å…ˆä½¿ç”¨é¢„è®¾çš„æè¿°
    description = color_map.get(color_name.lower())
    if description:
        return description
    # å¦‚æœæ²¡æœ‰é¢„è®¾ï¼Œåˆ™æä¾›ä¸€ä¸ªåŸºäºé€šç”¨åç§°çš„å¤‡ç”¨æè¿°
    elif color_name:
        return f"shade of {color_name.lower()}"
    # æœ€åæ‰ä½¿ç”¨HEXå€¼ä½œä¸ºå¤‡ç”¨
    else:
        return f"color with hex code {color_hex}"


def subject_desc(subject_name):
    """
    ç”Ÿæˆå°ç« å†…ä¸»ä½“é€ å‹çš„è‹±æ–‡æè¿°
    ä¾‹å¦‚ subject_name="book"ï¼Œè¿”å› "The center of the seal features a detailed relief of an open book."
    """
    # æ³¨é‡Š: æ‰€æœ‰çš„å€¼éƒ½ä»å®Œæ•´çš„å¥å­ä¿®æ”¹ä¸ºäº†åè¯çŸ­è¯­ï¼Œä¾‹å¦‚ "a book" è€Œä¸æ˜¯ "the seal has a book"ã€‚
    subject_map = {
        "book": "an open book with finely etched lines representing pages and text",
        "star": "a classic five-pointed star with clean, raised edges",
        "cat": "a stylized silhouette of a sitting cat with a gracefully curved tail",
        "flower": "elegant curved lines forming a rose silhouette",
        "å·¥ä½œä¸åˆ›ä½œ": "the clean, modern outline of a laptop computer, its screen displaying a simple line graph",
        "å­¦ä¹ ": "a charming relief of a graduation cap, with a tassel dangling to the side",
        "è¿åŠ¨": "a graceful female yoga pose line representing a feminine silhouette",
        "å®¶åŠ¡": "the simple, iconic outline of a house with a small chimney",
        "ä¸ªäººæŠ¤ç†": "a minimalist design of a shower head with delicate droplets appearing to fall from it",
        "é¥®é£Ÿ": "simple, elegant lines forming fruits shapes",
        "ä¼‘æ¯": "a serene crescent moon hanging over a soft, puffy pillow",
        "å¨±ä¹": "a musical note and a game controller, side-by-side",
    }
    return subject_map.get(
        subject_name.lower(),
        f"a clean {subject_name} silhouette",
    )


def generate_intelligent_color_description(color_list: list) -> str:
    """
    (æ™ºèƒ½ç‰ˆ) åˆ†ææƒé‡åˆ†å¸ƒï¼Œç”¨æœ€å¤šä¸‰å±‚é‡çº§æ¥åŠ¨æ€ç”Ÿæˆé¢œè‰²æè¿°ã€‚
    """
    if not color_list:
        return ""

    num_colors = len(color_list)
    descriptive_colors = [
        color_desc(c.get("color_enum").value, c.get("color_hex", ""))
        for c in color_list
    ]

    # --- æ ¸å¿ƒåˆ†æé€»è¾‘ ---

    # æƒ…å†µ1: åªæœ‰ä¸€ä¸ªé¢œè‰²
    if num_colors == 1:
        return f"a solid {descriptive_colors[0]} color"

    # æƒ…å†µ2: åªæœ‰ä¸¤ç§é¢œè‰²
    if num_colors == 2:
        # æ¯”è¾ƒæƒé‡ï¼Œå¦‚æœå·®è·ä¸å¤§ï¼Œåˆ™ä¸ºå¹¶åˆ—ä¸»è‰²
        if (
            color_list[0]["percentage"] / color_list[1]["percentage"] < 1.2
        ):  # æƒé‡æ¯”å°äº1.2å€ï¼Œè§†ä¸ºå¹¶åˆ—
            return f"a marbled blend of {descriptive_colors[0]} and {descriptive_colors[1]}"
        else:
            return f"{descriptive_colors[0]} marbled with {descriptive_colors[1]}"

    # æƒ…å†µ3: ä¸‰ä¸ªåŠä»¥ä¸Šé¢œè‰²ï¼Œè¿›è¡Œå±‚çº§åˆ†æ
    # Tier 1: ä¸»è‰²è°ƒ (The main players)
    tier1 = [descriptive_colors[0]]
    # æ£€æŸ¥ç¬¬äºŒåæ˜¯å¦ä¸ç¬¬ä¸€åå·®è·ä¸å¤§ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™å¹¶å…¥ä¸»è‰²è°ƒ
    if (
        color_list[1]["percentage"] / color_list[0]["percentage"] > 0.8
    ):  # ç¬¬äºŒåæƒé‡è¶…è¿‡ç¬¬ä¸€åçš„70%
        tier1.append(descriptive_colors[1])
        # æ£€æŸ¥ç¬¬ä¸‰åæ˜¯å¦ä¸ç¬¬äºŒåå·®è·ä¸å¤§
        if (
            num_colors > 2
            and color_list[2]["percentage"] / color_list[1]["percentage"] > 0.7
        ):
            tier1.append(descriptive_colors[2])

    tier1_text = f"a rich marble of {' and '.join(tier1)}"

    # Tier 2 & 3: æ¬¡è¦è‰²å’Œç‚¹ç¼€è‰²
    remaining_colors = descriptive_colors[len(tier1) :]
    if not remaining_colors:
        return tier1_text  # åªæœ‰ä¸»è‰²è°ƒ

    # Tier 2: æ¬¡è¦è‰² (The supporting cast)
    tier2 = []
    if remaining_colors:
        tier2.append(remaining_colors.pop(0))
        # æ£€æŸ¥ä¸‹ä¸€ä¸ªæ˜¯å¦ä¸å½“å‰å·®è·ä¸å¤§
        if (
            remaining_colors
            and color_list[len(tier1) + 1]["percentage"]
            / color_list[len(tier1)]["percentage"]
            > 0.6
        ):
            tier2.append(remaining_colors.pop(0))

    tier2_text = f"swirled with prominent streaks of {' and '.join(tier2)}"

    if not remaining_colors:
        return f"{tier1_text}, {tier2_text}"

    # Tier 3: ç‚¹ç¼€è‰² (The final touches)
    tier3 = remaining_colors
    tier3_text = f"and subtle hints of {', '.join(tier3)}"

    return f"{tier1_text}, {tier2_text}, {tier3_text}"


def wax_stamp_prompt(color_palette, subject_name=None):
    """
    æ ¹æ®color_paletteç»“æœç»„è£…è‹±æ–‡ç”»å›¾æç¤ºè¯ï¼Œå¹¶æ ¹æ®subject_nameæ™ºèƒ½æ’å…¥ä¸»ä½“é€ å‹æè¿°
    color_palette: (unique_color_info, color_list)
    subject_name: å°ç« å†…ä¸»ä½“é€ å‹çš„åç§°ï¼ˆå¯ä¸ºNoneæˆ–ç©ºå­—ç¬¦ä¸²ï¼‰
    """
    color_list = color_palette
    # é¢œè‰²æŒ‰æ¯”ä¾‹æ’åº
    color_list = (
        sorted(color_list, key=lambda x: -x.get("percentage", 0)) if color_list else []
    )

    # color_detail_text = generate_color_details_text(color_list)
    # æ³¨é‡Š: è°ƒç”¨æˆ‘ä»¬å…¨æ–°çš„ã€æ™ºèƒ½çš„é¢œè‰²æè¿°å‡½æ•°ã€‚
    color_text = generate_intelligent_color_description(color_list)

    # ä¸»ä½“é€ å‹æè¿°
    subject_name = subject_name or color_list[0].get("name") if color_list else ""
    subject_text = subject_desc(subject_name) if subject_name else ""

    # --- 4. å…¨æ–°Promptç»“æ„åŒ–ç»„è£… ---
    # --- 3. ç»ˆæPromptç»„è£… ---
    # æ³¨é‡Š: å®Œå…¨é‡‡ç”¨ä½ æä¾›çš„ã€ç»è¿‡éªŒè¯çš„æç®€æ¨¡æ¿ç»“æ„ã€‚
    prompt = (
        "Macro photograph of a wax seal on cream textured paper. "
        "Semi-translucent wax with organic, irregular, molten edges. "
    )

    if subject_text:
        # æ³¨é‡Š: æ’å…¥ä¸»ä½“å›¾æ¡ˆæè¿°
        prompt += f"The raised seal pattern shows {subject_text}. "

    # æ³¨é‡Š: æ’å…¥ç”±æ™ºèƒ½ç®—æ³•ç”Ÿæˆçš„é¢œè‰²æè¿°ï¼Œå¹¶åŠ å…¥é‡‘è‰²é—ªç²‰
    prompt += f"Marbled colors: {color_text}, with shimmering gold dust particles suspended within. "

    # æ³¨é‡Š: æ’å…¥å…‰ç…§å’Œé£æ ¼æè¿°
    prompt += (
        "Dramatic lighting highlights the translucent, glossy surface. "
        "Professional photography, shallow depth of field."
    )

    return prompt


# endregion
